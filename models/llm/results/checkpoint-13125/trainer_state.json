{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 13125,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002285714285714286,
      "grad_norm": 3.740276336669922,
      "learning_rate": 9e-07,
      "loss": 0.7151,
      "step": 10
    },
    {
      "epoch": 0.004571428571428572,
      "grad_norm": 3.4773032665252686,
      "learning_rate": 1.9e-06,
      "loss": 0.6891,
      "step": 20
    },
    {
      "epoch": 0.006857142857142857,
      "grad_norm": 2.6679563522338867,
      "learning_rate": 2.9e-06,
      "loss": 0.6506,
      "step": 30
    },
    {
      "epoch": 0.009142857142857144,
      "grad_norm": 1.684831142425537,
      "learning_rate": 3.9e-06,
      "loss": 0.5835,
      "step": 40
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 1.5588701963424683,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.4973,
      "step": 50
    },
    {
      "epoch": 0.013714285714285714,
      "grad_norm": 1.6038535833358765,
      "learning_rate": 5.9e-06,
      "loss": 0.3671,
      "step": 60
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.3700612783432007,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.2239,
      "step": 70
    },
    {
      "epoch": 0.018285714285714287,
      "grad_norm": 1.1400560140609741,
      "learning_rate": 7.9e-06,
      "loss": 0.1916,
      "step": 80
    },
    {
      "epoch": 0.02057142857142857,
      "grad_norm": 0.638788640499115,
      "learning_rate": 8.9e-06,
      "loss": 0.0875,
      "step": 90
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 2.3844544887542725,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0923,
      "step": 100
    },
    {
      "epoch": 0.025142857142857144,
      "grad_norm": 4.512235164642334,
      "learning_rate": 1.09e-05,
      "loss": 0.0513,
      "step": 110
    },
    {
      "epoch": 0.027428571428571427,
      "grad_norm": 0.2964513897895813,
      "learning_rate": 1.19e-05,
      "loss": 0.0257,
      "step": 120
    },
    {
      "epoch": 0.029714285714285714,
      "grad_norm": 0.591594934463501,
      "learning_rate": 1.29e-05,
      "loss": 0.0656,
      "step": 130
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.17335490882396698,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0325,
      "step": 140
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 0.11056171357631683,
      "learning_rate": 1.49e-05,
      "loss": 0.0084,
      "step": 150
    },
    {
      "epoch": 0.036571428571428574,
      "grad_norm": 0.4755837619304657,
      "learning_rate": 1.59e-05,
      "loss": 0.0936,
      "step": 160
    },
    {
      "epoch": 0.038857142857142854,
      "grad_norm": 0.15327852964401245,
      "learning_rate": 1.69e-05,
      "loss": 0.032,
      "step": 170
    },
    {
      "epoch": 0.04114285714285714,
      "grad_norm": 0.19798047840595245,
      "learning_rate": 1.79e-05,
      "loss": 0.0429,
      "step": 180
    },
    {
      "epoch": 0.04342857142857143,
      "grad_norm": 0.1852702647447586,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0326,
      "step": 190
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 0.09119946509599686,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0777,
      "step": 200
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.1869838982820511,
      "learning_rate": 2.09e-05,
      "loss": 0.0256,
      "step": 210
    },
    {
      "epoch": 0.05028571428571429,
      "grad_norm": 0.8070349097251892,
      "learning_rate": 2.19e-05,
      "loss": 0.0254,
      "step": 220
    },
    {
      "epoch": 0.052571428571428575,
      "grad_norm": 2.866472005844116,
      "learning_rate": 2.29e-05,
      "loss": 0.0291,
      "step": 230
    },
    {
      "epoch": 0.054857142857142854,
      "grad_norm": 0.050008367747068405,
      "learning_rate": 2.39e-05,
      "loss": 0.0312,
      "step": 240
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.038670863956213,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0162,
      "step": 250
    },
    {
      "epoch": 0.05942857142857143,
      "grad_norm": 0.029976803809404373,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.003,
      "step": 260
    },
    {
      "epoch": 0.061714285714285715,
      "grad_norm": 0.031144138425588608,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.003,
      "step": 270
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.04369983822107315,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0618,
      "step": 280
    },
    {
      "epoch": 0.06628571428571428,
      "grad_norm": 0.08010929822921753,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.007,
      "step": 290
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 0.027463169768452644,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0025,
      "step": 300
    },
    {
      "epoch": 0.07085714285714285,
      "grad_norm": 0.020218513906002045,
      "learning_rate": 3.09e-05,
      "loss": 0.007,
      "step": 310
    },
    {
      "epoch": 0.07314285714285715,
      "grad_norm": 0.026973169296979904,
      "learning_rate": 3.19e-05,
      "loss": 0.0012,
      "step": 320
    },
    {
      "epoch": 0.07542857142857143,
      "grad_norm": 0.017419712617993355,
      "learning_rate": 3.29e-05,
      "loss": 0.001,
      "step": 330
    },
    {
      "epoch": 0.07771428571428571,
      "grad_norm": 0.01755714602768421,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0343,
      "step": 340
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.018594201654195786,
      "learning_rate": 3.49e-05,
      "loss": 0.0088,
      "step": 350
    },
    {
      "epoch": 0.08228571428571428,
      "grad_norm": 0.014172670431435108,
      "learning_rate": 3.59e-05,
      "loss": 0.0025,
      "step": 360
    },
    {
      "epoch": 0.08457142857142858,
      "grad_norm": 0.015897292643785477,
      "learning_rate": 3.69e-05,
      "loss": 0.0011,
      "step": 370
    },
    {
      "epoch": 0.08685714285714285,
      "grad_norm": 0.014860437251627445,
      "learning_rate": 3.79e-05,
      "loss": 0.0043,
      "step": 380
    },
    {
      "epoch": 0.08914285714285715,
      "grad_norm": 0.010119752027094364,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0012,
      "step": 390
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.008390461094677448,
      "learning_rate": 3.99e-05,
      "loss": 0.0024,
      "step": 400
    },
    {
      "epoch": 0.09371428571428571,
      "grad_norm": 0.01097086351364851,
      "learning_rate": 4.09e-05,
      "loss": 0.0005,
      "step": 410
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.008250044658780098,
      "learning_rate": 4.19e-05,
      "loss": 0.0004,
      "step": 420
    },
    {
      "epoch": 0.09828571428571428,
      "grad_norm": 0.005765240173786879,
      "learning_rate": 4.29e-05,
      "loss": 0.0003,
      "step": 430
    },
    {
      "epoch": 0.10057142857142858,
      "grad_norm": 0.006986677646636963,
      "learning_rate": 4.39e-05,
      "loss": 0.0013,
      "step": 440
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 0.005261837039142847,
      "learning_rate": 4.49e-05,
      "loss": 0.0007,
      "step": 450
    },
    {
      "epoch": 0.10514285714285715,
      "grad_norm": 0.0051566725596785545,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0003,
      "step": 460
    },
    {
      "epoch": 0.10742857142857143,
      "grad_norm": 0.00912410393357277,
      "learning_rate": 4.69e-05,
      "loss": 0.0003,
      "step": 470
    },
    {
      "epoch": 0.10971428571428571,
      "grad_norm": 0.009411138482391834,
      "learning_rate": 4.79e-05,
      "loss": 0.0299,
      "step": 480
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.274044156074524,
      "learning_rate": 4.89e-05,
      "loss": 0.046,
      "step": 490
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.012134909629821777,
      "learning_rate": 4.99e-05,
      "loss": 0.0065,
      "step": 500
    },
    {
      "epoch": 0.11657142857142858,
      "grad_norm": 0.007071380503475666,
      "learning_rate": 4.9964356435643565e-05,
      "loss": 0.0007,
      "step": 510
    },
    {
      "epoch": 0.11885714285714286,
      "grad_norm": 0.024492666125297546,
      "learning_rate": 4.992475247524753e-05,
      "loss": 0.0025,
      "step": 520
    },
    {
      "epoch": 0.12114285714285715,
      "grad_norm": 0.004305507056415081,
      "learning_rate": 4.9885148514851487e-05,
      "loss": 0.0049,
      "step": 530
    },
    {
      "epoch": 0.12342857142857143,
      "grad_norm": 0.005171800963580608,
      "learning_rate": 4.984554455445545e-05,
      "loss": 0.0008,
      "step": 540
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 0.004690983798354864,
      "learning_rate": 4.980594059405941e-05,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.004238870460540056,
      "learning_rate": 4.9766336633663366e-05,
      "loss": 0.0005,
      "step": 560
    },
    {
      "epoch": 0.13028571428571428,
      "grad_norm": 0.004096199758350849,
      "learning_rate": 4.972673267326733e-05,
      "loss": 0.0008,
      "step": 570
    },
    {
      "epoch": 0.13257142857142856,
      "grad_norm": 0.006212291773408651,
      "learning_rate": 4.968712871287129e-05,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 0.13485714285714287,
      "grad_norm": 0.0034215152263641357,
      "learning_rate": 4.964752475247525e-05,
      "loss": 0.0004,
      "step": 590
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 0.0027924964670091867,
      "learning_rate": 4.960792079207921e-05,
      "loss": 0.0003,
      "step": 600
    },
    {
      "epoch": 0.13942857142857143,
      "grad_norm": 0.03003040701150894,
      "learning_rate": 4.9568316831683174e-05,
      "loss": 0.0004,
      "step": 610
    },
    {
      "epoch": 0.1417142857142857,
      "grad_norm": 0.03149987384676933,
      "learning_rate": 4.952871287128713e-05,
      "loss": 0.0313,
      "step": 620
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.09183958917856216,
      "learning_rate": 4.948910891089109e-05,
      "loss": 0.0008,
      "step": 630
    },
    {
      "epoch": 0.1462857142857143,
      "grad_norm": 0.0020682583563029766,
      "learning_rate": 4.944950495049505e-05,
      "loss": 0.0012,
      "step": 640
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 0.0020558235701173544,
      "learning_rate": 4.940990099009901e-05,
      "loss": 0.0002,
      "step": 650
    },
    {
      "epoch": 0.15085714285714286,
      "grad_norm": 0.0016657416708767414,
      "learning_rate": 4.9370297029702975e-05,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 0.15314285714285714,
      "grad_norm": 21.56111717224121,
      "learning_rate": 4.933069306930693e-05,
      "loss": 0.0438,
      "step": 670
    },
    {
      "epoch": 0.15542857142857142,
      "grad_norm": 0.017566990107297897,
      "learning_rate": 4.929108910891089e-05,
      "loss": 0.0003,
      "step": 680
    },
    {
      "epoch": 0.15771428571428572,
      "grad_norm": 0.0103385541588068,
      "learning_rate": 4.9251485148514854e-05,
      "loss": 0.0163,
      "step": 690
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.15241830050945282,
      "learning_rate": 4.921188118811881e-05,
      "loss": 0.0023,
      "step": 700
    },
    {
      "epoch": 0.16228571428571428,
      "grad_norm": 0.014665027149021626,
      "learning_rate": 4.9172277227722776e-05,
      "loss": 0.0038,
      "step": 710
    },
    {
      "epoch": 0.16457142857142856,
      "grad_norm": 0.004726789891719818,
      "learning_rate": 4.913267326732673e-05,
      "loss": 0.0013,
      "step": 720
    },
    {
      "epoch": 0.16685714285714287,
      "grad_norm": 0.004991322290152311,
      "learning_rate": 4.90930693069307e-05,
      "loss": 0.0003,
      "step": 730
    },
    {
      "epoch": 0.16914285714285715,
      "grad_norm": 0.002675709081813693,
      "learning_rate": 4.9053465346534655e-05,
      "loss": 0.0274,
      "step": 740
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.0468268059194088,
      "learning_rate": 4.901386138613861e-05,
      "loss": 0.0297,
      "step": 750
    },
    {
      "epoch": 0.1737142857142857,
      "grad_norm": 0.00420404551550746,
      "learning_rate": 4.8974257425742577e-05,
      "loss": 0.0031,
      "step": 760
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.005136961583048105,
      "learning_rate": 4.8934653465346534e-05,
      "loss": 0.0002,
      "step": 770
    },
    {
      "epoch": 0.1782857142857143,
      "grad_norm": 0.0025997755583375692,
      "learning_rate": 4.88950495049505e-05,
      "loss": 0.0009,
      "step": 780
    },
    {
      "epoch": 0.18057142857142858,
      "grad_norm": 0.00220744707621634,
      "learning_rate": 4.8855445544554456e-05,
      "loss": 0.0073,
      "step": 790
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 0.0013404014753177762,
      "learning_rate": 4.881584158415842e-05,
      "loss": 0.03,
      "step": 800
    },
    {
      "epoch": 0.18514285714285714,
      "grad_norm": 0.0029105290304869413,
      "learning_rate": 4.877623762376238e-05,
      "loss": 0.0011,
      "step": 810
    },
    {
      "epoch": 0.18742857142857142,
      "grad_norm": 0.0020631279330700636,
      "learning_rate": 4.8736633663366335e-05,
      "loss": 0.0191,
      "step": 820
    },
    {
      "epoch": 0.18971428571428572,
      "grad_norm": 2.6796741485595703,
      "learning_rate": 4.86970297029703e-05,
      "loss": 0.0865,
      "step": 830
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.030424712225794792,
      "learning_rate": 4.865742574257426e-05,
      "loss": 0.0004,
      "step": 840
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 0.004113452974706888,
      "learning_rate": 4.861782178217822e-05,
      "loss": 0.0131,
      "step": 850
    },
    {
      "epoch": 0.19657142857142856,
      "grad_norm": 0.0029011303558945656,
      "learning_rate": 4.857821782178218e-05,
      "loss": 0.0008,
      "step": 860
    },
    {
      "epoch": 0.19885714285714284,
      "grad_norm": 0.003438610816374421,
      "learning_rate": 4.853861386138614e-05,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 0.20114285714285715,
      "grad_norm": 0.008297131396830082,
      "learning_rate": 4.84990099009901e-05,
      "loss": 0.0002,
      "step": 880
    },
    {
      "epoch": 0.20342857142857143,
      "grad_norm": 0.002122537000104785,
      "learning_rate": 4.845940594059406e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 0.0028887600637972355,
      "learning_rate": 4.841980198019802e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.0022742561995983124,
      "learning_rate": 4.838019801980198e-05,
      "loss": 0.0552,
      "step": 910
    },
    {
      "epoch": 0.2102857142857143,
      "grad_norm": 0.002217639237642288,
      "learning_rate": 4.8340594059405944e-05,
      "loss": 0.0376,
      "step": 920
    },
    {
      "epoch": 0.21257142857142858,
      "grad_norm": 0.10412793606519699,
      "learning_rate": 4.83009900990099e-05,
      "loss": 0.0029,
      "step": 930
    },
    {
      "epoch": 0.21485714285714286,
      "grad_norm": 0.0035219083074480295,
      "learning_rate": 4.8261386138613866e-05,
      "loss": 0.0007,
      "step": 940
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 0.005495668854564428,
      "learning_rate": 4.822178217821782e-05,
      "loss": 0.0002,
      "step": 950
    },
    {
      "epoch": 0.21942857142857142,
      "grad_norm": 0.002059021033346653,
      "learning_rate": 4.818217821782178e-05,
      "loss": 0.0233,
      "step": 960
    },
    {
      "epoch": 0.22171428571428572,
      "grad_norm": 0.003924022428691387,
      "learning_rate": 4.8142574257425745e-05,
      "loss": 0.0032,
      "step": 970
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.003022597637027502,
      "learning_rate": 4.81029702970297e-05,
      "loss": 0.0003,
      "step": 980
    },
    {
      "epoch": 0.22628571428571428,
      "grad_norm": 0.004928122274577618,
      "learning_rate": 4.8063366336633667e-05,
      "loss": 0.0002,
      "step": 990
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.0025470752734690905,
      "learning_rate": 4.8023762376237624e-05,
      "loss": 0.0002,
      "step": 1000
    },
    {
      "epoch": 0.23085714285714284,
      "grad_norm": 0.002357641700655222,
      "learning_rate": 4.798415841584158e-05,
      "loss": 0.0011,
      "step": 1010
    },
    {
      "epoch": 0.23314285714285715,
      "grad_norm": 0.0019272230565547943,
      "learning_rate": 4.7944554455445546e-05,
      "loss": 0.0008,
      "step": 1020
    },
    {
      "epoch": 0.23542857142857143,
      "grad_norm": 0.003351072082296014,
      "learning_rate": 4.79049504950495e-05,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 0.2377142857142857,
      "grad_norm": 0.003102019429206848,
      "learning_rate": 4.786534653465347e-05,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.006654784549027681,
      "learning_rate": 4.7825742574257425e-05,
      "loss": 0.0001,
      "step": 1050
    },
    {
      "epoch": 0.2422857142857143,
      "grad_norm": 0.004374943673610687,
      "learning_rate": 4.778613861386139e-05,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 0.24457142857142858,
      "grad_norm": 0.0024389273021370173,
      "learning_rate": 4.774653465346535e-05,
      "loss": 0.0177,
      "step": 1070
    },
    {
      "epoch": 0.24685714285714286,
      "grad_norm": 0.0020346147939562798,
      "learning_rate": 4.7706930693069304e-05,
      "loss": 0.0009,
      "step": 1080
    },
    {
      "epoch": 0.24914285714285714,
      "grad_norm": 0.016218148171901703,
      "learning_rate": 4.766732673267327e-05,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 0.0013053570874035358,
      "learning_rate": 4.7627722772277226e-05,
      "loss": 0.0001,
      "step": 1100
    },
    {
      "epoch": 0.2537142857142857,
      "grad_norm": 0.563143789768219,
      "learning_rate": 4.758811881188119e-05,
      "loss": 0.0497,
      "step": 1110
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.0056235408410429955,
      "learning_rate": 4.754851485148515e-05,
      "loss": 0.0055,
      "step": 1120
    },
    {
      "epoch": 0.2582857142857143,
      "grad_norm": 0.006271315272897482,
      "learning_rate": 4.750891089108911e-05,
      "loss": 0.0122,
      "step": 1130
    },
    {
      "epoch": 0.26057142857142856,
      "grad_norm": 0.20714810490608215,
      "learning_rate": 4.746930693069307e-05,
      "loss": 0.0046,
      "step": 1140
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 0.006458823103457689,
      "learning_rate": 4.742970297029703e-05,
      "loss": 0.0191,
      "step": 1150
    },
    {
      "epoch": 0.2651428571428571,
      "grad_norm": 0.0070136976428329945,
      "learning_rate": 4.739009900990099e-05,
      "loss": 0.0027,
      "step": 1160
    },
    {
      "epoch": 0.2674285714285714,
      "grad_norm": 0.0023957006633281708,
      "learning_rate": 4.735049504950495e-05,
      "loss": 0.0006,
      "step": 1170
    },
    {
      "epoch": 0.26971428571428574,
      "grad_norm": 0.0016550136497244239,
      "learning_rate": 4.731089108910891e-05,
      "loss": 0.0012,
      "step": 1180
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.002548584481701255,
      "learning_rate": 4.727128712871287e-05,
      "loss": 0.0004,
      "step": 1190
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.0011632050154730678,
      "learning_rate": 4.7231683168316835e-05,
      "loss": 0.0009,
      "step": 1200
    },
    {
      "epoch": 0.2765714285714286,
      "grad_norm": 0.001574281370267272,
      "learning_rate": 4.719207920792079e-05,
      "loss": 0.0002,
      "step": 1210
    },
    {
      "epoch": 0.27885714285714286,
      "grad_norm": 0.0015945606864988804,
      "learning_rate": 4.715247524752475e-05,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 0.28114285714285714,
      "grad_norm": 0.0015280023217201233,
      "learning_rate": 4.7112871287128714e-05,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 0.2834285714285714,
      "grad_norm": 0.02201305702328682,
      "learning_rate": 4.707326732673267e-05,
      "loss": 0.0003,
      "step": 1240
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.001611037296243012,
      "learning_rate": 4.7033663366336636e-05,
      "loss": 0.0001,
      "step": 1250
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.0017322750063613057,
      "learning_rate": 4.699405940594059e-05,
      "loss": 0.0004,
      "step": 1260
    },
    {
      "epoch": 0.29028571428571426,
      "grad_norm": 0.002170282881706953,
      "learning_rate": 4.695445544554455e-05,
      "loss": 0.0001,
      "step": 1270
    },
    {
      "epoch": 0.2925714285714286,
      "grad_norm": 0.002346056280657649,
      "learning_rate": 4.6914851485148515e-05,
      "loss": 0.025,
      "step": 1280
    },
    {
      "epoch": 0.2948571428571429,
      "grad_norm": 0.002947199856862426,
      "learning_rate": 4.687524752475247e-05,
      "loss": 0.0001,
      "step": 1290
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 0.0010279183043166995,
      "learning_rate": 4.6835643564356444e-05,
      "loss": 0.0006,
      "step": 1300
    },
    {
      "epoch": 0.29942857142857143,
      "grad_norm": 0.001802814775146544,
      "learning_rate": 4.67960396039604e-05,
      "loss": 0.0186,
      "step": 1310
    },
    {
      "epoch": 0.3017142857142857,
      "grad_norm": 0.0009911153465509415,
      "learning_rate": 4.675643564356436e-05,
      "loss": 0.0122,
      "step": 1320
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.002679216442629695,
      "learning_rate": 4.671683168316832e-05,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 0.3062857142857143,
      "grad_norm": 0.0013237849343568087,
      "learning_rate": 4.667722772277228e-05,
      "loss": 0.0051,
      "step": 1340
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 0.0020110479090362787,
      "learning_rate": 4.6637623762376245e-05,
      "loss": 0.0001,
      "step": 1350
    },
    {
      "epoch": 0.31085714285714283,
      "grad_norm": 0.001203028834424913,
      "learning_rate": 4.65980198019802e-05,
      "loss": 0.0001,
      "step": 1360
    },
    {
      "epoch": 0.31314285714285717,
      "grad_norm": 0.002418173709884286,
      "learning_rate": 4.6558415841584166e-05,
      "loss": 0.046,
      "step": 1370
    },
    {
      "epoch": 0.31542857142857145,
      "grad_norm": 0.005143045447766781,
      "learning_rate": 4.6518811881188124e-05,
      "loss": 0.017,
      "step": 1380
    },
    {
      "epoch": 0.3177142857142857,
      "grad_norm": 0.004983610939234495,
      "learning_rate": 4.647920792079208e-05,
      "loss": 0.0017,
      "step": 1390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0017387024126946926,
      "learning_rate": 4.6439603960396045e-05,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 0.3222857142857143,
      "grad_norm": 0.2408410757780075,
      "learning_rate": 4.64e-05,
      "loss": 0.0075,
      "step": 1410
    },
    {
      "epoch": 0.32457142857142857,
      "grad_norm": 0.22317872941493988,
      "learning_rate": 4.636039603960397e-05,
      "loss": 0.0028,
      "step": 1420
    },
    {
      "epoch": 0.32685714285714285,
      "grad_norm": 0.002986358944326639,
      "learning_rate": 4.6320792079207925e-05,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 0.3291428571428571,
      "grad_norm": 0.0021399392280727625,
      "learning_rate": 4.628118811881189e-05,
      "loss": 0.0002,
      "step": 1440
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 0.0022506259847432375,
      "learning_rate": 4.6241584158415846e-05,
      "loss": 0.0001,
      "step": 1450
    },
    {
      "epoch": 0.33371428571428574,
      "grad_norm": 0.0014337883330881596,
      "learning_rate": 4.6201980198019804e-05,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.0014849398285150528,
      "learning_rate": 4.616237623762377e-05,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 0.3382857142857143,
      "grad_norm": 0.0131496237590909,
      "learning_rate": 4.6122772277227726e-05,
      "loss": 0.0434,
      "step": 1480
    },
    {
      "epoch": 0.3405714285714286,
      "grad_norm": 0.01043779868632555,
      "learning_rate": 4.608316831683169e-05,
      "loss": 0.0023,
      "step": 1490
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.0029359115287661552,
      "learning_rate": 4.604356435643565e-05,
      "loss": 0.0005,
      "step": 1500
    },
    {
      "epoch": 0.34514285714285714,
      "grad_norm": 0.04738129302859306,
      "learning_rate": 4.6003960396039605e-05,
      "loss": 0.0003,
      "step": 1510
    },
    {
      "epoch": 0.3474285714285714,
      "grad_norm": 0.0009493406396359205,
      "learning_rate": 4.596435643564357e-05,
      "loss": 0.0003,
      "step": 1520
    },
    {
      "epoch": 0.3497142857142857,
      "grad_norm": 0.001364892697893083,
      "learning_rate": 4.592475247524753e-05,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.001464797998778522,
      "learning_rate": 4.588514851485149e-05,
      "loss": 0.0003,
      "step": 1540
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 0.001016912516206503,
      "learning_rate": 4.584554455445545e-05,
      "loss": 0.0003,
      "step": 1550
    },
    {
      "epoch": 0.3565714285714286,
      "grad_norm": 0.0007655199733562768,
      "learning_rate": 4.580594059405941e-05,
      "loss": 0.0001,
      "step": 1560
    },
    {
      "epoch": 0.3588571428571429,
      "grad_norm": 0.0024258214980363846,
      "learning_rate": 4.576633663366337e-05,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 0.36114285714285715,
      "grad_norm": 0.014342102222144604,
      "learning_rate": 4.572673267326733e-05,
      "loss": 0.0003,
      "step": 1580
    },
    {
      "epoch": 0.36342857142857143,
      "grad_norm": 0.001169899245724082,
      "learning_rate": 4.568712871287129e-05,
      "loss": 0.0,
      "step": 1590
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 0.0011049897875636816,
      "learning_rate": 4.564752475247525e-05,
      "loss": 0.0304,
      "step": 1600
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.008682726882398129,
      "learning_rate": 4.5607920792079214e-05,
      "loss": 0.0009,
      "step": 1610
    },
    {
      "epoch": 0.3702857142857143,
      "grad_norm": 0.038094110786914825,
      "learning_rate": 4.556831683168317e-05,
      "loss": 0.0011,
      "step": 1620
    },
    {
      "epoch": 0.37257142857142855,
      "grad_norm": 0.0015474384417757392,
      "learning_rate": 4.5528712871287135e-05,
      "loss": 0.0001,
      "step": 1630
    },
    {
      "epoch": 0.37485714285714283,
      "grad_norm": 0.0017513138009235263,
      "learning_rate": 4.548910891089109e-05,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 0.0010260960552841425,
      "learning_rate": 4.544950495049505e-05,
      "loss": 0.0011,
      "step": 1650
    },
    {
      "epoch": 0.37942857142857145,
      "grad_norm": 0.002059569116681814,
      "learning_rate": 4.5409900990099015e-05,
      "loss": 0.0158,
      "step": 1660
    },
    {
      "epoch": 0.38171428571428573,
      "grad_norm": 0.002186578931286931,
      "learning_rate": 4.537029702970297e-05,
      "loss": 0.003,
      "step": 1670
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.009880454279482365,
      "learning_rate": 4.5330693069306936e-05,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 0.3862857142857143,
      "grad_norm": 0.0005294582224451005,
      "learning_rate": 4.5291089108910894e-05,
      "loss": 0.0001,
      "step": 1690
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 0.0015361221740022302,
      "learning_rate": 4.525148514851486e-05,
      "loss": 0.002,
      "step": 1700
    },
    {
      "epoch": 0.39085714285714285,
      "grad_norm": 0.0005673198029398918,
      "learning_rate": 4.5211881188118816e-05,
      "loss": 0.0029,
      "step": 1710
    },
    {
      "epoch": 0.3931428571428571,
      "grad_norm": 0.0008561941795051098,
      "learning_rate": 4.517227722772277e-05,
      "loss": 0.0017,
      "step": 1720
    },
    {
      "epoch": 0.3954285714285714,
      "grad_norm": 0.0018244660459458828,
      "learning_rate": 4.513267326732674e-05,
      "loss": 0.0007,
      "step": 1730
    },
    {
      "epoch": 0.3977142857142857,
      "grad_norm": 0.0331573411822319,
      "learning_rate": 4.5093069306930695e-05,
      "loss": 0.0008,
      "step": 1740
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0024659456685185432,
      "learning_rate": 4.505346534653466e-05,
      "loss": 0.0005,
      "step": 1750
    },
    {
      "epoch": 0.4022857142857143,
      "grad_norm": 0.0009627444087527692,
      "learning_rate": 4.501386138613862e-05,
      "loss": 0.0,
      "step": 1760
    },
    {
      "epoch": 0.4045714285714286,
      "grad_norm": 0.0006151202251203358,
      "learning_rate": 4.4974257425742574e-05,
      "loss": 0.0003,
      "step": 1770
    },
    {
      "epoch": 0.40685714285714286,
      "grad_norm": 0.001891900086775422,
      "learning_rate": 4.493465346534654e-05,
      "loss": 0.0002,
      "step": 1780
    },
    {
      "epoch": 0.40914285714285714,
      "grad_norm": 0.0008471852052025497,
      "learning_rate": 4.4895049504950496e-05,
      "loss": 0.0003,
      "step": 1790
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 0.01905054599046707,
      "learning_rate": 4.485544554455446e-05,
      "loss": 0.0001,
      "step": 1800
    },
    {
      "epoch": 0.4137142857142857,
      "grad_norm": 0.0004643963766284287,
      "learning_rate": 4.481584158415842e-05,
      "loss": 0.0002,
      "step": 1810
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.0012862428557127714,
      "learning_rate": 4.477623762376238e-05,
      "loss": 0.0,
      "step": 1820
    },
    {
      "epoch": 0.41828571428571426,
      "grad_norm": 0.0013772555394098163,
      "learning_rate": 4.473663366336634e-05,
      "loss": 0.0,
      "step": 1830
    },
    {
      "epoch": 0.4205714285714286,
      "grad_norm": 0.033862918615341187,
      "learning_rate": 4.46970297029703e-05,
      "loss": 0.0003,
      "step": 1840
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 0.0010736089898273349,
      "learning_rate": 4.465742574257426e-05,
      "loss": 0.0,
      "step": 1850
    },
    {
      "epoch": 0.42514285714285716,
      "grad_norm": 0.0011497102677822113,
      "learning_rate": 4.461782178217822e-05,
      "loss": 0.0,
      "step": 1860
    },
    {
      "epoch": 0.42742857142857144,
      "grad_norm": 1.164515495300293,
      "learning_rate": 4.457821782178218e-05,
      "loss": 0.0249,
      "step": 1870
    },
    {
      "epoch": 0.4297142857142857,
      "grad_norm": 0.0004428183601703495,
      "learning_rate": 4.453861386138614e-05,
      "loss": 0.0158,
      "step": 1880
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.0018021672731265426,
      "learning_rate": 4.4499009900990105e-05,
      "loss": 0.0001,
      "step": 1890
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 0.003135208273306489,
      "learning_rate": 4.445940594059406e-05,
      "loss": 0.002,
      "step": 1900
    },
    {
      "epoch": 0.43657142857142855,
      "grad_norm": 0.002180902985855937,
      "learning_rate": 4.441980198019802e-05,
      "loss": 0.0001,
      "step": 1910
    },
    {
      "epoch": 0.43885714285714283,
      "grad_norm": 0.00080820795847103,
      "learning_rate": 4.4380198019801984e-05,
      "loss": 0.0001,
      "step": 1920
    },
    {
      "epoch": 0.44114285714285717,
      "grad_norm": 0.0013026699889451265,
      "learning_rate": 4.434059405940594e-05,
      "loss": 0.002,
      "step": 1930
    },
    {
      "epoch": 0.44342857142857145,
      "grad_norm": 0.001665339688770473,
      "learning_rate": 4.4300990099009906e-05,
      "loss": 0.0032,
      "step": 1940
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 0.0018731160089373589,
      "learning_rate": 4.426138613861386e-05,
      "loss": 0.0012,
      "step": 1950
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.08799444139003754,
      "learning_rate": 4.422178217821783e-05,
      "loss": 0.001,
      "step": 1960
    },
    {
      "epoch": 0.4502857142857143,
      "grad_norm": 0.0022995241452008486,
      "learning_rate": 4.4182178217821785e-05,
      "loss": 0.0001,
      "step": 1970
    },
    {
      "epoch": 0.45257142857142857,
      "grad_norm": 0.0012515037087723613,
      "learning_rate": 4.414257425742574e-05,
      "loss": 0.0006,
      "step": 1980
    },
    {
      "epoch": 0.45485714285714285,
      "grad_norm": 0.0008082212880253792,
      "learning_rate": 4.410297029702971e-05,
      "loss": 0.0,
      "step": 1990
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.001860804040916264,
      "learning_rate": 4.4063366336633664e-05,
      "loss": 0.0175,
      "step": 2000
    },
    {
      "epoch": 0.4594285714285714,
      "grad_norm": 0.002701464341953397,
      "learning_rate": 4.402376237623763e-05,
      "loss": 0.0,
      "step": 2010
    },
    {
      "epoch": 0.4617142857142857,
      "grad_norm": 0.002839724998921156,
      "learning_rate": 4.3984158415841586e-05,
      "loss": 0.0001,
      "step": 2020
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.0012672852026298642,
      "learning_rate": 4.394455445544555e-05,
      "loss": 0.0019,
      "step": 2030
    },
    {
      "epoch": 0.4662857142857143,
      "grad_norm": 0.001792155671864748,
      "learning_rate": 4.390495049504951e-05,
      "loss": 0.0012,
      "step": 2040
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 0.001376780797727406,
      "learning_rate": 4.3865346534653465e-05,
      "loss": 0.001,
      "step": 2050
    },
    {
      "epoch": 0.47085714285714286,
      "grad_norm": 0.0008808704442344606,
      "learning_rate": 4.382574257425743e-05,
      "loss": 0.0,
      "step": 2060
    },
    {
      "epoch": 0.47314285714285714,
      "grad_norm": 0.0005489136674441397,
      "learning_rate": 4.378613861386139e-05,
      "loss": 0.0026,
      "step": 2070
    },
    {
      "epoch": 0.4754285714285714,
      "grad_norm": 0.001363328192383051,
      "learning_rate": 4.374653465346535e-05,
      "loss": 0.0,
      "step": 2080
    },
    {
      "epoch": 0.4777142857142857,
      "grad_norm": 0.0009495064150542021,
      "learning_rate": 4.370693069306931e-05,
      "loss": 0.0007,
      "step": 2090
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0005960938869975507,
      "learning_rate": 4.3667326732673266e-05,
      "loss": 0.0006,
      "step": 2100
    },
    {
      "epoch": 0.48228571428571426,
      "grad_norm": 0.054451435804367065,
      "learning_rate": 4.362772277227723e-05,
      "loss": 0.0009,
      "step": 2110
    },
    {
      "epoch": 0.4845714285714286,
      "grad_norm": 0.0007320178556255996,
      "learning_rate": 4.358811881188119e-05,
      "loss": 0.0001,
      "step": 2120
    },
    {
      "epoch": 0.4868571428571429,
      "grad_norm": 0.0004123291582800448,
      "learning_rate": 4.354851485148515e-05,
      "loss": 0.0,
      "step": 2130
    },
    {
      "epoch": 0.48914285714285716,
      "grad_norm": 0.0004079568898305297,
      "learning_rate": 4.350891089108911e-05,
      "loss": 0.0,
      "step": 2140
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 0.0008064362918958068,
      "learning_rate": 4.3469306930693074e-05,
      "loss": 0.0005,
      "step": 2150
    },
    {
      "epoch": 0.4937142857142857,
      "grad_norm": 0.0008090861956588924,
      "learning_rate": 4.342970297029703e-05,
      "loss": 0.0004,
      "step": 2160
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.0009937467984855175,
      "learning_rate": 4.339009900990099e-05,
      "loss": 0.0196,
      "step": 2170
    },
    {
      "epoch": 0.4982857142857143,
      "grad_norm": 0.0010970880975946784,
      "learning_rate": 4.335049504950495e-05,
      "loss": 0.001,
      "step": 2180
    },
    {
      "epoch": 0.5005714285714286,
      "grad_norm": 0.048034630715847015,
      "learning_rate": 4.331089108910891e-05,
      "loss": 0.0004,
      "step": 2190
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 0.006678285542875528,
      "learning_rate": 4.3271287128712875e-05,
      "loss": 0.001,
      "step": 2200
    },
    {
      "epoch": 0.5051428571428571,
      "grad_norm": 0.0013587347930297256,
      "learning_rate": 4.323168316831683e-05,
      "loss": 0.0018,
      "step": 2210
    },
    {
      "epoch": 0.5074285714285715,
      "grad_norm": 0.0005547335604205728,
      "learning_rate": 4.31920792079208e-05,
      "loss": 0.0,
      "step": 2220
    },
    {
      "epoch": 0.5097142857142857,
      "grad_norm": 0.0005216862191446126,
      "learning_rate": 4.3152475247524754e-05,
      "loss": 0.0007,
      "step": 2230
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.00036701015778817236,
      "learning_rate": 4.311287128712871e-05,
      "loss": 0.0,
      "step": 2240
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.000849829229991883,
      "learning_rate": 4.3073267326732676e-05,
      "loss": 0.0157,
      "step": 2250
    },
    {
      "epoch": 0.5165714285714286,
      "grad_norm": 0.0003231181181035936,
      "learning_rate": 4.303366336633663e-05,
      "loss": 0.0,
      "step": 2260
    },
    {
      "epoch": 0.5188571428571429,
      "grad_norm": 0.09738603234291077,
      "learning_rate": 4.29940594059406e-05,
      "loss": 0.0011,
      "step": 2270
    },
    {
      "epoch": 0.5211428571428571,
      "grad_norm": 0.001366058480925858,
      "learning_rate": 4.2954455445544555e-05,
      "loss": 0.0,
      "step": 2280
    },
    {
      "epoch": 0.5234285714285715,
      "grad_norm": 0.001120383501984179,
      "learning_rate": 4.291485148514852e-05,
      "loss": 0.0129,
      "step": 2290
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 0.0013261206913739443,
      "learning_rate": 4.287524752475248e-05,
      "loss": 0.0014,
      "step": 2300
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.00038613888318650424,
      "learning_rate": 4.2835643564356434e-05,
      "loss": 0.0001,
      "step": 2310
    },
    {
      "epoch": 0.5302857142857142,
      "grad_norm": 0.0008134216768667102,
      "learning_rate": 4.27960396039604e-05,
      "loss": 0.0,
      "step": 2320
    },
    {
      "epoch": 0.5325714285714286,
      "grad_norm": 0.0006707623833790421,
      "learning_rate": 4.2756435643564356e-05,
      "loss": 0.0021,
      "step": 2330
    },
    {
      "epoch": 0.5348571428571428,
      "grad_norm": 0.0014472167240455747,
      "learning_rate": 4.271683168316832e-05,
      "loss": 0.0,
      "step": 2340
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 0.0008119536214508116,
      "learning_rate": 4.267722772277228e-05,
      "loss": 0.0,
      "step": 2350
    },
    {
      "epoch": 0.5394285714285715,
      "grad_norm": 0.0006978416931815445,
      "learning_rate": 4.2637623762376235e-05,
      "loss": 0.0001,
      "step": 2360
    },
    {
      "epoch": 0.5417142857142857,
      "grad_norm": 0.0004599886015057564,
      "learning_rate": 4.25980198019802e-05,
      "loss": 0.0,
      "step": 2370
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.0073822783306241035,
      "learning_rate": 4.255841584158416e-05,
      "loss": 0.0001,
      "step": 2380
    },
    {
      "epoch": 0.5462857142857143,
      "grad_norm": 0.0013235409278422594,
      "learning_rate": 4.251881188118812e-05,
      "loss": 0.0,
      "step": 2390
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.0008773750741966069,
      "learning_rate": 4.247920792079208e-05,
      "loss": 0.0009,
      "step": 2400
    },
    {
      "epoch": 0.5508571428571428,
      "grad_norm": 0.0006324829300865531,
      "learning_rate": 4.243960396039604e-05,
      "loss": 0.0236,
      "step": 2410
    },
    {
      "epoch": 0.5531428571428572,
      "grad_norm": 0.000875689962413162,
      "learning_rate": 4.24e-05,
      "loss": 0.0128,
      "step": 2420
    },
    {
      "epoch": 0.5554285714285714,
      "grad_norm": 0.0005372112500481308,
      "learning_rate": 4.236039603960396e-05,
      "loss": 0.0,
      "step": 2430
    },
    {
      "epoch": 0.5577142857142857,
      "grad_norm": 0.02284954860806465,
      "learning_rate": 4.232079207920792e-05,
      "loss": 0.0029,
      "step": 2440
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.0005593867390416563,
      "learning_rate": 4.228118811881188e-05,
      "loss": 0.0,
      "step": 2450
    },
    {
      "epoch": 0.5622857142857143,
      "grad_norm": 0.0022081707138568163,
      "learning_rate": 4.2241584158415844e-05,
      "loss": 0.012,
      "step": 2460
    },
    {
      "epoch": 0.5645714285714286,
      "grad_norm": 0.001097100437618792,
      "learning_rate": 4.22019801980198e-05,
      "loss": 0.0014,
      "step": 2470
    },
    {
      "epoch": 0.5668571428571428,
      "grad_norm": 0.0007757693529129028,
      "learning_rate": 4.2162376237623766e-05,
      "loss": 0.0002,
      "step": 2480
    },
    {
      "epoch": 0.5691428571428572,
      "grad_norm": 3.8182692527770996,
      "learning_rate": 4.212277227722772e-05,
      "loss": 0.0507,
      "step": 2490
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.006022223737090826,
      "learning_rate": 4.208316831683168e-05,
      "loss": 0.0039,
      "step": 2500
    },
    {
      "epoch": 0.5737142857142857,
      "grad_norm": 0.002848268486559391,
      "learning_rate": 4.2043564356435645e-05,
      "loss": 0.0071,
      "step": 2510
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.002625061431899667,
      "learning_rate": 4.20039603960396e-05,
      "loss": 0.0128,
      "step": 2520
    },
    {
      "epoch": 0.5782857142857143,
      "grad_norm": 0.5059270858764648,
      "learning_rate": 4.196435643564357e-05,
      "loss": 0.0096,
      "step": 2530
    },
    {
      "epoch": 0.5805714285714285,
      "grad_norm": 0.0024712784215807915,
      "learning_rate": 4.1924752475247524e-05,
      "loss": 0.0049,
      "step": 2540
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.09777244180440903,
      "learning_rate": 4.188514851485149e-05,
      "loss": 0.0011,
      "step": 2550
    },
    {
      "epoch": 0.5851428571428572,
      "grad_norm": 0.07169678807258606,
      "learning_rate": 4.1845544554455446e-05,
      "loss": 0.0513,
      "step": 2560
    },
    {
      "epoch": 0.5874285714285714,
      "grad_norm": 0.011567692272365093,
      "learning_rate": 4.1805940594059404e-05,
      "loss": 0.0015,
      "step": 2570
    },
    {
      "epoch": 0.5897142857142857,
      "grad_norm": 0.010144650936126709,
      "learning_rate": 4.176633663366337e-05,
      "loss": 0.0005,
      "step": 2580
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.0011210968950763345,
      "learning_rate": 4.1726732673267325e-05,
      "loss": 0.0016,
      "step": 2590
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.003865746781229973,
      "learning_rate": 4.168712871287129e-05,
      "loss": 0.0185,
      "step": 2600
    },
    {
      "epoch": 0.5965714285714285,
      "grad_norm": 0.0016661230474710464,
      "learning_rate": 4.164752475247525e-05,
      "loss": 0.0009,
      "step": 2610
    },
    {
      "epoch": 0.5988571428571429,
      "grad_norm": 0.0015262848464772105,
      "learning_rate": 4.160792079207921e-05,
      "loss": 0.0001,
      "step": 2620
    },
    {
      "epoch": 0.6011428571428571,
      "grad_norm": 0.0013546068221330643,
      "learning_rate": 4.156831683168317e-05,
      "loss": 0.001,
      "step": 2630
    },
    {
      "epoch": 0.6034285714285714,
      "grad_norm": 0.004547026939690113,
      "learning_rate": 4.1528712871287126e-05,
      "loss": 0.0001,
      "step": 2640
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 0.0025968262925744057,
      "learning_rate": 4.148910891089109e-05,
      "loss": 0.0001,
      "step": 2650
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.09512857347726822,
      "learning_rate": 4.144950495049505e-05,
      "loss": 0.0026,
      "step": 2660
    },
    {
      "epoch": 0.6102857142857143,
      "grad_norm": 0.0011542949359863997,
      "learning_rate": 4.140990099009901e-05,
      "loss": 0.0001,
      "step": 2670
    },
    {
      "epoch": 0.6125714285714285,
      "grad_norm": 0.0006223244126886129,
      "learning_rate": 4.137029702970297e-05,
      "loss": 0.0001,
      "step": 2680
    },
    {
      "epoch": 0.6148571428571429,
      "grad_norm": 0.0017780462512746453,
      "learning_rate": 4.133069306930693e-05,
      "loss": 0.0175,
      "step": 2690
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 0.0014131146017462015,
      "learning_rate": 4.129108910891089e-05,
      "loss": 0.0126,
      "step": 2700
    },
    {
      "epoch": 0.6194285714285714,
      "grad_norm": 0.0022601259406656027,
      "learning_rate": 4.125148514851485e-05,
      "loss": 0.0001,
      "step": 2710
    },
    {
      "epoch": 0.6217142857142857,
      "grad_norm": 0.0023400166537612677,
      "learning_rate": 4.121188118811881e-05,
      "loss": 0.0036,
      "step": 2720
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.002588600618764758,
      "learning_rate": 4.117227722772277e-05,
      "loss": 0.0017,
      "step": 2730
    },
    {
      "epoch": 0.6262857142857143,
      "grad_norm": 0.0004981934325769544,
      "learning_rate": 4.1132673267326735e-05,
      "loss": 0.0026,
      "step": 2740
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.10871714353561401,
      "learning_rate": 4.109306930693069e-05,
      "loss": 0.0024,
      "step": 2750
    },
    {
      "epoch": 0.6308571428571429,
      "grad_norm": 0.001148095354437828,
      "learning_rate": 4.105346534653465e-05,
      "loss": 0.0009,
      "step": 2760
    },
    {
      "epoch": 0.6331428571428571,
      "grad_norm": 0.7171735763549805,
      "learning_rate": 4.1013861386138614e-05,
      "loss": 0.0154,
      "step": 2770
    },
    {
      "epoch": 0.6354285714285715,
      "grad_norm": 0.0012119758175686002,
      "learning_rate": 4.097425742574257e-05,
      "loss": 0.0013,
      "step": 2780
    },
    {
      "epoch": 0.6377142857142857,
      "grad_norm": 0.0007291315123438835,
      "learning_rate": 4.0934653465346536e-05,
      "loss": 0.0022,
      "step": 2790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0003399699635338038,
      "learning_rate": 4.0895049504950494e-05,
      "loss": 0.0011,
      "step": 2800
    },
    {
      "epoch": 0.6422857142857142,
      "grad_norm": 0.0012812403729185462,
      "learning_rate": 4.085544554455446e-05,
      "loss": 0.0018,
      "step": 2810
    },
    {
      "epoch": 0.6445714285714286,
      "grad_norm": 0.0006587139214389026,
      "learning_rate": 4.0815841584158415e-05,
      "loss": 0.0016,
      "step": 2820
    },
    {
      "epoch": 0.6468571428571429,
      "grad_norm": 0.0027361661195755005,
      "learning_rate": 4.077623762376237e-05,
      "loss": 0.0681,
      "step": 2830
    },
    {
      "epoch": 0.6491428571428571,
      "grad_norm": 0.010690193623304367,
      "learning_rate": 4.073663366336634e-05,
      "loss": 0.0002,
      "step": 2840
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 0.005793983582407236,
      "learning_rate": 4.0697029702970295e-05,
      "loss": 0.0012,
      "step": 2850
    },
    {
      "epoch": 0.6537142857142857,
      "grad_norm": 0.0018352215411141515,
      "learning_rate": 4.065742574257426e-05,
      "loss": 0.0004,
      "step": 2860
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.00834899116307497,
      "learning_rate": 4.061782178217822e-05,
      "loss": 0.0142,
      "step": 2870
    },
    {
      "epoch": 0.6582857142857143,
      "grad_norm": 0.0063244979828596115,
      "learning_rate": 4.057821782178218e-05,
      "loss": 0.0015,
      "step": 2880
    },
    {
      "epoch": 0.6605714285714286,
      "grad_norm": 0.11705222725868225,
      "learning_rate": 4.0538613861386145e-05,
      "loss": 0.0027,
      "step": 2890
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 0.006225711666047573,
      "learning_rate": 4.04990099009901e-05,
      "loss": 0.0039,
      "step": 2900
    },
    {
      "epoch": 0.6651428571428571,
      "grad_norm": 0.0020309346728026867,
      "learning_rate": 4.0459405940594067e-05,
      "loss": 0.0001,
      "step": 2910
    },
    {
      "epoch": 0.6674285714285715,
      "grad_norm": 0.04748058691620827,
      "learning_rate": 4.0419801980198024e-05,
      "loss": 0.0024,
      "step": 2920
    },
    {
      "epoch": 0.6697142857142857,
      "grad_norm": 0.001783704268746078,
      "learning_rate": 4.038019801980198e-05,
      "loss": 0.0001,
      "step": 2930
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.053426653146743774,
      "learning_rate": 4.0340594059405946e-05,
      "loss": 0.0004,
      "step": 2940
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 0.05458895489573479,
      "learning_rate": 4.03009900990099e-05,
      "loss": 0.0008,
      "step": 2950
    },
    {
      "epoch": 0.6765714285714286,
      "grad_norm": 0.0017231979873031378,
      "learning_rate": 4.026138613861387e-05,
      "loss": 0.0003,
      "step": 2960
    },
    {
      "epoch": 0.6788571428571428,
      "grad_norm": 0.0017737586749717593,
      "learning_rate": 4.0221782178217825e-05,
      "loss": 0.0179,
      "step": 2970
    },
    {
      "epoch": 0.6811428571428572,
      "grad_norm": 0.002143662190064788,
      "learning_rate": 4.018217821782179e-05,
      "loss": 0.0009,
      "step": 2980
    },
    {
      "epoch": 0.6834285714285714,
      "grad_norm": 0.0009773877682164311,
      "learning_rate": 4.014257425742575e-05,
      "loss": 0.0001,
      "step": 2990
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.0013399667805060744,
      "learning_rate": 4.0102970297029704e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.0011501560220494866,
      "learning_rate": 4.006336633663367e-05,
      "loss": 0.0005,
      "step": 3010
    },
    {
      "epoch": 0.6902857142857143,
      "grad_norm": 0.0024527888745069504,
      "learning_rate": 4.0023762376237626e-05,
      "loss": 0.0001,
      "step": 3020
    },
    {
      "epoch": 0.6925714285714286,
      "grad_norm": 0.04644615948200226,
      "learning_rate": 3.998415841584159e-05,
      "loss": 0.013,
      "step": 3030
    },
    {
      "epoch": 0.6948571428571428,
      "grad_norm": 0.0020555874798446894,
      "learning_rate": 3.994455445544555e-05,
      "loss": 0.0015,
      "step": 3040
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 0.06796196848154068,
      "learning_rate": 3.990495049504951e-05,
      "loss": 0.0032,
      "step": 3050
    },
    {
      "epoch": 0.6994285714285714,
      "grad_norm": 0.0013895891606807709,
      "learning_rate": 3.986534653465347e-05,
      "loss": 0.0005,
      "step": 3060
    },
    {
      "epoch": 0.7017142857142857,
      "grad_norm": 0.00048348240670748055,
      "learning_rate": 3.982574257425743e-05,
      "loss": 0.0167,
      "step": 3070
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.0021802587434649467,
      "learning_rate": 3.978613861386139e-05,
      "loss": 0.0013,
      "step": 3080
    },
    {
      "epoch": 0.7062857142857143,
      "grad_norm": 0.0003567376115825027,
      "learning_rate": 3.974653465346535e-05,
      "loss": 0.0013,
      "step": 3090
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 0.0014394079335033894,
      "learning_rate": 3.970693069306931e-05,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 0.7108571428571429,
      "grad_norm": 0.000544907758012414,
      "learning_rate": 3.966732673267327e-05,
      "loss": 0.0002,
      "step": 3110
    },
    {
      "epoch": 0.7131428571428572,
      "grad_norm": 0.061933938413858414,
      "learning_rate": 3.9627722772277235e-05,
      "loss": 0.001,
      "step": 3120
    },
    {
      "epoch": 0.7154285714285714,
      "grad_norm": 0.09075701236724854,
      "learning_rate": 3.958811881188119e-05,
      "loss": 0.0009,
      "step": 3130
    },
    {
      "epoch": 0.7177142857142857,
      "grad_norm": 0.08333854377269745,
      "learning_rate": 3.954851485148515e-05,
      "loss": 0.0013,
      "step": 3140
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.001299364841543138,
      "learning_rate": 3.9508910891089114e-05,
      "loss": 0.0,
      "step": 3150
    },
    {
      "epoch": 0.7222857142857143,
      "grad_norm": 0.0013733268715441227,
      "learning_rate": 3.946930693069307e-05,
      "loss": 0.0545,
      "step": 3160
    },
    {
      "epoch": 0.7245714285714285,
      "grad_norm": 0.7380452752113342,
      "learning_rate": 3.9429702970297036e-05,
      "loss": 0.0131,
      "step": 3170
    },
    {
      "epoch": 0.7268571428571429,
      "grad_norm": 0.006720860488712788,
      "learning_rate": 3.939009900990099e-05,
      "loss": 0.0002,
      "step": 3180
    },
    {
      "epoch": 0.7291428571428571,
      "grad_norm": 0.010495467111468315,
      "learning_rate": 3.935049504950495e-05,
      "loss": 0.0014,
      "step": 3190
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 0.11178581416606903,
      "learning_rate": 3.9310891089108915e-05,
      "loss": 0.0008,
      "step": 3200
    },
    {
      "epoch": 0.7337142857142858,
      "grad_norm": 0.004828216973692179,
      "learning_rate": 3.927128712871287e-05,
      "loss": 0.0002,
      "step": 3210
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.0062202769331634045,
      "learning_rate": 3.923168316831684e-05,
      "loss": 0.0031,
      "step": 3220
    },
    {
      "epoch": 0.7382857142857143,
      "grad_norm": 0.004390725400298834,
      "learning_rate": 3.9192079207920794e-05,
      "loss": 0.0015,
      "step": 3230
    },
    {
      "epoch": 0.7405714285714285,
      "grad_norm": 0.0035754467826336622,
      "learning_rate": 3.915247524752476e-05,
      "loss": 0.0002,
      "step": 3240
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.0014501884579658508,
      "learning_rate": 3.9112871287128716e-05,
      "loss": 0.0001,
      "step": 3250
    },
    {
      "epoch": 0.7451428571428571,
      "grad_norm": 0.0016630555037409067,
      "learning_rate": 3.9073267326732674e-05,
      "loss": 0.0002,
      "step": 3260
    },
    {
      "epoch": 0.7474285714285714,
      "grad_norm": 0.0027461370918899775,
      "learning_rate": 3.903366336633664e-05,
      "loss": 0.0008,
      "step": 3270
    },
    {
      "epoch": 0.7497142857142857,
      "grad_norm": 0.017574306577444077,
      "learning_rate": 3.8994059405940595e-05,
      "loss": 0.0147,
      "step": 3280
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5293452143669128,
      "learning_rate": 3.895445544554456e-05,
      "loss": 0.0119,
      "step": 3290
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 0.0018382887355983257,
      "learning_rate": 3.891485148514852e-05,
      "loss": 0.0002,
      "step": 3300
    },
    {
      "epoch": 0.7565714285714286,
      "grad_norm": 0.0031689235474914312,
      "learning_rate": 3.887524752475248e-05,
      "loss": 0.0098,
      "step": 3310
    },
    {
      "epoch": 0.7588571428571429,
      "grad_norm": 0.0017568935872986913,
      "learning_rate": 3.883564356435644e-05,
      "loss": 0.0024,
      "step": 3320
    },
    {
      "epoch": 0.7611428571428571,
      "grad_norm": 0.021043362095952034,
      "learning_rate": 3.8796039603960396e-05,
      "loss": 0.0001,
      "step": 3330
    },
    {
      "epoch": 0.7634285714285715,
      "grad_norm": 0.0016759580466896296,
      "learning_rate": 3.875643564356436e-05,
      "loss": 0.0024,
      "step": 3340
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 0.0017648100620135665,
      "learning_rate": 3.871683168316832e-05,
      "loss": 0.0002,
      "step": 3350
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.0018864237936213613,
      "learning_rate": 3.867722772277228e-05,
      "loss": 0.0078,
      "step": 3360
    },
    {
      "epoch": 0.7702857142857142,
      "grad_norm": 0.0023485554847866297,
      "learning_rate": 3.863762376237624e-05,
      "loss": 0.0001,
      "step": 3370
    },
    {
      "epoch": 0.7725714285714286,
      "grad_norm": 0.0016027754172682762,
      "learning_rate": 3.8598019801980204e-05,
      "loss": 0.0028,
      "step": 3380
    },
    {
      "epoch": 0.7748571428571429,
      "grad_norm": 0.0007346588536165655,
      "learning_rate": 3.855841584158416e-05,
      "loss": 0.0001,
      "step": 3390
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 0.001571694971062243,
      "learning_rate": 3.851881188118812e-05,
      "loss": 0.0001,
      "step": 3400
    },
    {
      "epoch": 0.7794285714285715,
      "grad_norm": 0.0025472959969192743,
      "learning_rate": 3.847920792079208e-05,
      "loss": 0.0001,
      "step": 3410
    },
    {
      "epoch": 0.7817142857142857,
      "grad_norm": 0.001617135712876916,
      "learning_rate": 3.843960396039604e-05,
      "loss": 0.0024,
      "step": 3420
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.24669590592384338,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0062,
      "step": 3430
    },
    {
      "epoch": 0.7862857142857143,
      "grad_norm": 0.001688498887233436,
      "learning_rate": 3.836039603960396e-05,
      "loss": 0.0001,
      "step": 3440
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.0011812025913968682,
      "learning_rate": 3.832079207920792e-05,
      "loss": 0.0001,
      "step": 3450
    },
    {
      "epoch": 0.7908571428571428,
      "grad_norm": 0.39733609557151794,
      "learning_rate": 3.8281188118811884e-05,
      "loss": 0.0093,
      "step": 3460
    },
    {
      "epoch": 0.7931428571428571,
      "grad_norm": 0.0010077526094391942,
      "learning_rate": 3.824158415841584e-05,
      "loss": 0.0001,
      "step": 3470
    },
    {
      "epoch": 0.7954285714285714,
      "grad_norm": 0.0009374109213240445,
      "learning_rate": 3.8201980198019806e-05,
      "loss": 0.0015,
      "step": 3480
    },
    {
      "epoch": 0.7977142857142857,
      "grad_norm": 0.0014667181530967355,
      "learning_rate": 3.8162376237623764e-05,
      "loss": 0.0015,
      "step": 3490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0009686101111583412,
      "learning_rate": 3.812277227722773e-05,
      "loss": 0.0017,
      "step": 3500
    },
    {
      "epoch": 0.8022857142857143,
      "grad_norm": 0.0017543146386742592,
      "learning_rate": 3.8083168316831685e-05,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 0.8045714285714286,
      "grad_norm": 0.0007888033869676292,
      "learning_rate": 3.804356435643564e-05,
      "loss": 0.0013,
      "step": 3520
    },
    {
      "epoch": 0.8068571428571428,
      "grad_norm": 0.00035996761289425194,
      "learning_rate": 3.800396039603961e-05,
      "loss": 0.0,
      "step": 3530
    },
    {
      "epoch": 0.8091428571428572,
      "grad_norm": 0.0020344676449894905,
      "learning_rate": 3.7964356435643565e-05,
      "loss": 0.0001,
      "step": 3540
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 0.000509807316120714,
      "learning_rate": 3.792475247524753e-05,
      "loss": 0.0,
      "step": 3550
    },
    {
      "epoch": 0.8137142857142857,
      "grad_norm": 0.00035945457057096064,
      "learning_rate": 3.7885148514851486e-05,
      "loss": 0.011,
      "step": 3560
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.0014420287916436791,
      "learning_rate": 3.784554455445545e-05,
      "loss": 0.0,
      "step": 3570
    },
    {
      "epoch": 0.8182857142857143,
      "grad_norm": 0.0011665988713502884,
      "learning_rate": 3.780594059405941e-05,
      "loss": 0.0022,
      "step": 3580
    },
    {
      "epoch": 0.8205714285714286,
      "grad_norm": 0.0015281110536307096,
      "learning_rate": 3.7766336633663365e-05,
      "loss": 0.0039,
      "step": 3590
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.0008338265470229089,
      "learning_rate": 3.772673267326733e-05,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 0.8251428571428572,
      "grad_norm": 0.0012142224004492164,
      "learning_rate": 3.768712871287129e-05,
      "loss": 0.0013,
      "step": 3610
    },
    {
      "epoch": 0.8274285714285714,
      "grad_norm": 0.0002613971591927111,
      "learning_rate": 3.764752475247525e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 0.8297142857142857,
      "grad_norm": 0.00024997457512654364,
      "learning_rate": 3.760792079207921e-05,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.001766803557984531,
      "learning_rate": 3.756831683168317e-05,
      "loss": 0.0012,
      "step": 3640
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 0.0010395693825557828,
      "learning_rate": 3.752871287128713e-05,
      "loss": 0.001,
      "step": 3650
    },
    {
      "epoch": 0.8365714285714285,
      "grad_norm": 0.0009130109683610499,
      "learning_rate": 3.748910891089109e-05,
      "loss": 0.0128,
      "step": 3660
    },
    {
      "epoch": 0.8388571428571429,
      "grad_norm": 0.0014981023268774152,
      "learning_rate": 3.744950495049505e-05,
      "loss": 0.0008,
      "step": 3670
    },
    {
      "epoch": 0.8411428571428572,
      "grad_norm": 0.0004759600851684809,
      "learning_rate": 3.740990099009901e-05,
      "loss": 0.0007,
      "step": 3680
    },
    {
      "epoch": 0.8434285714285714,
      "grad_norm": 0.0008679016609676182,
      "learning_rate": 3.7370297029702974e-05,
      "loss": 0.0004,
      "step": 3690
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 0.00016777971177361906,
      "learning_rate": 3.733069306930693e-05,
      "loss": 0.0124,
      "step": 3700
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.0004313170211389661,
      "learning_rate": 3.7291089108910896e-05,
      "loss": 0.0022,
      "step": 3710
    },
    {
      "epoch": 0.8502857142857143,
      "grad_norm": 0.0009103118209168315,
      "learning_rate": 3.7251485148514853e-05,
      "loss": 0.0004,
      "step": 3720
    },
    {
      "epoch": 0.8525714285714285,
      "grad_norm": 0.0004922967636957765,
      "learning_rate": 3.721188118811881e-05,
      "loss": 0.0002,
      "step": 3730
    },
    {
      "epoch": 0.8548571428571429,
      "grad_norm": 0.000526546617038548,
      "learning_rate": 3.7172277227722775e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.00038375696749426425,
      "learning_rate": 3.713267326732673e-05,
      "loss": 0.0013,
      "step": 3750
    },
    {
      "epoch": 0.8594285714285714,
      "grad_norm": 0.00031165574910119176,
      "learning_rate": 3.70930693069307e-05,
      "loss": 0.0,
      "step": 3760
    },
    {
      "epoch": 0.8617142857142858,
      "grad_norm": 0.0008191322558559477,
      "learning_rate": 3.7053465346534654e-05,
      "loss": 0.0,
      "step": 3770
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.0005847761640325189,
      "learning_rate": 3.701386138613861e-05,
      "loss": 0.0001,
      "step": 3780
    },
    {
      "epoch": 0.8662857142857143,
      "grad_norm": 0.0007980658556334674,
      "learning_rate": 3.6974257425742576e-05,
      "loss": 0.0,
      "step": 3790
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 0.0012591974809765816,
      "learning_rate": 3.6934653465346534e-05,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 0.8708571428571429,
      "grad_norm": 0.003380856476724148,
      "learning_rate": 3.68950495049505e-05,
      "loss": 0.0007,
      "step": 3810
    },
    {
      "epoch": 0.8731428571428571,
      "grad_norm": 0.025510553270578384,
      "learning_rate": 3.6855445544554455e-05,
      "loss": 0.0175,
      "step": 3820
    },
    {
      "epoch": 0.8754285714285714,
      "grad_norm": 0.0008868165896274149,
      "learning_rate": 3.681584158415842e-05,
      "loss": 0.0001,
      "step": 3830
    },
    {
      "epoch": 0.8777142857142857,
      "grad_norm": 0.0003695141931530088,
      "learning_rate": 3.677623762376238e-05,
      "loss": 0.0017,
      "step": 3840
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.011360072530806065,
      "learning_rate": 3.6736633663366335e-05,
      "loss": 0.0572,
      "step": 3850
    },
    {
      "epoch": 0.8822857142857143,
      "grad_norm": 0.00509734358638525,
      "learning_rate": 3.66970297029703e-05,
      "loss": 0.0708,
      "step": 3860
    },
    {
      "epoch": 0.8845714285714286,
      "grad_norm": 0.4414825439453125,
      "learning_rate": 3.6657425742574256e-05,
      "loss": 0.0113,
      "step": 3870
    },
    {
      "epoch": 0.8868571428571429,
      "grad_norm": 0.003007824532687664,
      "learning_rate": 3.661782178217822e-05,
      "loss": 0.0001,
      "step": 3880
    },
    {
      "epoch": 0.8891428571428571,
      "grad_norm": 0.002509098267182708,
      "learning_rate": 3.657821782178218e-05,
      "loss": 0.0001,
      "step": 3890
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 0.0031461373437196016,
      "learning_rate": 3.653861386138614e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 0.8937142857142857,
      "grad_norm": 0.002433429006487131,
      "learning_rate": 3.64990099009901e-05,
      "loss": 0.0166,
      "step": 3910
    },
    {
      "epoch": 0.896,
      "grad_norm": 73.3879623413086,
      "learning_rate": 3.645940594059406e-05,
      "loss": 0.0495,
      "step": 3920
    },
    {
      "epoch": 0.8982857142857142,
      "grad_norm": 0.41999804973602295,
      "learning_rate": 3.641980198019802e-05,
      "loss": 0.0264,
      "step": 3930
    },
    {
      "epoch": 0.9005714285714286,
      "grad_norm": 0.020433735102415085,
      "learning_rate": 3.638019801980198e-05,
      "loss": 0.0007,
      "step": 3940
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 0.007631801534444094,
      "learning_rate": 3.6340594059405943e-05,
      "loss": 0.0002,
      "step": 3950
    },
    {
      "epoch": 0.9051428571428571,
      "grad_norm": 0.0010590091114863753,
      "learning_rate": 3.63009900990099e-05,
      "loss": 0.0001,
      "step": 3960
    },
    {
      "epoch": 0.9074285714285715,
      "grad_norm": 0.003842582693323493,
      "learning_rate": 3.6261386138613865e-05,
      "loss": 0.0423,
      "step": 3970
    },
    {
      "epoch": 0.9097142857142857,
      "grad_norm": 0.00481830770149827,
      "learning_rate": 3.622178217821782e-05,
      "loss": 0.064,
      "step": 3980
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.004136374220252037,
      "learning_rate": 3.618217821782178e-05,
      "loss": 0.0048,
      "step": 3990
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.007460343651473522,
      "learning_rate": 3.6142574257425744e-05,
      "loss": 0.0018,
      "step": 4000
    },
    {
      "epoch": 0.9165714285714286,
      "grad_norm": 0.0027627800591289997,
      "learning_rate": 3.61029702970297e-05,
      "loss": 0.0015,
      "step": 4010
    },
    {
      "epoch": 0.9188571428571428,
      "grad_norm": 0.0037983416114002466,
      "learning_rate": 3.6063366336633666e-05,
      "loss": 0.0014,
      "step": 4020
    },
    {
      "epoch": 0.9211428571428572,
      "grad_norm": 0.0023549303878098726,
      "learning_rate": 3.6023762376237624e-05,
      "loss": 0.0001,
      "step": 4030
    },
    {
      "epoch": 0.9234285714285714,
      "grad_norm": 0.004233699291944504,
      "learning_rate": 3.598415841584158e-05,
      "loss": 0.0012,
      "step": 4040
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 0.001797117292881012,
      "learning_rate": 3.5944554455445545e-05,
      "loss": 0.0012,
      "step": 4050
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.001017024158500135,
      "learning_rate": 3.59049504950495e-05,
      "loss": 0.0002,
      "step": 4060
    },
    {
      "epoch": 0.9302857142857143,
      "grad_norm": 0.0014029494486749172,
      "learning_rate": 3.586534653465347e-05,
      "loss": 0.0001,
      "step": 4070
    },
    {
      "epoch": 0.9325714285714286,
      "grad_norm": 0.003012098604813218,
      "learning_rate": 3.5825742574257425e-05,
      "loss": 0.0154,
      "step": 4080
    },
    {
      "epoch": 0.9348571428571428,
      "grad_norm": 0.002175047993659973,
      "learning_rate": 3.578613861386139e-05,
      "loss": 0.0018,
      "step": 4090
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 0.0014581193681806326,
      "learning_rate": 3.5746534653465346e-05,
      "loss": 0.001,
      "step": 4100
    },
    {
      "epoch": 0.9394285714285714,
      "grad_norm": 0.0007191626937128603,
      "learning_rate": 3.5706930693069304e-05,
      "loss": 0.0009,
      "step": 4110
    },
    {
      "epoch": 0.9417142857142857,
      "grad_norm": 0.07829563319683075,
      "learning_rate": 3.566732673267327e-05,
      "loss": 0.0027,
      "step": 4120
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.000523604394402355,
      "learning_rate": 3.5627722772277226e-05,
      "loss": 0.0001,
      "step": 4130
    },
    {
      "epoch": 0.9462857142857143,
      "grad_norm": 0.0009062765748240054,
      "learning_rate": 3.558811881188119e-05,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 0.001876436872407794,
      "learning_rate": 3.554851485148515e-05,
      "loss": 0.0011,
      "step": 4150
    },
    {
      "epoch": 0.9508571428571428,
      "grad_norm": 0.0013870848342776299,
      "learning_rate": 3.550891089108911e-05,
      "loss": 0.0088,
      "step": 4160
    },
    {
      "epoch": 0.9531428571428572,
      "grad_norm": 0.0010649452451616526,
      "learning_rate": 3.546930693069307e-05,
      "loss": 0.0004,
      "step": 4170
    },
    {
      "epoch": 0.9554285714285714,
      "grad_norm": 0.00849274080246687,
      "learning_rate": 3.542970297029703e-05,
      "loss": 0.0194,
      "step": 4180
    },
    {
      "epoch": 0.9577142857142857,
      "grad_norm": 0.000456468784250319,
      "learning_rate": 3.539009900990099e-05,
      "loss": 0.001,
      "step": 4190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0016270288033410907,
      "learning_rate": 3.535049504950495e-05,
      "loss": 0.0002,
      "step": 4200
    },
    {
      "epoch": 0.9622857142857143,
      "grad_norm": 0.0013444866053760052,
      "learning_rate": 3.531089108910891e-05,
      "loss": 0.0023,
      "step": 4210
    },
    {
      "epoch": 0.9645714285714285,
      "grad_norm": 0.00043314314098097384,
      "learning_rate": 3.527128712871287e-05,
      "loss": 0.0124,
      "step": 4220
    },
    {
      "epoch": 0.9668571428571429,
      "grad_norm": 0.002268644981086254,
      "learning_rate": 3.5231683168316834e-05,
      "loss": 0.0015,
      "step": 4230
    },
    {
      "epoch": 0.9691428571428572,
      "grad_norm": 0.0007056522881612182,
      "learning_rate": 3.519207920792079e-05,
      "loss": 0.0015,
      "step": 4240
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.000649982423055917,
      "learning_rate": 3.515247524752475e-05,
      "loss": 0.0029,
      "step": 4250
    },
    {
      "epoch": 0.9737142857142858,
      "grad_norm": 0.0005612350651063025,
      "learning_rate": 3.5112871287128714e-05,
      "loss": 0.0009,
      "step": 4260
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.000982191413640976,
      "learning_rate": 3.507326732673267e-05,
      "loss": 0.001,
      "step": 4270
    },
    {
      "epoch": 0.9782857142857143,
      "grad_norm": 0.5841589570045471,
      "learning_rate": 3.5033663366336635e-05,
      "loss": 0.0147,
      "step": 4280
    },
    {
      "epoch": 0.9805714285714285,
      "grad_norm": 0.00087334169074893,
      "learning_rate": 3.499405940594059e-05,
      "loss": 0.0001,
      "step": 4290
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 0.0012627687538042665,
      "learning_rate": 3.495445544554456e-05,
      "loss": 0.0001,
      "step": 4300
    },
    {
      "epoch": 0.9851428571428571,
      "grad_norm": 0.0013212849153205752,
      "learning_rate": 3.4914851485148515e-05,
      "loss": 0.0023,
      "step": 4310
    },
    {
      "epoch": 0.9874285714285714,
      "grad_norm": 0.001034233020618558,
      "learning_rate": 3.487524752475247e-05,
      "loss": 0.0001,
      "step": 4320
    },
    {
      "epoch": 0.9897142857142858,
      "grad_norm": 0.0009987103985622525,
      "learning_rate": 3.4835643564356436e-05,
      "loss": 0.0,
      "step": 4330
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.000645873136818409,
      "learning_rate": 3.4796039603960394e-05,
      "loss": 0.0009,
      "step": 4340
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 0.01193157397210598,
      "learning_rate": 3.475643564356436e-05,
      "loss": 0.0019,
      "step": 4350
    },
    {
      "epoch": 0.9965714285714286,
      "grad_norm": 0.00020339791080914438,
      "learning_rate": 3.4716831683168316e-05,
      "loss": 0.0018,
      "step": 4360
    },
    {
      "epoch": 0.9988571428571429,
      "grad_norm": 0.00016156226047314703,
      "learning_rate": 3.467722772277227e-05,
      "loss": 0.0142,
      "step": 4370
    },
    {
      "epoch": 1.0011428571428571,
      "grad_norm": 0.002060928847640753,
      "learning_rate": 3.463762376237624e-05,
      "loss": 0.0,
      "step": 4380
    },
    {
      "epoch": 1.0034285714285713,
      "grad_norm": 0.00020297813171055168,
      "learning_rate": 3.4598019801980195e-05,
      "loss": 0.0283,
      "step": 4390
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 0.0005367910489439964,
      "learning_rate": 3.455841584158416e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.0016509296838194132,
      "learning_rate": 3.451881188118812e-05,
      "loss": 0.0,
      "step": 4410
    },
    {
      "epoch": 1.0102857142857142,
      "grad_norm": 0.0005615815753117204,
      "learning_rate": 3.447920792079208e-05,
      "loss": 0.0074,
      "step": 4420
    },
    {
      "epoch": 1.0125714285714287,
      "grad_norm": 0.0020931842736899853,
      "learning_rate": 3.443960396039604e-05,
      "loss": 0.0584,
      "step": 4430
    },
    {
      "epoch": 1.014857142857143,
      "grad_norm": 0.009070276282727718,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0031,
      "step": 4440
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 0.04135869815945625,
      "learning_rate": 3.436039603960397e-05,
      "loss": 0.0002,
      "step": 4450
    },
    {
      "epoch": 1.0194285714285714,
      "grad_norm": 0.004582781344652176,
      "learning_rate": 3.4320792079207924e-05,
      "loss": 0.011,
      "step": 4460
    },
    {
      "epoch": 1.0217142857142858,
      "grad_norm": 0.008091217838227749,
      "learning_rate": 3.428118811881189e-05,
      "loss": 0.0001,
      "step": 4470
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.0011761501664295793,
      "learning_rate": 3.4241584158415846e-05,
      "loss": 0.0002,
      "step": 4480
    },
    {
      "epoch": 1.0262857142857142,
      "grad_norm": 0.00251031294465065,
      "learning_rate": 3.4201980198019804e-05,
      "loss": 0.0025,
      "step": 4490
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.004517729394137859,
      "learning_rate": 3.416237623762377e-05,
      "loss": 0.0001,
      "step": 4500
    },
    {
      "epoch": 1.030857142857143,
      "grad_norm": 0.0024672425352036953,
      "learning_rate": 3.4122772277227725e-05,
      "loss": 0.0024,
      "step": 4510
    },
    {
      "epoch": 1.0331428571428571,
      "grad_norm": 0.00526216346770525,
      "learning_rate": 3.408316831683169e-05,
      "loss": 0.0044,
      "step": 4520
    },
    {
      "epoch": 1.0354285714285714,
      "grad_norm": 0.0025559901259839535,
      "learning_rate": 3.404356435643565e-05,
      "loss": 0.0001,
      "step": 4530
    },
    {
      "epoch": 1.0377142857142858,
      "grad_norm": 0.0021480994764715433,
      "learning_rate": 3.4003960396039605e-05,
      "loss": 0.0001,
      "step": 4540
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.0015679709613323212,
      "learning_rate": 3.396435643564357e-05,
      "loss": 0.0001,
      "step": 4550
    },
    {
      "epoch": 1.0422857142857143,
      "grad_norm": 0.0003689823788590729,
      "learning_rate": 3.3924752475247526e-05,
      "loss": 0.0001,
      "step": 4560
    },
    {
      "epoch": 1.0445714285714285,
      "grad_norm": 0.00119756069034338,
      "learning_rate": 3.388514851485149e-05,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 1.046857142857143,
      "grad_norm": 0.0026217757258564234,
      "learning_rate": 3.384554455445545e-05,
      "loss": 0.0036,
      "step": 4580
    },
    {
      "epoch": 1.0491428571428572,
      "grad_norm": 0.0015793232014402747,
      "learning_rate": 3.380594059405941e-05,
      "loss": 0.0001,
      "step": 4590
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 0.0014875947963446379,
      "learning_rate": 3.376633663366337e-05,
      "loss": 0.0017,
      "step": 4600
    },
    {
      "epoch": 1.0537142857142858,
      "grad_norm": 0.10327010601758957,
      "learning_rate": 3.372673267326733e-05,
      "loss": 0.0029,
      "step": 4610
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.000489576836116612,
      "learning_rate": 3.368712871287129e-05,
      "loss": 0.0029,
      "step": 4620
    },
    {
      "epoch": 1.0582857142857143,
      "grad_norm": 0.0001392675330862403,
      "learning_rate": 3.364752475247525e-05,
      "loss": 0.0001,
      "step": 4630
    },
    {
      "epoch": 1.0605714285714285,
      "grad_norm": 0.0021349794697016478,
      "learning_rate": 3.3607920792079213e-05,
      "loss": 0.0011,
      "step": 4640
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 0.0023758080787956715,
      "learning_rate": 3.356831683168317e-05,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 1.0651428571428572,
      "grad_norm": 0.0016833435511216521,
      "learning_rate": 3.3528712871287135e-05,
      "loss": 0.0,
      "step": 4660
    },
    {
      "epoch": 1.0674285714285714,
      "grad_norm": 0.09838154166936874,
      "learning_rate": 3.348910891089109e-05,
      "loss": 0.0148,
      "step": 4670
    },
    {
      "epoch": 1.0697142857142856,
      "grad_norm": 0.00117539893835783,
      "learning_rate": 3.344950495049505e-05,
      "loss": 0.0001,
      "step": 4680
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.4966360330581665,
      "learning_rate": 3.3409900990099014e-05,
      "loss": 0.011,
      "step": 4690
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 0.0008399239741265774,
      "learning_rate": 3.337029702970297e-05,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 1.0765714285714285,
      "grad_norm": 0.0012953572440892458,
      "learning_rate": 3.3330693069306936e-05,
      "loss": 0.0,
      "step": 4710
    },
    {
      "epoch": 1.078857142857143,
      "grad_norm": 0.0009297516662627459,
      "learning_rate": 3.3291089108910894e-05,
      "loss": 0.0001,
      "step": 4720
    },
    {
      "epoch": 1.0811428571428572,
      "grad_norm": 0.0004075306642334908,
      "learning_rate": 3.325148514851486e-05,
      "loss": 0.0,
      "step": 4730
    },
    {
      "epoch": 1.0834285714285714,
      "grad_norm": 0.0014911171747371554,
      "learning_rate": 3.3211881188118815e-05,
      "loss": 0.0018,
      "step": 4740
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.0008362180087715387,
      "learning_rate": 3.317227722772277e-05,
      "loss": 0.0016,
      "step": 4750
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.00037381943548098207,
      "learning_rate": 3.313267326732674e-05,
      "loss": 0.0,
      "step": 4760
    },
    {
      "epoch": 1.0902857142857143,
      "grad_norm": 0.13301460444927216,
      "learning_rate": 3.3093069306930695e-05,
      "loss": 0.0222,
      "step": 4770
    },
    {
      "epoch": 1.0925714285714285,
      "grad_norm": 0.0011686774669215083,
      "learning_rate": 3.305346534653466e-05,
      "loss": 0.0,
      "step": 4780
    },
    {
      "epoch": 1.0948571428571428,
      "grad_norm": 0.0008854588959366083,
      "learning_rate": 3.3013861386138616e-05,
      "loss": 0.0041,
      "step": 4790
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 0.00040240923408418894,
      "learning_rate": 3.297425742574258e-05,
      "loss": 0.0019,
      "step": 4800
    },
    {
      "epoch": 1.0994285714285714,
      "grad_norm": 0.00026507460279390216,
      "learning_rate": 3.293465346534654e-05,
      "loss": 0.0088,
      "step": 4810
    },
    {
      "epoch": 1.1017142857142856,
      "grad_norm": 0.0008540269336663187,
      "learning_rate": 3.2895049504950496e-05,
      "loss": 0.0021,
      "step": 4820
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.0030111195519566536,
      "learning_rate": 3.285544554455446e-05,
      "loss": 0.0,
      "step": 4830
    },
    {
      "epoch": 1.1062857142857143,
      "grad_norm": 0.0012118478771299124,
      "learning_rate": 3.281584158415842e-05,
      "loss": 0.0084,
      "step": 4840
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 0.0003653414605651051,
      "learning_rate": 3.277623762376238e-05,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 1.1108571428571428,
      "grad_norm": 0.0006578757893294096,
      "learning_rate": 3.273663366336634e-05,
      "loss": 0.0024,
      "step": 4860
    },
    {
      "epoch": 1.1131428571428572,
      "grad_norm": 0.0006209593266248703,
      "learning_rate": 3.26970297029703e-05,
      "loss": 0.0,
      "step": 4870
    },
    {
      "epoch": 1.1154285714285714,
      "grad_norm": 0.13463644683361053,
      "learning_rate": 3.265742574257426e-05,
      "loss": 0.0046,
      "step": 4880
    },
    {
      "epoch": 1.1177142857142857,
      "grad_norm": 0.0010992723982781172,
      "learning_rate": 3.261782178217822e-05,
      "loss": 0.0,
      "step": 4890
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.12898367643356323,
      "learning_rate": 3.257821782178218e-05,
      "loss": 0.002,
      "step": 4900
    },
    {
      "epoch": 1.1222857142857143,
      "grad_norm": 0.00035955547355115414,
      "learning_rate": 3.253861386138614e-05,
      "loss": 0.0103,
      "step": 4910
    },
    {
      "epoch": 1.1245714285714286,
      "grad_norm": 0.00028211550670675933,
      "learning_rate": 3.2499009900990104e-05,
      "loss": 0.0039,
      "step": 4920
    },
    {
      "epoch": 1.1268571428571428,
      "grad_norm": 0.00048581091687083244,
      "learning_rate": 3.245940594059406e-05,
      "loss": 0.0019,
      "step": 4930
    },
    {
      "epoch": 1.1291428571428572,
      "grad_norm": 0.001341343391686678,
      "learning_rate": 3.241980198019802e-05,
      "loss": 0.0427,
      "step": 4940
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 0.0009132904815487564,
      "learning_rate": 3.2380198019801984e-05,
      "loss": 0.005,
      "step": 4950
    },
    {
      "epoch": 1.1337142857142857,
      "grad_norm": 0.001676257816143334,
      "learning_rate": 3.234059405940594e-05,
      "loss": 0.0,
      "step": 4960
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.000581404019612819,
      "learning_rate": 3.2300990099009905e-05,
      "loss": 0.0168,
      "step": 4970
    },
    {
      "epoch": 1.1382857142857143,
      "grad_norm": 0.0005508690373972058,
      "learning_rate": 3.226138613861386e-05,
      "loss": 0.0001,
      "step": 4980
    },
    {
      "epoch": 1.1405714285714286,
      "grad_norm": 0.0008768278639763594,
      "learning_rate": 3.222178217821783e-05,
      "loss": 0.0001,
      "step": 4990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.0017220494337379932,
      "learning_rate": 3.2182178217821785e-05,
      "loss": 0.0104,
      "step": 5000
    },
    {
      "epoch": 1.145142857142857,
      "grad_norm": 0.0038003476802259684,
      "learning_rate": 3.214257425742574e-05,
      "loss": 0.0026,
      "step": 5010
    },
    {
      "epoch": 1.1474285714285715,
      "grad_norm": 0.0013293926604092121,
      "learning_rate": 3.2102970297029706e-05,
      "loss": 0.0022,
      "step": 5020
    },
    {
      "epoch": 1.1497142857142857,
      "grad_norm": 0.0010542564559727907,
      "learning_rate": 3.2063366336633664e-05,
      "loss": 0.0012,
      "step": 5030
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.0006530886748805642,
      "learning_rate": 3.202376237623763e-05,
      "loss": 0.001,
      "step": 5040
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 0.0015095543349161744,
      "learning_rate": 3.1984158415841586e-05,
      "loss": 0.0001,
      "step": 5050
    },
    {
      "epoch": 1.1565714285714286,
      "grad_norm": 0.0800071731209755,
      "learning_rate": 3.194455445544555e-05,
      "loss": 0.0027,
      "step": 5060
    },
    {
      "epoch": 1.1588571428571428,
      "grad_norm": 0.0010703688021749258,
      "learning_rate": 3.190495049504951e-05,
      "loss": 0.0008,
      "step": 5070
    },
    {
      "epoch": 1.161142857142857,
      "grad_norm": 0.0009157613385468721,
      "learning_rate": 3.1865346534653465e-05,
      "loss": 0.0014,
      "step": 5080
    },
    {
      "epoch": 1.1634285714285715,
      "grad_norm": 0.0012269819853827357,
      "learning_rate": 3.182574257425743e-05,
      "loss": 0.0001,
      "step": 5090
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 0.0007260882994160056,
      "learning_rate": 3.1786138613861387e-05,
      "loss": 0.0006,
      "step": 5100
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.0007252849172800779,
      "learning_rate": 3.174653465346535e-05,
      "loss": 0.0018,
      "step": 5110
    },
    {
      "epoch": 1.1702857142857144,
      "grad_norm": 0.0027564088813960552,
      "learning_rate": 3.170693069306931e-05,
      "loss": 0.0164,
      "step": 5120
    },
    {
      "epoch": 1.1725714285714286,
      "grad_norm": 0.0015401318669319153,
      "learning_rate": 3.1667326732673266e-05,
      "loss": 0.0009,
      "step": 5130
    },
    {
      "epoch": 1.1748571428571428,
      "grad_norm": 0.0012036849511787295,
      "learning_rate": 3.162772277227723e-05,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 0.09207353740930557,
      "learning_rate": 3.158811881188119e-05,
      "loss": 0.0026,
      "step": 5150
    },
    {
      "epoch": 1.1794285714285715,
      "grad_norm": 0.0006976795848459005,
      "learning_rate": 3.154851485148515e-05,
      "loss": 0.0154,
      "step": 5160
    },
    {
      "epoch": 1.1817142857142857,
      "grad_norm": 0.0031539893243461847,
      "learning_rate": 3.150891089108911e-05,
      "loss": 0.0001,
      "step": 5170
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.0020365987438708544,
      "learning_rate": 3.1469306930693074e-05,
      "loss": 0.0001,
      "step": 5180
    },
    {
      "epoch": 1.1862857142857144,
      "grad_norm": 0.0011467342264950275,
      "learning_rate": 3.142970297029703e-05,
      "loss": 0.0038,
      "step": 5190
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 0.0016978320199996233,
      "learning_rate": 3.139009900990099e-05,
      "loss": 0.0012,
      "step": 5200
    },
    {
      "epoch": 1.1908571428571428,
      "grad_norm": 0.0010349205695092678,
      "learning_rate": 3.135049504950495e-05,
      "loss": 0.0026,
      "step": 5210
    },
    {
      "epoch": 1.193142857142857,
      "grad_norm": 0.0015620834892615676,
      "learning_rate": 3.131089108910891e-05,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 1.1954285714285715,
      "grad_norm": 0.0010177341755479574,
      "learning_rate": 3.1271287128712875e-05,
      "loss": 0.0,
      "step": 5230
    },
    {
      "epoch": 1.1977142857142857,
      "grad_norm": 0.07571052014827728,
      "learning_rate": 3.123168316831683e-05,
      "loss": 0.0013,
      "step": 5240
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0012243136297911406,
      "learning_rate": 3.1192079207920796e-05,
      "loss": 0.0006,
      "step": 5250
    },
    {
      "epoch": 1.2022857142857144,
      "grad_norm": 0.0009604375809431076,
      "learning_rate": 3.1152475247524754e-05,
      "loss": 0.0154,
      "step": 5260
    },
    {
      "epoch": 1.2045714285714286,
      "grad_norm": 0.0009184952941723168,
      "learning_rate": 3.111287128712871e-05,
      "loss": 0.0125,
      "step": 5270
    },
    {
      "epoch": 1.2068571428571429,
      "grad_norm": 0.0007685419404879212,
      "learning_rate": 3.1073267326732676e-05,
      "loss": 0.0009,
      "step": 5280
    },
    {
      "epoch": 1.209142857142857,
      "grad_norm": 0.0006889499491080642,
      "learning_rate": 3.103366336633663e-05,
      "loss": 0.0,
      "step": 5290
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 0.0015372924972325563,
      "learning_rate": 3.09940594059406e-05,
      "loss": 0.0129,
      "step": 5300
    },
    {
      "epoch": 1.2137142857142857,
      "grad_norm": 0.0005204277113080025,
      "learning_rate": 3.0954455445544555e-05,
      "loss": 0.024,
      "step": 5310
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.0011755131417885423,
      "learning_rate": 3.091485148514852e-05,
      "loss": 0.0019,
      "step": 5320
    },
    {
      "epoch": 1.2182857142857142,
      "grad_norm": 0.0004333560063969344,
      "learning_rate": 3.0875247524752477e-05,
      "loss": 0.0,
      "step": 5330
    },
    {
      "epoch": 1.2205714285714286,
      "grad_norm": 0.0007023342186585069,
      "learning_rate": 3.0835643564356434e-05,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 0.0016454043798148632,
      "learning_rate": 3.07960396039604e-05,
      "loss": 0.0059,
      "step": 5350
    },
    {
      "epoch": 1.225142857142857,
      "grad_norm": 0.0003874994581565261,
      "learning_rate": 3.0756435643564356e-05,
      "loss": 0.0122,
      "step": 5360
    },
    {
      "epoch": 1.2274285714285713,
      "grad_norm": 0.0014308457029983401,
      "learning_rate": 3.071683168316832e-05,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 1.2297142857142858,
      "grad_norm": 0.0009768868330866098,
      "learning_rate": 3.067722772277228e-05,
      "loss": 0.0033,
      "step": 5380
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.001159793813712895,
      "learning_rate": 3.063762376237624e-05,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 0.0017177213449031115,
      "learning_rate": 3.05980198019802e-05,
      "loss": 0.0014,
      "step": 5400
    },
    {
      "epoch": 1.2365714285714287,
      "grad_norm": 0.0007826843648217618,
      "learning_rate": 3.055841584158416e-05,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 1.2388571428571429,
      "grad_norm": 0.11932943016290665,
      "learning_rate": 3.051881188118812e-05,
      "loss": 0.0112,
      "step": 5420
    },
    {
      "epoch": 1.241142857142857,
      "grad_norm": 0.0010182089172303677,
      "learning_rate": 3.047920792079208e-05,
      "loss": 0.0018,
      "step": 5430
    },
    {
      "epoch": 1.2434285714285713,
      "grad_norm": 0.00026186511968262494,
      "learning_rate": 3.043960396039604e-05,
      "loss": 0.0028,
      "step": 5440
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 0.0009010552894324064,
      "learning_rate": 3.04e-05,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.0010870987316593528,
      "learning_rate": 3.036039603960396e-05,
      "loss": 0.0014,
      "step": 5460
    },
    {
      "epoch": 1.2502857142857142,
      "grad_norm": 0.0004853545397054404,
      "learning_rate": 3.0320792079207922e-05,
      "loss": 0.0025,
      "step": 5470
    },
    {
      "epoch": 1.2525714285714287,
      "grad_norm": 0.00041593878995627165,
      "learning_rate": 3.0281188118811883e-05,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 1.254857142857143,
      "grad_norm": 0.0008593726088292897,
      "learning_rate": 3.0241584158415844e-05,
      "loss": 0.0,
      "step": 5490
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.0008099966798909009,
      "learning_rate": 3.02019801980198e-05,
      "loss": 0.0019,
      "step": 5500
    },
    {
      "epoch": 1.2594285714285713,
      "grad_norm": 0.10506730526685715,
      "learning_rate": 3.0162376237623762e-05,
      "loss": 0.002,
      "step": 5510
    },
    {
      "epoch": 1.2617142857142858,
      "grad_norm": 0.0009096799767576158,
      "learning_rate": 3.0122772277227723e-05,
      "loss": 0.001,
      "step": 5520
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.0013250939082354307,
      "learning_rate": 3.0083168316831684e-05,
      "loss": 0.0,
      "step": 5530
    },
    {
      "epoch": 1.2662857142857142,
      "grad_norm": 0.0013746818294748664,
      "learning_rate": 3.0043564356435645e-05,
      "loss": 0.0007,
      "step": 5540
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 0.0011138373520225286,
      "learning_rate": 3.0003960396039606e-05,
      "loss": 0.0011,
      "step": 5550
    },
    {
      "epoch": 1.270857142857143,
      "grad_norm": 0.0012046893825754523,
      "learning_rate": 2.9964356435643563e-05,
      "loss": 0.0007,
      "step": 5560
    },
    {
      "epoch": 1.2731428571428571,
      "grad_norm": 0.0006388233741745353,
      "learning_rate": 2.9924752475247524e-05,
      "loss": 0.0005,
      "step": 5570
    },
    {
      "epoch": 1.2754285714285714,
      "grad_norm": 0.00039549419307149947,
      "learning_rate": 2.9885148514851485e-05,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 1.2777142857142856,
      "grad_norm": 0.06825509667396545,
      "learning_rate": 2.9845544554455446e-05,
      "loss": 0.0127,
      "step": 5590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.0009886614279821515,
      "learning_rate": 2.9805940594059407e-05,
      "loss": 0.0006,
      "step": 5600
    },
    {
      "epoch": 1.2822857142857143,
      "grad_norm": 0.06203334778547287,
      "learning_rate": 2.9766336633663368e-05,
      "loss": 0.0046,
      "step": 5610
    },
    {
      "epoch": 1.2845714285714287,
      "grad_norm": 0.0019815070554614067,
      "learning_rate": 2.972673267326733e-05,
      "loss": 0.0714,
      "step": 5620
    },
    {
      "epoch": 1.286857142857143,
      "grad_norm": 0.0010015795705839992,
      "learning_rate": 2.9687128712871286e-05,
      "loss": 0.0136,
      "step": 5630
    },
    {
      "epoch": 1.2891428571428571,
      "grad_norm": 0.0020316129084676504,
      "learning_rate": 2.9647524752475247e-05,
      "loss": 0.0021,
      "step": 5640
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 0.002592050703242421,
      "learning_rate": 2.9607920792079208e-05,
      "loss": 0.0023,
      "step": 5650
    },
    {
      "epoch": 1.2937142857142856,
      "grad_norm": 0.005044309888035059,
      "learning_rate": 2.956831683168317e-05,
      "loss": 0.0012,
      "step": 5660
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.0017844876274466515,
      "learning_rate": 2.952871287128713e-05,
      "loss": 0.0019,
      "step": 5670
    },
    {
      "epoch": 1.2982857142857143,
      "grad_norm": 0.0039035652298480272,
      "learning_rate": 2.948910891089109e-05,
      "loss": 0.0009,
      "step": 5680
    },
    {
      "epoch": 1.3005714285714285,
      "grad_norm": 0.0007565213018096983,
      "learning_rate": 2.9449504950495048e-05,
      "loss": 0.0001,
      "step": 5690
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 0.0018323400290682912,
      "learning_rate": 2.940990099009901e-05,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 1.3051428571428572,
      "grad_norm": 0.0026205596514046192,
      "learning_rate": 2.937029702970297e-05,
      "loss": 0.0001,
      "step": 5710
    },
    {
      "epoch": 1.3074285714285714,
      "grad_norm": 0.0018534704577177763,
      "learning_rate": 2.933069306930693e-05,
      "loss": 0.0009,
      "step": 5720
    },
    {
      "epoch": 1.3097142857142856,
      "grad_norm": 0.0018628400284796953,
      "learning_rate": 2.929108910891089e-05,
      "loss": 0.0008,
      "step": 5730
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.0023290214594453573,
      "learning_rate": 2.9251485148514852e-05,
      "loss": 0.0007,
      "step": 5740
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 0.002781696617603302,
      "learning_rate": 2.9211881188118813e-05,
      "loss": 0.0001,
      "step": 5750
    },
    {
      "epoch": 1.3165714285714285,
      "grad_norm": 0.000555964361410588,
      "learning_rate": 2.917227722772277e-05,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 1.318857142857143,
      "grad_norm": 0.00045316549949347973,
      "learning_rate": 2.913267326732673e-05,
      "loss": 0.0167,
      "step": 5770
    },
    {
      "epoch": 1.3211428571428572,
      "grad_norm": 0.0014335766900330782,
      "learning_rate": 2.9093069306930692e-05,
      "loss": 0.001,
      "step": 5780
    },
    {
      "epoch": 1.3234285714285714,
      "grad_norm": 0.0003820878337137401,
      "learning_rate": 2.9053465346534653e-05,
      "loss": 0.0003,
      "step": 5790
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 0.0017966045998036861,
      "learning_rate": 2.9013861386138614e-05,
      "loss": 0.0004,
      "step": 5800
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.0008641481399536133,
      "learning_rate": 2.8974257425742575e-05,
      "loss": 0.0011,
      "step": 5810
    },
    {
      "epoch": 1.3302857142857143,
      "grad_norm": 0.00112612871453166,
      "learning_rate": 2.8934653465346532e-05,
      "loss": 0.0,
      "step": 5820
    },
    {
      "epoch": 1.3325714285714285,
      "grad_norm": 0.0010662636486813426,
      "learning_rate": 2.8895049504950493e-05,
      "loss": 0.0011,
      "step": 5830
    },
    {
      "epoch": 1.334857142857143,
      "grad_norm": 0.0022807784844189882,
      "learning_rate": 2.8855445544554454e-05,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 0.0005714420694857836,
      "learning_rate": 2.8815841584158415e-05,
      "loss": 0.0134,
      "step": 5850
    },
    {
      "epoch": 1.3394285714285714,
      "grad_norm": 5.469258758239448e-05,
      "learning_rate": 2.8776237623762376e-05,
      "loss": 0.0,
      "step": 5860
    },
    {
      "epoch": 1.3417142857142856,
      "grad_norm": 0.0018104607006534934,
      "learning_rate": 2.8736633663366337e-05,
      "loss": 0.0,
      "step": 5870
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.08583323657512665,
      "learning_rate": 2.8697029702970298e-05,
      "loss": 0.0006,
      "step": 5880
    },
    {
      "epoch": 1.3462857142857143,
      "grad_norm": 0.0012717132922261953,
      "learning_rate": 2.8657425742574255e-05,
      "loss": 0.0034,
      "step": 5890
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 0.0004410298424772918,
      "learning_rate": 2.8617821782178216e-05,
      "loss": 0.001,
      "step": 5900
    },
    {
      "epoch": 1.350857142857143,
      "grad_norm": 0.0006624885136261582,
      "learning_rate": 2.8578217821782177e-05,
      "loss": 0.0,
      "step": 5910
    },
    {
      "epoch": 1.3531428571428572,
      "grad_norm": 0.00045892721391282976,
      "learning_rate": 2.8538613861386138e-05,
      "loss": 0.002,
      "step": 5920
    },
    {
      "epoch": 1.3554285714285714,
      "grad_norm": 0.001462747692130506,
      "learning_rate": 2.84990099009901e-05,
      "loss": 0.0008,
      "step": 5930
    },
    {
      "epoch": 1.3577142857142857,
      "grad_norm": 6.732173642376438e-05,
      "learning_rate": 2.845940594059406e-05,
      "loss": 0.0004,
      "step": 5940
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.0007453174330294132,
      "learning_rate": 2.8419801980198017e-05,
      "loss": 0.0002,
      "step": 5950
    },
    {
      "epoch": 1.3622857142857143,
      "grad_norm": 0.0013665962032973766,
      "learning_rate": 2.8380198019801978e-05,
      "loss": 0.0002,
      "step": 5960
    },
    {
      "epoch": 1.3645714285714285,
      "grad_norm": 0.0014670898672193289,
      "learning_rate": 2.834059405940594e-05,
      "loss": 0.0,
      "step": 5970
    },
    {
      "epoch": 1.366857142857143,
      "grad_norm": 0.0005931953201070428,
      "learning_rate": 2.83009900990099e-05,
      "loss": 0.0002,
      "step": 5980
    },
    {
      "epoch": 1.3691428571428572,
      "grad_norm": 0.0018792243208736181,
      "learning_rate": 2.826138613861386e-05,
      "loss": 0.0007,
      "step": 5990
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 0.09353511780500412,
      "learning_rate": 2.822178217821782e-05,
      "loss": 0.0009,
      "step": 6000
    },
    {
      "epoch": 1.3737142857142857,
      "grad_norm": 0.0004653763317037374,
      "learning_rate": 2.8182178217821782e-05,
      "loss": 0.0,
      "step": 6010
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.06396739184856415,
      "learning_rate": 2.814257425742574e-05,
      "loss": 0.0193,
      "step": 6020
    },
    {
      "epoch": 1.3782857142857143,
      "grad_norm": 0.0010491504799574614,
      "learning_rate": 2.8102970297029707e-05,
      "loss": 0.0015,
      "step": 6030
    },
    {
      "epoch": 1.3805714285714286,
      "grad_norm": 0.07513602077960968,
      "learning_rate": 2.8063366336633668e-05,
      "loss": 0.0005,
      "step": 6040
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 0.00032088844454847276,
      "learning_rate": 2.802376237623763e-05,
      "loss": 0.0006,
      "step": 6050
    },
    {
      "epoch": 1.3851428571428572,
      "grad_norm": 0.0006313072517514229,
      "learning_rate": 2.7984158415841587e-05,
      "loss": 0.0005,
      "step": 6060
    },
    {
      "epoch": 1.3874285714285715,
      "grad_norm": 0.0009092367254197598,
      "learning_rate": 2.7944554455445548e-05,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 1.3897142857142857,
      "grad_norm": 0.0011977681424468756,
      "learning_rate": 2.790495049504951e-05,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.00012497253192123026,
      "learning_rate": 2.786534653465347e-05,
      "loss": 0.0014,
      "step": 6090
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 0.000760940252803266,
      "learning_rate": 2.782574257425743e-05,
      "loss": 0.0004,
      "step": 6100
    },
    {
      "epoch": 1.3965714285714286,
      "grad_norm": 0.00026912393514066935,
      "learning_rate": 2.778613861386139e-05,
      "loss": 0.0,
      "step": 6110
    },
    {
      "epoch": 1.3988571428571428,
      "grad_norm": 0.0007551602320745587,
      "learning_rate": 2.7746534653465352e-05,
      "loss": 0.0143,
      "step": 6120
    },
    {
      "epoch": 1.4011428571428572,
      "grad_norm": 0.0009739657398313284,
      "learning_rate": 2.770693069306931e-05,
      "loss": 0.0002,
      "step": 6130
    },
    {
      "epoch": 1.4034285714285715,
      "grad_norm": 0.0004437936295289546,
      "learning_rate": 2.766732673267327e-05,
      "loss": 0.0136,
      "step": 6140
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 0.000884108361788094,
      "learning_rate": 2.762772277227723e-05,
      "loss": 0.001,
      "step": 6150
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.0012248799903318286,
      "learning_rate": 2.7588118811881192e-05,
      "loss": 0.0003,
      "step": 6160
    },
    {
      "epoch": 1.4102857142857144,
      "grad_norm": 0.0006581888301298022,
      "learning_rate": 2.7548514851485153e-05,
      "loss": 0.0,
      "step": 6170
    },
    {
      "epoch": 1.4125714285714286,
      "grad_norm": 0.00014595560787711293,
      "learning_rate": 2.7508910891089114e-05,
      "loss": 0.0001,
      "step": 6180
    },
    {
      "epoch": 1.4148571428571428,
      "grad_norm": 0.0009914152324199677,
      "learning_rate": 2.746930693069307e-05,
      "loss": 0.0012,
      "step": 6190
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 0.0002267128584207967,
      "learning_rate": 2.7429702970297032e-05,
      "loss": 0.0221,
      "step": 6200
    },
    {
      "epoch": 1.4194285714285715,
      "grad_norm": 0.0005238514859229326,
      "learning_rate": 2.7390099009900993e-05,
      "loss": 0.0031,
      "step": 6210
    },
    {
      "epoch": 1.4217142857142857,
      "grad_norm": 0.11743494123220444,
      "learning_rate": 2.7350495049504954e-05,
      "loss": 0.0014,
      "step": 6220
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.00040238548535853624,
      "learning_rate": 2.7310891089108915e-05,
      "loss": 0.0001,
      "step": 6230
    },
    {
      "epoch": 1.4262857142857142,
      "grad_norm": 0.0007666940800845623,
      "learning_rate": 2.7271287128712876e-05,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.0008407764253206551,
      "learning_rate": 2.7231683168316837e-05,
      "loss": 0.0039,
      "step": 6250
    },
    {
      "epoch": 1.4308571428571428,
      "grad_norm": 0.0003832265501841903,
      "learning_rate": 2.7192079207920794e-05,
      "loss": 0.0,
      "step": 6260
    },
    {
      "epoch": 1.4331428571428573,
      "grad_norm": 0.0009191479766741395,
      "learning_rate": 2.7152475247524755e-05,
      "loss": 0.0123,
      "step": 6270
    },
    {
      "epoch": 1.4354285714285715,
      "grad_norm": 0.0003435259568504989,
      "learning_rate": 2.7112871287128716e-05,
      "loss": 0.0001,
      "step": 6280
    },
    {
      "epoch": 1.4377142857142857,
      "grad_norm": 0.0007585521088913083,
      "learning_rate": 2.7073267326732677e-05,
      "loss": 0.0013,
      "step": 6290
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.0010634718928486109,
      "learning_rate": 2.7033663366336637e-05,
      "loss": 0.0115,
      "step": 6300
    },
    {
      "epoch": 1.4422857142857142,
      "grad_norm": 0.0006702611572109163,
      "learning_rate": 2.69940594059406e-05,
      "loss": 0.0,
      "step": 6310
    },
    {
      "epoch": 1.4445714285714286,
      "grad_norm": 0.1175546869635582,
      "learning_rate": 2.6954455445544556e-05,
      "loss": 0.0015,
      "step": 6320
    },
    {
      "epoch": 1.4468571428571428,
      "grad_norm": 0.009386753663420677,
      "learning_rate": 2.6914851485148517e-05,
      "loss": 0.063,
      "step": 6330
    },
    {
      "epoch": 1.449142857142857,
      "grad_norm": 5.1272418204462156e-05,
      "learning_rate": 2.6875247524752478e-05,
      "loss": 0.0002,
      "step": 6340
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 0.004030683543533087,
      "learning_rate": 2.683564356435644e-05,
      "loss": 0.0013,
      "step": 6350
    },
    {
      "epoch": 1.4537142857142857,
      "grad_norm": 0.003789540147408843,
      "learning_rate": 2.67960396039604e-05,
      "loss": 0.0015,
      "step": 6360
    },
    {
      "epoch": 1.456,
      "grad_norm": 6.0524605942191556e-05,
      "learning_rate": 2.675643564356436e-05,
      "loss": 0.0012,
      "step": 6370
    },
    {
      "epoch": 1.4582857142857142,
      "grad_norm": 0.0009343751589767635,
      "learning_rate": 2.671683168316832e-05,
      "loss": 0.0011,
      "step": 6380
    },
    {
      "epoch": 1.4605714285714286,
      "grad_norm": 0.0032553160563111305,
      "learning_rate": 2.667722772277228e-05,
      "loss": 0.0001,
      "step": 6390
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.0020644143223762512,
      "learning_rate": 2.663762376237624e-05,
      "loss": 0.011,
      "step": 6400
    },
    {
      "epoch": 1.465142857142857,
      "grad_norm": 0.010704305954277515,
      "learning_rate": 2.65980198019802e-05,
      "loss": 0.0513,
      "step": 6410
    },
    {
      "epoch": 1.4674285714285715,
      "grad_norm": 0.009443224407732487,
      "learning_rate": 2.655841584158416e-05,
      "loss": 0.0005,
      "step": 6420
    },
    {
      "epoch": 1.4697142857142858,
      "grad_norm": 0.0038888673298060894,
      "learning_rate": 2.6518811881188122e-05,
      "loss": 0.012,
      "step": 6430
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.0020691908430308104,
      "learning_rate": 2.6479207920792083e-05,
      "loss": 0.0027,
      "step": 6440
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 0.1058056429028511,
      "learning_rate": 2.643960396039604e-05,
      "loss": 0.0138,
      "step": 6450
    },
    {
      "epoch": 1.4765714285714286,
      "grad_norm": 0.006271365098655224,
      "learning_rate": 2.64e-05,
      "loss": 0.0002,
      "step": 6460
    },
    {
      "epoch": 1.4788571428571429,
      "grad_norm": 0.0034453815314918756,
      "learning_rate": 2.6360396039603962e-05,
      "loss": 0.0002,
      "step": 6470
    },
    {
      "epoch": 1.481142857142857,
      "grad_norm": 0.005375211592763662,
      "learning_rate": 2.6320792079207923e-05,
      "loss": 0.0001,
      "step": 6480
    },
    {
      "epoch": 1.4834285714285715,
      "grad_norm": 0.002810171339660883,
      "learning_rate": 2.6281188118811884e-05,
      "loss": 0.0001,
      "step": 6490
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.2162342369556427,
      "learning_rate": 2.6241584158415845e-05,
      "loss": 0.0048,
      "step": 6500
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.004675024654716253,
      "learning_rate": 2.6201980198019806e-05,
      "loss": 0.0018,
      "step": 6510
    },
    {
      "epoch": 1.4902857142857142,
      "grad_norm": 0.0021094800904393196,
      "learning_rate": 2.6162376237623763e-05,
      "loss": 0.0102,
      "step": 6520
    },
    {
      "epoch": 1.4925714285714284,
      "grad_norm": 0.0026786283124238253,
      "learning_rate": 2.6122772277227724e-05,
      "loss": 0.0001,
      "step": 6530
    },
    {
      "epoch": 1.4948571428571429,
      "grad_norm": 0.003593975445255637,
      "learning_rate": 2.6083168316831685e-05,
      "loss": 0.0094,
      "step": 6540
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 0.003029419807717204,
      "learning_rate": 2.6043564356435646e-05,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 1.4994285714285716,
      "grad_norm": 0.003929078578948975,
      "learning_rate": 2.6003960396039607e-05,
      "loss": 0.0031,
      "step": 6560
    },
    {
      "epoch": 1.5017142857142858,
      "grad_norm": 0.00291410181671381,
      "learning_rate": 2.5964356435643568e-05,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.10694091767072678,
      "learning_rate": 2.592475247524753e-05,
      "loss": 0.0105,
      "step": 6580
    },
    {
      "epoch": 1.5062857142857142,
      "grad_norm": 0.002202007919549942,
      "learning_rate": 2.5885148514851486e-05,
      "loss": 0.0022,
      "step": 6590
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 0.0034177887719124556,
      "learning_rate": 2.5845544554455447e-05,
      "loss": 0.0017,
      "step": 6600
    },
    {
      "epoch": 1.510857142857143,
      "grad_norm": 0.0010085966205224395,
      "learning_rate": 2.5805940594059408e-05,
      "loss": 0.0001,
      "step": 6610
    },
    {
      "epoch": 1.5131428571428571,
      "grad_norm": 0.003639149246737361,
      "learning_rate": 2.576633663366337e-05,
      "loss": 0.0012,
      "step": 6620
    },
    {
      "epoch": 1.5154285714285716,
      "grad_norm": 1.8637421131134033,
      "learning_rate": 2.572673267326733e-05,
      "loss": 0.0489,
      "step": 6630
    },
    {
      "epoch": 1.5177142857142858,
      "grad_norm": 0.0030644822400063276,
      "learning_rate": 2.568712871287129e-05,
      "loss": 0.001,
      "step": 6640
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.008730722591280937,
      "learning_rate": 2.5647524752475248e-05,
      "loss": 0.0009,
      "step": 6650
    },
    {
      "epoch": 1.5222857142857142,
      "grad_norm": 0.010328052565455437,
      "learning_rate": 2.560792079207921e-05,
      "loss": 0.0006,
      "step": 6660
    },
    {
      "epoch": 1.5245714285714285,
      "grad_norm": 0.0038042424712330103,
      "learning_rate": 2.556831683168317e-05,
      "loss": 0.0002,
      "step": 6670
    },
    {
      "epoch": 1.5268571428571427,
      "grad_norm": 0.0053701139986515045,
      "learning_rate": 2.552871287128713e-05,
      "loss": 0.0002,
      "step": 6680
    },
    {
      "epoch": 1.5291428571428571,
      "grad_norm": 0.0028593873139470816,
      "learning_rate": 2.548910891089109e-05,
      "loss": 0.0002,
      "step": 6690
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 0.005945874378085136,
      "learning_rate": 2.5449504950495052e-05,
      "loss": 0.0001,
      "step": 6700
    },
    {
      "epoch": 1.5337142857142858,
      "grad_norm": 0.006752066779881716,
      "learning_rate": 2.5409900990099013e-05,
      "loss": 0.0018,
      "step": 6710
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.004528960213065147,
      "learning_rate": 2.537029702970297e-05,
      "loss": 0.0016,
      "step": 6720
    },
    {
      "epoch": 1.5382857142857143,
      "grad_norm": 0.0034136853646486998,
      "learning_rate": 2.533069306930693e-05,
      "loss": 0.0001,
      "step": 6730
    },
    {
      "epoch": 1.5405714285714285,
      "grad_norm": 0.0015134820714592934,
      "learning_rate": 2.5291089108910892e-05,
      "loss": 0.0001,
      "step": 6740
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.00416509760543704,
      "learning_rate": 2.5251485148514853e-05,
      "loss": 0.012,
      "step": 6750
    },
    {
      "epoch": 1.5451428571428572,
      "grad_norm": 0.0022759903222322464,
      "learning_rate": 2.5211881188118814e-05,
      "loss": 0.0433,
      "step": 6760
    },
    {
      "epoch": 1.5474285714285714,
      "grad_norm": 0.005906573496758938,
      "learning_rate": 2.5172277227722775e-05,
      "loss": 0.0009,
      "step": 6770
    },
    {
      "epoch": 1.5497142857142858,
      "grad_norm": 0.14617820084095,
      "learning_rate": 2.5132673267326732e-05,
      "loss": 0.0017,
      "step": 6780
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.005637835711240768,
      "learning_rate": 2.5093069306930693e-05,
      "loss": 0.0002,
      "step": 6790
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 0.005445328541100025,
      "learning_rate": 2.5053465346534654e-05,
      "loss": 0.0013,
      "step": 6800
    },
    {
      "epoch": 1.5565714285714285,
      "grad_norm": 0.0011143959127366543,
      "learning_rate": 2.5013861386138615e-05,
      "loss": 0.0017,
      "step": 6810
    },
    {
      "epoch": 1.5588571428571427,
      "grad_norm": 0.003938006702810526,
      "learning_rate": 2.4974257425742576e-05,
      "loss": 0.0001,
      "step": 6820
    },
    {
      "epoch": 1.5611428571428572,
      "grad_norm": 0.0033501232974231243,
      "learning_rate": 2.4934653465346537e-05,
      "loss": 0.0002,
      "step": 6830
    },
    {
      "epoch": 1.5634285714285714,
      "grad_norm": 0.0027369444724172354,
      "learning_rate": 2.4895049504950498e-05,
      "loss": 0.0001,
      "step": 6840
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 0.0015366873703897,
      "learning_rate": 2.4855445544554455e-05,
      "loss": 0.0147,
      "step": 6850
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.002948399865999818,
      "learning_rate": 2.4815841584158416e-05,
      "loss": 0.0003,
      "step": 6860
    },
    {
      "epoch": 1.5702857142857143,
      "grad_norm": 0.0057292175479233265,
      "learning_rate": 2.4776237623762377e-05,
      "loss": 0.0001,
      "step": 6870
    },
    {
      "epoch": 1.5725714285714285,
      "grad_norm": 0.0018838646356016397,
      "learning_rate": 2.4736633663366338e-05,
      "loss": 0.0001,
      "step": 6880
    },
    {
      "epoch": 1.5748571428571427,
      "grad_norm": 0.0032939002849161625,
      "learning_rate": 2.46970297029703e-05,
      "loss": 0.0018,
      "step": 6890
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 0.00418966356664896,
      "learning_rate": 2.465742574257426e-05,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 1.5794285714285714,
      "grad_norm": 0.002549033612012863,
      "learning_rate": 2.4617821782178217e-05,
      "loss": 0.0001,
      "step": 6910
    },
    {
      "epoch": 1.5817142857142859,
      "grad_norm": 0.0028505718801170588,
      "learning_rate": 2.4578217821782178e-05,
      "loss": 0.0429,
      "step": 6920
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.00970774982124567,
      "learning_rate": 2.453861386138614e-05,
      "loss": 0.0001,
      "step": 6930
    },
    {
      "epoch": 1.5862857142857143,
      "grad_norm": 0.0035547681618481874,
      "learning_rate": 2.44990099009901e-05,
      "loss": 0.0002,
      "step": 6940
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 0.008120470680296421,
      "learning_rate": 2.445940594059406e-05,
      "loss": 0.0049,
      "step": 6950
    },
    {
      "epoch": 1.5908571428571427,
      "grad_norm": 0.004277293104678392,
      "learning_rate": 2.441980198019802e-05,
      "loss": 0.0001,
      "step": 6960
    },
    {
      "epoch": 1.5931428571428572,
      "grad_norm": 0.0029765276703983545,
      "learning_rate": 2.4380198019801982e-05,
      "loss": 0.0004,
      "step": 6970
    },
    {
      "epoch": 1.5954285714285714,
      "grad_norm": 0.013103795237839222,
      "learning_rate": 2.434059405940594e-05,
      "loss": 0.0002,
      "step": 6980
    },
    {
      "epoch": 1.5977142857142859,
      "grad_norm": 0.003925963770598173,
      "learning_rate": 2.43009900990099e-05,
      "loss": 0.0004,
      "step": 6990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0008961613639257848,
      "learning_rate": 2.426138613861386e-05,
      "loss": 0.0001,
      "step": 7000
    },
    {
      "epoch": 1.6022857142857143,
      "grad_norm": 0.0030388275627046824,
      "learning_rate": 2.4221782178217822e-05,
      "loss": 0.0001,
      "step": 7010
    },
    {
      "epoch": 1.6045714285714285,
      "grad_norm": 0.002941784681752324,
      "learning_rate": 2.4182178217821783e-05,
      "loss": 0.0001,
      "step": 7020
    },
    {
      "epoch": 1.6068571428571428,
      "grad_norm": 0.002243573311716318,
      "learning_rate": 2.4142574257425744e-05,
      "loss": 0.0256,
      "step": 7030
    },
    {
      "epoch": 1.609142857142857,
      "grad_norm": 0.004275276325643063,
      "learning_rate": 2.41029702970297e-05,
      "loss": 0.0002,
      "step": 7040
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 0.002184587763622403,
      "learning_rate": 2.4063366336633663e-05,
      "loss": 0.0016,
      "step": 7050
    },
    {
      "epoch": 1.6137142857142859,
      "grad_norm": 0.0025481891352683306,
      "learning_rate": 2.4023762376237623e-05,
      "loss": 0.0008,
      "step": 7060
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.0016185530694201589,
      "learning_rate": 2.3984158415841584e-05,
      "loss": 0.0001,
      "step": 7070
    },
    {
      "epoch": 1.6182857142857143,
      "grad_norm": 0.0039795818738639355,
      "learning_rate": 2.3944554455445545e-05,
      "loss": 0.0001,
      "step": 7080
    },
    {
      "epoch": 1.6205714285714286,
      "grad_norm": 0.001846281928010285,
      "learning_rate": 2.3904950495049506e-05,
      "loss": 0.0001,
      "step": 7090
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 0.009547514840960503,
      "learning_rate": 2.3865346534653467e-05,
      "loss": 0.0006,
      "step": 7100
    },
    {
      "epoch": 1.625142857142857,
      "grad_norm": 0.0016327457269653678,
      "learning_rate": 2.3825742574257424e-05,
      "loss": 0.0111,
      "step": 7110
    },
    {
      "epoch": 1.6274285714285714,
      "grad_norm": 0.0006406907341443002,
      "learning_rate": 2.3786138613861385e-05,
      "loss": 0.0009,
      "step": 7120
    },
    {
      "epoch": 1.6297142857142857,
      "grad_norm": 0.00047648526378907263,
      "learning_rate": 2.3746534653465346e-05,
      "loss": 0.0005,
      "step": 7130
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.0017483558040112257,
      "learning_rate": 2.3706930693069307e-05,
      "loss": 0.0001,
      "step": 7140
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 0.0015672283479943871,
      "learning_rate": 2.3667326732673268e-05,
      "loss": 0.0005,
      "step": 7150
    },
    {
      "epoch": 1.6365714285714286,
      "grad_norm": 0.001817789627239108,
      "learning_rate": 2.362772277227723e-05,
      "loss": 0.02,
      "step": 7160
    },
    {
      "epoch": 1.6388571428571428,
      "grad_norm": 0.0013369505759328604,
      "learning_rate": 2.358811881188119e-05,
      "loss": 0.0001,
      "step": 7170
    },
    {
      "epoch": 1.641142857142857,
      "grad_norm": 0.0012584616197273135,
      "learning_rate": 2.3548514851485147e-05,
      "loss": 0.0082,
      "step": 7180
    },
    {
      "epoch": 1.6434285714285715,
      "grad_norm": 0.0019452626584097743,
      "learning_rate": 2.3508910891089108e-05,
      "loss": 0.0008,
      "step": 7190
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.41293829679489136,
      "learning_rate": 2.346930693069307e-05,
      "loss": 0.0096,
      "step": 7200
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.002289065159857273,
      "learning_rate": 2.3429702970297033e-05,
      "loss": 0.0025,
      "step": 7210
    },
    {
      "epoch": 1.6502857142857144,
      "grad_norm": 0.0006870593060739338,
      "learning_rate": 2.3390099009900994e-05,
      "loss": 0.0001,
      "step": 7220
    },
    {
      "epoch": 1.6525714285714286,
      "grad_norm": 0.0024687531404197216,
      "learning_rate": 2.335049504950495e-05,
      "loss": 0.0008,
      "step": 7230
    },
    {
      "epoch": 1.6548571428571428,
      "grad_norm": 0.0014819907955825329,
      "learning_rate": 2.3310891089108912e-05,
      "loss": 0.0076,
      "step": 7240
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.002537210937589407,
      "learning_rate": 2.3271287128712873e-05,
      "loss": 0.0001,
      "step": 7250
    },
    {
      "epoch": 1.6594285714285715,
      "grad_norm": 0.0017201467417180538,
      "learning_rate": 2.3231683168316834e-05,
      "loss": 0.0033,
      "step": 7260
    },
    {
      "epoch": 1.6617142857142857,
      "grad_norm": 0.0022050447296351194,
      "learning_rate": 2.3192079207920795e-05,
      "loss": 0.0024,
      "step": 7270
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.0024438039399683475,
      "learning_rate": 2.3152475247524756e-05,
      "loss": 0.0161,
      "step": 7280
    },
    {
      "epoch": 1.6662857142857144,
      "grad_norm": 0.003263952676206827,
      "learning_rate": 2.3112871287128713e-05,
      "loss": 0.0032,
      "step": 7290
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 0.0015474067768082023,
      "learning_rate": 2.3073267326732674e-05,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 1.6708571428571428,
      "grad_norm": 0.0018871863139793277,
      "learning_rate": 2.3033663366336635e-05,
      "loss": 0.0001,
      "step": 7310
    },
    {
      "epoch": 1.673142857142857,
      "grad_norm": 0.002020597690716386,
      "learning_rate": 2.2994059405940596e-05,
      "loss": 0.0001,
      "step": 7320
    },
    {
      "epoch": 1.6754285714285713,
      "grad_norm": 3.451680458965711e-05,
      "learning_rate": 2.2954455445544557e-05,
      "loss": 0.0,
      "step": 7330
    },
    {
      "epoch": 1.6777142857142857,
      "grad_norm": 0.0013958156341686845,
      "learning_rate": 2.2914851485148518e-05,
      "loss": 0.009,
      "step": 7340
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.10216512531042099,
      "learning_rate": 2.287524752475248e-05,
      "loss": 0.0018,
      "step": 7350
    },
    {
      "epoch": 1.6822857142857144,
      "grad_norm": 0.00037649591104127467,
      "learning_rate": 2.2835643564356436e-05,
      "loss": 0.0039,
      "step": 7360
    },
    {
      "epoch": 1.6845714285714286,
      "grad_norm": 0.0009628406260162592,
      "learning_rate": 2.2796039603960397e-05,
      "loss": 0.0016,
      "step": 7370
    },
    {
      "epoch": 1.6868571428571428,
      "grad_norm": 0.001315094530582428,
      "learning_rate": 2.2756435643564358e-05,
      "loss": 0.0012,
      "step": 7380
    },
    {
      "epoch": 1.689142857142857,
      "grad_norm": 0.0013818717561662197,
      "learning_rate": 2.271683168316832e-05,
      "loss": 0.003,
      "step": 7390
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 0.0009065489284694195,
      "learning_rate": 2.267722772277228e-05,
      "loss": 0.002,
      "step": 7400
    },
    {
      "epoch": 1.6937142857142857,
      "grad_norm": 0.056314073503017426,
      "learning_rate": 2.263762376237624e-05,
      "loss": 0.0019,
      "step": 7410
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.001159497071057558,
      "learning_rate": 2.25980198019802e-05,
      "loss": 0.0084,
      "step": 7420
    },
    {
      "epoch": 1.6982857142857144,
      "grad_norm": 3.772495256271213e-05,
      "learning_rate": 2.255841584158416e-05,
      "loss": 0.0,
      "step": 7430
    },
    {
      "epoch": 1.7005714285714286,
      "grad_norm": 0.002153853652998805,
      "learning_rate": 2.251881188118812e-05,
      "loss": 0.0207,
      "step": 7440
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 0.0017139019910246134,
      "learning_rate": 2.247920792079208e-05,
      "loss": 0.0005,
      "step": 7450
    },
    {
      "epoch": 1.705142857142857,
      "grad_norm": 0.0010885726660490036,
      "learning_rate": 2.243960396039604e-05,
      "loss": 0.0008,
      "step": 7460
    },
    {
      "epoch": 1.7074285714285713,
      "grad_norm": 0.0002545272873248905,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0,
      "step": 7470
    },
    {
      "epoch": 1.7097142857142857,
      "grad_norm": 0.0014858548529446125,
      "learning_rate": 2.2360396039603963e-05,
      "loss": 0.0001,
      "step": 7480
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.0013897594762966037,
      "learning_rate": 2.232079207920792e-05,
      "loss": 0.0,
      "step": 7490
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.000933450588490814,
      "learning_rate": 2.228118811881188e-05,
      "loss": 0.0007,
      "step": 7500
    },
    {
      "epoch": 1.7165714285714286,
      "grad_norm": 0.0012810492189601064,
      "learning_rate": 2.2241584158415842e-05,
      "loss": 0.0,
      "step": 7510
    },
    {
      "epoch": 1.7188571428571429,
      "grad_norm": 0.0007191551849246025,
      "learning_rate": 2.2201980198019803e-05,
      "loss": 0.0007,
      "step": 7520
    },
    {
      "epoch": 1.721142857142857,
      "grad_norm": 0.00043917959555983543,
      "learning_rate": 2.2162376237623764e-05,
      "loss": 0.001,
      "step": 7530
    },
    {
      "epoch": 1.7234285714285713,
      "grad_norm": 0.0005463561974465847,
      "learning_rate": 2.2122772277227725e-05,
      "loss": 0.0024,
      "step": 7540
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 0.0009815102675929666,
      "learning_rate": 2.2083168316831686e-05,
      "loss": 0.0,
      "step": 7550
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.0005609096842817962,
      "learning_rate": 2.2043564356435643e-05,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 1.7302857142857144,
      "grad_norm": 0.0013042076025158167,
      "learning_rate": 2.2003960396039604e-05,
      "loss": 0.0,
      "step": 7570
    },
    {
      "epoch": 1.7325714285714287,
      "grad_norm": 0.0009706258424557745,
      "learning_rate": 2.1964356435643565e-05,
      "loss": 0.0,
      "step": 7580
    },
    {
      "epoch": 1.7348571428571429,
      "grad_norm": 0.0006300978129729629,
      "learning_rate": 2.1924752475247526e-05,
      "loss": 0.0005,
      "step": 7590
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 0.0012265507830306888,
      "learning_rate": 2.1885148514851487e-05,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 1.7394285714285713,
      "grad_norm": 0.002099728910252452,
      "learning_rate": 2.1845544554455448e-05,
      "loss": 0.0,
      "step": 7610
    },
    {
      "epoch": 1.7417142857142855,
      "grad_norm": 0.0014312205603346229,
      "learning_rate": 2.1805940594059405e-05,
      "loss": 0.0,
      "step": 7620
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.0005856758798472583,
      "learning_rate": 2.1766336633663366e-05,
      "loss": 0.0004,
      "step": 7630
    },
    {
      "epoch": 1.7462857142857144,
      "grad_norm": 0.00029086318681947887,
      "learning_rate": 2.1726732673267327e-05,
      "loss": 0.001,
      "step": 7640
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 0.0004821009060833603,
      "learning_rate": 2.1687128712871288e-05,
      "loss": 0.0,
      "step": 7650
    },
    {
      "epoch": 1.750857142857143,
      "grad_norm": 0.00035033293534070253,
      "learning_rate": 2.164752475247525e-05,
      "loss": 0.0004,
      "step": 7660
    },
    {
      "epoch": 1.7531428571428571,
      "grad_norm": 0.0007960789371281862,
      "learning_rate": 2.160792079207921e-05,
      "loss": 0.0006,
      "step": 7670
    },
    {
      "epoch": 1.7554285714285713,
      "grad_norm": 0.0019233048660680652,
      "learning_rate": 2.156831683168317e-05,
      "loss": 0.0,
      "step": 7680
    },
    {
      "epoch": 1.7577142857142856,
      "grad_norm": 0.0026254686526954174,
      "learning_rate": 2.1528712871287128e-05,
      "loss": 0.01,
      "step": 7690
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.0015227114781737328,
      "learning_rate": 2.148910891089109e-05,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 1.7622857142857142,
      "grad_norm": 0.2961210310459137,
      "learning_rate": 2.144950495049505e-05,
      "loss": 0.0101,
      "step": 7710
    },
    {
      "epoch": 1.7645714285714287,
      "grad_norm": 0.0002917996607720852,
      "learning_rate": 2.140990099009901e-05,
      "loss": 0.0,
      "step": 7720
    },
    {
      "epoch": 1.766857142857143,
      "grad_norm": 0.0011275789001956582,
      "learning_rate": 2.137029702970297e-05,
      "loss": 0.0,
      "step": 7730
    },
    {
      "epoch": 1.7691428571428571,
      "grad_norm": 0.0014852527529001236,
      "learning_rate": 2.1330693069306932e-05,
      "loss": 0.0008,
      "step": 7740
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.0005110761849209666,
      "learning_rate": 2.129108910891089e-05,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 1.7737142857142856,
      "grad_norm": 0.0009649557177908719,
      "learning_rate": 2.125148514851485e-05,
      "loss": 0.0,
      "step": 7760
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.001142585533671081,
      "learning_rate": 2.1211881188118812e-05,
      "loss": 0.0027,
      "step": 7770
    },
    {
      "epoch": 1.7782857142857142,
      "grad_norm": 0.0008659209124743938,
      "learning_rate": 2.1172277227722773e-05,
      "loss": 0.0023,
      "step": 7780
    },
    {
      "epoch": 1.7805714285714287,
      "grad_norm": 0.0005813399329781532,
      "learning_rate": 2.1132673267326733e-05,
      "loss": 0.0085,
      "step": 7790
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 0.04633157700300217,
      "learning_rate": 2.1093069306930694e-05,
      "loss": 0.0003,
      "step": 7800
    },
    {
      "epoch": 1.7851428571428571,
      "grad_norm": 0.0006297595100477338,
      "learning_rate": 2.1053465346534655e-05,
      "loss": 0.0003,
      "step": 7810
    },
    {
      "epoch": 1.7874285714285714,
      "grad_norm": 0.0008718896424397826,
      "learning_rate": 2.1013861386138613e-05,
      "loss": 0.0,
      "step": 7820
    },
    {
      "epoch": 1.7897142857142856,
      "grad_norm": 0.0011555772507563233,
      "learning_rate": 2.0974257425742574e-05,
      "loss": 0.0,
      "step": 7830
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.0019869657699018717,
      "learning_rate": 2.0934653465346534e-05,
      "loss": 0.0069,
      "step": 7840
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 0.0002543033624533564,
      "learning_rate": 2.0895049504950495e-05,
      "loss": 0.0003,
      "step": 7850
    },
    {
      "epoch": 1.7965714285714287,
      "grad_norm": 0.0006971170660108328,
      "learning_rate": 2.0855445544554456e-05,
      "loss": 0.0,
      "step": 7860
    },
    {
      "epoch": 1.798857142857143,
      "grad_norm": 0.00100419158115983,
      "learning_rate": 2.0815841584158417e-05,
      "loss": 0.0,
      "step": 7870
    },
    {
      "epoch": 1.8011428571428572,
      "grad_norm": 0.0011908573796972632,
      "learning_rate": 2.0776237623762375e-05,
      "loss": 0.0072,
      "step": 7880
    },
    {
      "epoch": 1.8034285714285714,
      "grad_norm": 0.0012177388416603208,
      "learning_rate": 2.0736633663366335e-05,
      "loss": 0.0,
      "step": 7890
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 0.0006414800300262868,
      "learning_rate": 2.0697029702970296e-05,
      "loss": 0.0011,
      "step": 7900
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.00027853596839122474,
      "learning_rate": 2.0657425742574257e-05,
      "loss": 0.0,
      "step": 7910
    },
    {
      "epoch": 1.8102857142857143,
      "grad_norm": 0.0005900994292460382,
      "learning_rate": 2.0617821782178218e-05,
      "loss": 0.0,
      "step": 7920
    },
    {
      "epoch": 1.8125714285714287,
      "grad_norm": 0.0007899738266132772,
      "learning_rate": 2.057821782178218e-05,
      "loss": 0.0035,
      "step": 7930
    },
    {
      "epoch": 1.814857142857143,
      "grad_norm": 3.4343702282058075e-05,
      "learning_rate": 2.053861386138614e-05,
      "loss": 0.0095,
      "step": 7940
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 0.00045567157212644815,
      "learning_rate": 2.0499009900990097e-05,
      "loss": 0.0034,
      "step": 7950
    },
    {
      "epoch": 1.8194285714285714,
      "grad_norm": 0.00044267610064707696,
      "learning_rate": 2.0459405940594058e-05,
      "loss": 0.0,
      "step": 7960
    },
    {
      "epoch": 1.8217142857142856,
      "grad_norm": 0.0003282260149717331,
      "learning_rate": 2.041980198019802e-05,
      "loss": 0.0067,
      "step": 7970
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.0003755087382160127,
      "learning_rate": 2.038019801980198e-05,
      "loss": 0.0,
      "step": 7980
    },
    {
      "epoch": 1.8262857142857143,
      "grad_norm": 0.0011618140852078795,
      "learning_rate": 2.034059405940594e-05,
      "loss": 0.022,
      "step": 7990
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.000979248434305191,
      "learning_rate": 2.03009900990099e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 1.830857142857143,
      "grad_norm": 0.0005200215964578092,
      "learning_rate": 2.0261386138613863e-05,
      "loss": 0.0,
      "step": 8010
    },
    {
      "epoch": 1.8331428571428572,
      "grad_norm": 0.000775799504481256,
      "learning_rate": 2.0221782178217823e-05,
      "loss": 0.0009,
      "step": 8020
    },
    {
      "epoch": 1.8354285714285714,
      "grad_norm": 0.000982710043899715,
      "learning_rate": 2.0182178217821784e-05,
      "loss": 0.0003,
      "step": 8030
    },
    {
      "epoch": 1.8377142857142856,
      "grad_norm": 0.0016086590476334095,
      "learning_rate": 2.0142574257425745e-05,
      "loss": 0.0,
      "step": 8040
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.618481787270866e-05,
      "learning_rate": 2.0102970297029706e-05,
      "loss": 0.0,
      "step": 8050
    },
    {
      "epoch": 1.8422857142857143,
      "grad_norm": 0.0010802375618368387,
      "learning_rate": 2.0063366336633667e-05,
      "loss": 0.0,
      "step": 8060
    },
    {
      "epoch": 1.8445714285714285,
      "grad_norm": 0.0006178580806590617,
      "learning_rate": 2.0023762376237624e-05,
      "loss": 0.0004,
      "step": 8070
    },
    {
      "epoch": 1.846857142857143,
      "grad_norm": 0.0006108914967626333,
      "learning_rate": 1.9984158415841585e-05,
      "loss": 0.0,
      "step": 8080
    },
    {
      "epoch": 1.8491428571428572,
      "grad_norm": 0.00014976215607021004,
      "learning_rate": 1.9944554455445546e-05,
      "loss": 0.0,
      "step": 8090
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 0.04141848161816597,
      "learning_rate": 1.9904950495049507e-05,
      "loss": 0.0009,
      "step": 8100
    },
    {
      "epoch": 1.8537142857142856,
      "grad_norm": 0.00041986769065260887,
      "learning_rate": 1.9865346534653468e-05,
      "loss": 0.0,
      "step": 8110
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.00047999038361012936,
      "learning_rate": 1.982574257425743e-05,
      "loss": 0.0004,
      "step": 8120
    },
    {
      "epoch": 1.8582857142857143,
      "grad_norm": 0.0005216775462031364,
      "learning_rate": 1.978613861386139e-05,
      "loss": 0.0,
      "step": 8130
    },
    {
      "epoch": 1.8605714285714285,
      "grad_norm": 0.0009674479370005429,
      "learning_rate": 1.9746534653465347e-05,
      "loss": 0.0,
      "step": 8140
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 0.00030250794952735305,
      "learning_rate": 1.9706930693069308e-05,
      "loss": 0.0,
      "step": 8150
    },
    {
      "epoch": 1.8651428571428572,
      "grad_norm": 0.0013546422123908997,
      "learning_rate": 1.966732673267327e-05,
      "loss": 0.0004,
      "step": 8160
    },
    {
      "epoch": 1.8674285714285714,
      "grad_norm": 0.0005338580231182277,
      "learning_rate": 1.962772277227723e-05,
      "loss": 0.0204,
      "step": 8170
    },
    {
      "epoch": 1.8697142857142857,
      "grad_norm": 2.825683623086661e-05,
      "learning_rate": 1.958811881188119e-05,
      "loss": 0.0035,
      "step": 8180
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.0006254573236219585,
      "learning_rate": 1.954851485148515e-05,
      "loss": 0.0,
      "step": 8190
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 0.06611252576112747,
      "learning_rate": 1.950891089108911e-05,
      "loss": 0.0015,
      "step": 8200
    },
    {
      "epoch": 1.8765714285714286,
      "grad_norm": 0.0005480232648551464,
      "learning_rate": 1.946930693069307e-05,
      "loss": 0.0004,
      "step": 8210
    },
    {
      "epoch": 1.878857142857143,
      "grad_norm": 0.08506559580564499,
      "learning_rate": 1.942970297029703e-05,
      "loss": 0.0006,
      "step": 8220
    },
    {
      "epoch": 1.8811428571428572,
      "grad_norm": 0.002050786977633834,
      "learning_rate": 1.939009900990099e-05,
      "loss": 0.0,
      "step": 8230
    },
    {
      "epoch": 1.8834285714285715,
      "grad_norm": 0.0751539096236229,
      "learning_rate": 1.9350495049504953e-05,
      "loss": 0.0177,
      "step": 8240
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 2.667268199729733e-05,
      "learning_rate": 1.9310891089108913e-05,
      "loss": 0.003,
      "step": 8250
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.0006147101521492004,
      "learning_rate": 1.9271287128712874e-05,
      "loss": 0.0005,
      "step": 8260
    },
    {
      "epoch": 1.8902857142857141,
      "grad_norm": 0.00035922485403716564,
      "learning_rate": 1.9231683168316832e-05,
      "loss": 0.0,
      "step": 8270
    },
    {
      "epoch": 1.8925714285714286,
      "grad_norm": 0.0006613520090468228,
      "learning_rate": 1.9192079207920793e-05,
      "loss": 0.0,
      "step": 8280
    },
    {
      "epoch": 1.894857142857143,
      "grad_norm": 0.0007935210596770048,
      "learning_rate": 1.9152475247524754e-05,
      "loss": 0.0,
      "step": 8290
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 0.0009594336152076721,
      "learning_rate": 1.9112871287128714e-05,
      "loss": 0.0016,
      "step": 8300
    },
    {
      "epoch": 1.8994285714285715,
      "grad_norm": 0.0004422111960593611,
      "learning_rate": 1.9073267326732675e-05,
      "loss": 0.006,
      "step": 8310
    },
    {
      "epoch": 1.9017142857142857,
      "grad_norm": 0.00033891727798618376,
      "learning_rate": 1.9033663366336636e-05,
      "loss": 0.0,
      "step": 8320
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.0009446774492971599,
      "learning_rate": 1.8994059405940594e-05,
      "loss": 0.0,
      "step": 8330
    },
    {
      "epoch": 1.9062857142857141,
      "grad_norm": 0.0004628608003258705,
      "learning_rate": 1.8954455445544555e-05,
      "loss": 0.0008,
      "step": 8340
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 0.000461369170807302,
      "learning_rate": 1.8914851485148515e-05,
      "loss": 0.0,
      "step": 8350
    },
    {
      "epoch": 1.9108571428571428,
      "grad_norm": 0.0007767126080580056,
      "learning_rate": 1.8875247524752476e-05,
      "loss": 0.0007,
      "step": 8360
    },
    {
      "epoch": 1.9131428571428573,
      "grad_norm": 0.0003946627548430115,
      "learning_rate": 1.8835643564356437e-05,
      "loss": 0.0034,
      "step": 8370
    },
    {
      "epoch": 1.9154285714285715,
      "grad_norm": 0.00043918946175836027,
      "learning_rate": 1.8796039603960398e-05,
      "loss": 0.0005,
      "step": 8380
    },
    {
      "epoch": 1.9177142857142857,
      "grad_norm": 0.0005166240152902901,
      "learning_rate": 1.875643564356436e-05,
      "loss": 0.0004,
      "step": 8390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0005753371515311301,
      "learning_rate": 1.8716831683168316e-05,
      "loss": 0.0004,
      "step": 8400
    },
    {
      "epoch": 1.9222857142857142,
      "grad_norm": 0.0005967525648884475,
      "learning_rate": 1.8677227722772277e-05,
      "loss": 0.0,
      "step": 8410
    },
    {
      "epoch": 1.9245714285714286,
      "grad_norm": 0.0005507425521500409,
      "learning_rate": 1.8637623762376238e-05,
      "loss": 0.0005,
      "step": 8420
    },
    {
      "epoch": 1.9268571428571428,
      "grad_norm": 0.00015790459292475134,
      "learning_rate": 1.85980198019802e-05,
      "loss": 0.0004,
      "step": 8430
    },
    {
      "epoch": 1.9291428571428573,
      "grad_norm": 0.00025196606293320656,
      "learning_rate": 1.855841584158416e-05,
      "loss": 0.0004,
      "step": 8440
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.0006448167259804904,
      "learning_rate": 1.851881188118812e-05,
      "loss": 0.0,
      "step": 8450
    },
    {
      "epoch": 1.9337142857142857,
      "grad_norm": 0.0006435700342990458,
      "learning_rate": 1.8479207920792078e-05,
      "loss": 0.0004,
      "step": 8460
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.0005409720470197499,
      "learning_rate": 1.843960396039604e-05,
      "loss": 0.0161,
      "step": 8470
    },
    {
      "epoch": 1.9382857142857142,
      "grad_norm": 0.0003575590963009745,
      "learning_rate": 1.84e-05,
      "loss": 0.0007,
      "step": 8480
    },
    {
      "epoch": 1.9405714285714286,
      "grad_norm": 0.0001085519979824312,
      "learning_rate": 1.836039603960396e-05,
      "loss": 0.0012,
      "step": 8490
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 0.00015235572936944664,
      "learning_rate": 1.8320792079207922e-05,
      "loss": 0.0006,
      "step": 8500
    },
    {
      "epoch": 1.9451428571428573,
      "grad_norm": 0.00027594342827796936,
      "learning_rate": 1.8281188118811883e-05,
      "loss": 0.0039,
      "step": 8510
    },
    {
      "epoch": 1.9474285714285715,
      "grad_norm": 0.0009467391646467149,
      "learning_rate": 1.8241584158415844e-05,
      "loss": 0.0005,
      "step": 8520
    },
    {
      "epoch": 1.9497142857142857,
      "grad_norm": 0.08598512411117554,
      "learning_rate": 1.82019801980198e-05,
      "loss": 0.0568,
      "step": 8530
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.0016597210196778178,
      "learning_rate": 1.8162376237623762e-05,
      "loss": 0.0007,
      "step": 8540
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 0.00033221906051039696,
      "learning_rate": 1.8122772277227723e-05,
      "loss": 0.0122,
      "step": 8550
    },
    {
      "epoch": 1.9565714285714284,
      "grad_norm": 0.0008718306780792773,
      "learning_rate": 1.8083168316831684e-05,
      "loss": 0.0,
      "step": 8560
    },
    {
      "epoch": 1.9588571428571429,
      "grad_norm": 0.0016650849720463157,
      "learning_rate": 1.8043564356435645e-05,
      "loss": 0.002,
      "step": 8570
    },
    {
      "epoch": 1.9611428571428573,
      "grad_norm": 0.001298374030739069,
      "learning_rate": 1.8003960396039605e-05,
      "loss": 0.0,
      "step": 8580
    },
    {
      "epoch": 1.9634285714285715,
      "grad_norm": 0.04829859733581543,
      "learning_rate": 1.7964356435643563e-05,
      "loss": 0.0006,
      "step": 8590
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 0.0006354667712002993,
      "learning_rate": 1.7924752475247524e-05,
      "loss": 0.0002,
      "step": 8600
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.000816226121969521,
      "learning_rate": 1.7885148514851485e-05,
      "loss": 0.0,
      "step": 8610
    },
    {
      "epoch": 1.9702857142857142,
      "grad_norm": 0.0005389770376496017,
      "learning_rate": 1.7845544554455446e-05,
      "loss": 0.0,
      "step": 8620
    },
    {
      "epoch": 1.9725714285714284,
      "grad_norm": 0.0007266780594363809,
      "learning_rate": 1.7805940594059406e-05,
      "loss": 0.0004,
      "step": 8630
    },
    {
      "epoch": 1.9748571428571429,
      "grad_norm": 0.0011090401094406843,
      "learning_rate": 1.7766336633663367e-05,
      "loss": 0.0004,
      "step": 8640
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 5.245438660494983e-05,
      "learning_rate": 1.7726732673267328e-05,
      "loss": 0.0001,
      "step": 8650
    },
    {
      "epoch": 1.9794285714285715,
      "grad_norm": 0.0011313739232718945,
      "learning_rate": 1.7687128712871286e-05,
      "loss": 0.0078,
      "step": 8660
    },
    {
      "epoch": 1.9817142857142858,
      "grad_norm": 0.00029084982816129923,
      "learning_rate": 1.7647524752475246e-05,
      "loss": 0.0,
      "step": 8670
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.0002096618409268558,
      "learning_rate": 1.7607920792079207e-05,
      "loss": 0.0003,
      "step": 8680
    },
    {
      "epoch": 1.9862857142857142,
      "grad_norm": 0.0009051481611095369,
      "learning_rate": 1.7568316831683168e-05,
      "loss": 0.0001,
      "step": 8690
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 0.0012580964248627424,
      "learning_rate": 1.752871287128713e-05,
      "loss": 0.0001,
      "step": 8700
    },
    {
      "epoch": 1.9908571428571429,
      "grad_norm": 0.0005887565203011036,
      "learning_rate": 1.748910891089109e-05,
      "loss": 0.0093,
      "step": 8710
    },
    {
      "epoch": 1.993142857142857,
      "grad_norm": 0.0009224558598361909,
      "learning_rate": 1.744950495049505e-05,
      "loss": 0.022,
      "step": 8720
    },
    {
      "epoch": 1.9954285714285716,
      "grad_norm": 0.00037390575744211674,
      "learning_rate": 1.740990099009901e-05,
      "loss": 0.0004,
      "step": 8730
    },
    {
      "epoch": 1.9977142857142858,
      "grad_norm": 0.0005427172873169184,
      "learning_rate": 1.737029702970297e-05,
      "loss": 0.0005,
      "step": 8740
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0003519939782563597,
      "learning_rate": 1.733069306930693e-05,
      "loss": 0.0009,
      "step": 8750
    },
    {
      "epoch": 2.0022857142857142,
      "grad_norm": 0.0009536645375192165,
      "learning_rate": 1.729108910891089e-05,
      "loss": 0.0,
      "step": 8760
    },
    {
      "epoch": 2.0045714285714284,
      "grad_norm": 0.0002782169613055885,
      "learning_rate": 1.7251485148514852e-05,
      "loss": 0.0,
      "step": 8770
    },
    {
      "epoch": 2.0068571428571427,
      "grad_norm": 0.00058135692961514,
      "learning_rate": 1.7211881188118813e-05,
      "loss": 0.0,
      "step": 8780
    },
    {
      "epoch": 2.0091428571428573,
      "grad_norm": 0.06570351123809814,
      "learning_rate": 1.7172277227722774e-05,
      "loss": 0.0014,
      "step": 8790
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.0041921017691493034,
      "learning_rate": 1.7132673267326734e-05,
      "loss": 0.0005,
      "step": 8800
    },
    {
      "epoch": 2.013714285714286,
      "grad_norm": 0.00041969987796619534,
      "learning_rate": 1.7093069306930695e-05,
      "loss": 0.0,
      "step": 8810
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.0010758558055385947,
      "learning_rate": 1.7053465346534656e-05,
      "loss": 0.0027,
      "step": 8820
    },
    {
      "epoch": 2.0182857142857142,
      "grad_norm": 0.008334449492394924,
      "learning_rate": 1.7013861386138617e-05,
      "loss": 0.0001,
      "step": 8830
    },
    {
      "epoch": 2.0205714285714285,
      "grad_norm": 0.0009163485956378281,
      "learning_rate": 1.6974257425742575e-05,
      "loss": 0.0,
      "step": 8840
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 5.575149043579586e-05,
      "learning_rate": 1.6934653465346535e-05,
      "loss": 0.0004,
      "step": 8850
    },
    {
      "epoch": 2.0251428571428574,
      "grad_norm": 0.0011221157619729638,
      "learning_rate": 1.6895049504950496e-05,
      "loss": 0.0,
      "step": 8860
    },
    {
      "epoch": 2.0274285714285716,
      "grad_norm": 0.06070102006196976,
      "learning_rate": 1.6855445544554457e-05,
      "loss": 0.0004,
      "step": 8870
    },
    {
      "epoch": 2.029714285714286,
      "grad_norm": 0.0004092137096449733,
      "learning_rate": 1.6815841584158418e-05,
      "loss": 0.0005,
      "step": 8880
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.0005131305661052465,
      "learning_rate": 1.677623762376238e-05,
      "loss": 0.0,
      "step": 8890
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.0008549217018298805,
      "learning_rate": 1.673663366336634e-05,
      "loss": 0.0004,
      "step": 8900
    },
    {
      "epoch": 2.0365714285714285,
      "grad_norm": 0.0007955876062624156,
      "learning_rate": 1.6697029702970297e-05,
      "loss": 0.0003,
      "step": 8910
    },
    {
      "epoch": 2.0388571428571427,
      "grad_norm": 0.0008484519203193486,
      "learning_rate": 1.6657425742574258e-05,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 2.041142857142857,
      "grad_norm": 0.00016038240573834628,
      "learning_rate": 1.661782178217822e-05,
      "loss": 0.0031,
      "step": 8930
    },
    {
      "epoch": 2.0434285714285716,
      "grad_norm": 0.0005987592157907784,
      "learning_rate": 1.657821782178218e-05,
      "loss": 0.0151,
      "step": 8940
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 0.00032824050867930055,
      "learning_rate": 1.653861386138614e-05,
      "loss": 0.0004,
      "step": 8950
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.0011003492400050163,
      "learning_rate": 1.6499009900990102e-05,
      "loss": 0.0,
      "step": 8960
    },
    {
      "epoch": 2.0502857142857143,
      "grad_norm": 0.001308727078139782,
      "learning_rate": 1.6459405940594063e-05,
      "loss": 0.0,
      "step": 8970
    },
    {
      "epoch": 2.0525714285714285,
      "grad_norm": 0.00015036732656881213,
      "learning_rate": 1.641980198019802e-05,
      "loss": 0.0,
      "step": 8980
    },
    {
      "epoch": 2.0548571428571427,
      "grad_norm": 0.0011582380393519998,
      "learning_rate": 1.638019801980198e-05,
      "loss": 0.0,
      "step": 8990
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 0.00028868101071566343,
      "learning_rate": 1.6340594059405942e-05,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 2.0594285714285716,
      "grad_norm": 0.00016397192666772753,
      "learning_rate": 1.6300990099009903e-05,
      "loss": 0.0,
      "step": 9010
    },
    {
      "epoch": 2.061714285714286,
      "grad_norm": 0.0007510918658226728,
      "learning_rate": 1.6261386138613864e-05,
      "loss": 0.006,
      "step": 9020
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.002621567342430353,
      "learning_rate": 1.6221782178217824e-05,
      "loss": 0.0006,
      "step": 9030
    },
    {
      "epoch": 2.0662857142857143,
      "grad_norm": 0.00042510326602496207,
      "learning_rate": 1.6182178217821782e-05,
      "loss": 0.0,
      "step": 9040
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 0.0007220700499601662,
      "learning_rate": 1.6142574257425743e-05,
      "loss": 0.0005,
      "step": 9050
    },
    {
      "epoch": 2.0708571428571427,
      "grad_norm": 0.0010745906038209796,
      "learning_rate": 1.6102970297029704e-05,
      "loss": 0.0,
      "step": 9060
    },
    {
      "epoch": 2.073142857142857,
      "grad_norm": 0.0009861004073172808,
      "learning_rate": 1.6063366336633665e-05,
      "loss": 0.0,
      "step": 9070
    },
    {
      "epoch": 2.0754285714285716,
      "grad_norm": 0.0005352297448553145,
      "learning_rate": 1.6023762376237625e-05,
      "loss": 0.0,
      "step": 9080
    },
    {
      "epoch": 2.077714285714286,
      "grad_norm": 0.0007920988136902452,
      "learning_rate": 1.5984158415841586e-05,
      "loss": 0.003,
      "step": 9090
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.0003991110424976796,
      "learning_rate": 1.5944554455445547e-05,
      "loss": 0.0003,
      "step": 9100
    },
    {
      "epoch": 2.0822857142857143,
      "grad_norm": 0.000579498359002173,
      "learning_rate": 1.5904950495049505e-05,
      "loss": 0.0283,
      "step": 9110
    },
    {
      "epoch": 2.0845714285714285,
      "grad_norm": 0.06794163584709167,
      "learning_rate": 1.5865346534653466e-05,
      "loss": 0.0189,
      "step": 9120
    },
    {
      "epoch": 2.0868571428571427,
      "grad_norm": 0.0006020484725013375,
      "learning_rate": 1.5825742574257426e-05,
      "loss": 0.0005,
      "step": 9130
    },
    {
      "epoch": 2.089142857142857,
      "grad_norm": 0.0013498261105269194,
      "learning_rate": 1.5786138613861387e-05,
      "loss": 0.0034,
      "step": 9140
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 0.0006545817595906556,
      "learning_rate": 1.5746534653465348e-05,
      "loss": 0.0,
      "step": 9150
    },
    {
      "epoch": 2.093714285714286,
      "grad_norm": 0.00052553357090801,
      "learning_rate": 1.570693069306931e-05,
      "loss": 0.0013,
      "step": 9160
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.001144740148447454,
      "learning_rate": 1.5667326732673267e-05,
      "loss": 0.0,
      "step": 9170
    },
    {
      "epoch": 2.0982857142857143,
      "grad_norm": 0.001281488104723394,
      "learning_rate": 1.5627722772277227e-05,
      "loss": 0.0578,
      "step": 9180
    },
    {
      "epoch": 2.1005714285714285,
      "grad_norm": 0.017734868451952934,
      "learning_rate": 1.558811881188119e-05,
      "loss": 0.0007,
      "step": 9190
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 0.005559505894780159,
      "learning_rate": 1.554851485148515e-05,
      "loss": 0.0151,
      "step": 9200
    },
    {
      "epoch": 2.105142857142857,
      "grad_norm": 0.000615952885709703,
      "learning_rate": 1.550891089108911e-05,
      "loss": 0.0001,
      "step": 9210
    },
    {
      "epoch": 2.1074285714285717,
      "grad_norm": 0.0008721197955310345,
      "learning_rate": 1.546930693069307e-05,
      "loss": 0.0001,
      "step": 9220
    },
    {
      "epoch": 2.109714285714286,
      "grad_norm": 0.0013770610094070435,
      "learning_rate": 1.5429702970297032e-05,
      "loss": 0.0,
      "step": 9230
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.0006823808653280139,
      "learning_rate": 1.539009900990099e-05,
      "loss": 0.0001,
      "step": 9240
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 0.0011877836659550667,
      "learning_rate": 1.535049504950495e-05,
      "loss": 0.0103,
      "step": 9250
    },
    {
      "epoch": 2.1165714285714285,
      "grad_norm": 0.0019521209178492427,
      "learning_rate": 1.531089108910891e-05,
      "loss": 0.0001,
      "step": 9260
    },
    {
      "epoch": 2.1188571428571428,
      "grad_norm": 0.0007605823338963091,
      "learning_rate": 1.5271287128712872e-05,
      "loss": 0.0,
      "step": 9270
    },
    {
      "epoch": 2.121142857142857,
      "grad_norm": 0.0006088490481488407,
      "learning_rate": 1.5231683168316833e-05,
      "loss": 0.0029,
      "step": 9280
    },
    {
      "epoch": 2.123428571428571,
      "grad_norm": 0.2250010371208191,
      "learning_rate": 1.5192079207920792e-05,
      "loss": 0.0122,
      "step": 9290
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 0.002095842035487294,
      "learning_rate": 1.5152475247524753e-05,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.00039264134829863906,
      "learning_rate": 1.5112871287128714e-05,
      "loss": 0.0001,
      "step": 9310
    },
    {
      "epoch": 2.1302857142857143,
      "grad_norm": 0.0004586520080920309,
      "learning_rate": 1.5073267326732673e-05,
      "loss": 0.0057,
      "step": 9320
    },
    {
      "epoch": 2.1325714285714286,
      "grad_norm": 0.0012644872767850757,
      "learning_rate": 1.5033663366336634e-05,
      "loss": 0.0057,
      "step": 9330
    },
    {
      "epoch": 2.134857142857143,
      "grad_norm": 0.0017417772905901074,
      "learning_rate": 1.4994059405940595e-05,
      "loss": 0.0521,
      "step": 9340
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.1592608392238617,
      "learning_rate": 1.4954455445544554e-05,
      "loss": 0.0092,
      "step": 9350
    },
    {
      "epoch": 2.1394285714285712,
      "grad_norm": 0.003314071334898472,
      "learning_rate": 1.4914851485148515e-05,
      "loss": 0.0026,
      "step": 9360
    },
    {
      "epoch": 2.141714285714286,
      "grad_norm": 0.005649974104017019,
      "learning_rate": 1.4875247524752476e-05,
      "loss": 0.0064,
      "step": 9370
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.0017266131471842527,
      "learning_rate": 1.4835643564356436e-05,
      "loss": 0.0013,
      "step": 9380
    },
    {
      "epoch": 2.1462857142857144,
      "grad_norm": 0.0007405511569231749,
      "learning_rate": 1.4796039603960396e-05,
      "loss": 0.0006,
      "step": 9390
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 0.002903733402490616,
      "learning_rate": 1.4756435643564357e-05,
      "loss": 0.0035,
      "step": 9400
    },
    {
      "epoch": 2.150857142857143,
      "grad_norm": 0.0028658444061875343,
      "learning_rate": 1.4716831683168317e-05,
      "loss": 0.0001,
      "step": 9410
    },
    {
      "epoch": 2.153142857142857,
      "grad_norm": 0.0021998053416609764,
      "learning_rate": 1.4677227722772277e-05,
      "loss": 0.0006,
      "step": 9420
    },
    {
      "epoch": 2.1554285714285712,
      "grad_norm": 4.333668402978219e-05,
      "learning_rate": 1.4637623762376237e-05,
      "loss": 0.0076,
      "step": 9430
    },
    {
      "epoch": 2.157714285714286,
      "grad_norm": 0.0008387240814045072,
      "learning_rate": 1.4598019801980198e-05,
      "loss": 0.0001,
      "step": 9440
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.004260537214577198,
      "learning_rate": 1.4558415841584158e-05,
      "loss": 0.0004,
      "step": 9450
    },
    {
      "epoch": 2.1622857142857144,
      "grad_norm": 0.0035696181003004313,
      "learning_rate": 1.4518811881188118e-05,
      "loss": 0.0003,
      "step": 9460
    },
    {
      "epoch": 2.1645714285714286,
      "grad_norm": 0.0014011972816661,
      "learning_rate": 1.447920792079208e-05,
      "loss": 0.0001,
      "step": 9470
    },
    {
      "epoch": 2.166857142857143,
      "grad_norm": 0.001991894794628024,
      "learning_rate": 1.4439603960396038e-05,
      "loss": 0.0003,
      "step": 9480
    },
    {
      "epoch": 2.169142857142857,
      "grad_norm": 0.0008927192538976669,
      "learning_rate": 1.44e-05,
      "loss": 0.0001,
      "step": 9490
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.0020966643933206797,
      "learning_rate": 1.436039603960396e-05,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 2.1737142857142855,
      "grad_norm": 0.0010543399257585406,
      "learning_rate": 1.4320792079207921e-05,
      "loss": 0.0001,
      "step": 9510
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.0019305438036099076,
      "learning_rate": 1.428118811881188e-05,
      "loss": 0.0001,
      "step": 9520
    },
    {
      "epoch": 2.1782857142857144,
      "grad_norm": 0.14477336406707764,
      "learning_rate": 1.4241584158415841e-05,
      "loss": 0.0087,
      "step": 9530
    },
    {
      "epoch": 2.1805714285714286,
      "grad_norm": 0.002710321918129921,
      "learning_rate": 1.4201980198019802e-05,
      "loss": 0.0001,
      "step": 9540
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 0.0011940299300476909,
      "learning_rate": 1.4162376237623761e-05,
      "loss": 0.0031,
      "step": 9550
    },
    {
      "epoch": 2.185142857142857,
      "grad_norm": 0.0011854625772684813,
      "learning_rate": 1.4122772277227722e-05,
      "loss": 0.0,
      "step": 9560
    },
    {
      "epoch": 2.1874285714285713,
      "grad_norm": 0.0013566073030233383,
      "learning_rate": 1.4083168316831683e-05,
      "loss": 0.0061,
      "step": 9570
    },
    {
      "epoch": 2.1897142857142855,
      "grad_norm": 0.0013864886714145541,
      "learning_rate": 1.4043564356435646e-05,
      "loss": 0.0001,
      "step": 9580
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.0022923650685697794,
      "learning_rate": 1.4003960396039606e-05,
      "loss": 0.0034,
      "step": 9590
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 0.0017512348713353276,
      "learning_rate": 1.3964356435643566e-05,
      "loss": 0.0065,
      "step": 9600
    },
    {
      "epoch": 2.1965714285714286,
      "grad_norm": 0.00019576348131522536,
      "learning_rate": 1.3924752475247526e-05,
      "loss": 0.0,
      "step": 9610
    },
    {
      "epoch": 2.198857142857143,
      "grad_norm": 0.0030105742625892162,
      "learning_rate": 1.3885148514851487e-05,
      "loss": 0.0001,
      "step": 9620
    },
    {
      "epoch": 2.201142857142857,
      "grad_norm": 0.001627867459319532,
      "learning_rate": 1.3845544554455448e-05,
      "loss": 0.0391,
      "step": 9630
    },
    {
      "epoch": 2.2034285714285713,
      "grad_norm": 0.0020587528124451637,
      "learning_rate": 1.3805940594059407e-05,
      "loss": 0.0004,
      "step": 9640
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 0.0024800337851047516,
      "learning_rate": 1.3766336633663368e-05,
      "loss": 0.0065,
      "step": 9650
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.004225183743983507,
      "learning_rate": 1.372673267326733e-05,
      "loss": 0.0001,
      "step": 9660
    },
    {
      "epoch": 2.2102857142857144,
      "grad_norm": 0.0022871692199259996,
      "learning_rate": 1.3687128712871288e-05,
      "loss": 0.0001,
      "step": 9670
    },
    {
      "epoch": 2.2125714285714286,
      "grad_norm": 0.0024079973809421062,
      "learning_rate": 1.364752475247525e-05,
      "loss": 0.0004,
      "step": 9680
    },
    {
      "epoch": 2.214857142857143,
      "grad_norm": 0.0020096173975616693,
      "learning_rate": 1.360792079207921e-05,
      "loss": 0.0036,
      "step": 9690
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 0.06786033511161804,
      "learning_rate": 1.356831683168317e-05,
      "loss": 0.0066,
      "step": 9700
    },
    {
      "epoch": 2.2194285714285713,
      "grad_norm": 0.00214366870932281,
      "learning_rate": 1.352871287128713e-05,
      "loss": 0.0001,
      "step": 9710
    },
    {
      "epoch": 2.2217142857142855,
      "grad_norm": 0.0022154832258820534,
      "learning_rate": 1.3489108910891091e-05,
      "loss": 0.0062,
      "step": 9720
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.0017858424689620733,
      "learning_rate": 1.344950495049505e-05,
      "loss": 0.0003,
      "step": 9730
    },
    {
      "epoch": 2.2262857142857144,
      "grad_norm": 0.0015349817695096135,
      "learning_rate": 1.3409900990099011e-05,
      "loss": 0.0058,
      "step": 9740
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 8.594937324523926,
      "learning_rate": 1.3370297029702972e-05,
      "loss": 0.0197,
      "step": 9750
    },
    {
      "epoch": 2.230857142857143,
      "grad_norm": 3.811598777770996,
      "learning_rate": 1.3330693069306933e-05,
      "loss": 0.0013,
      "step": 9760
    },
    {
      "epoch": 2.233142857142857,
      "grad_norm": 0.0006101902690716088,
      "learning_rate": 1.3291089108910892e-05,
      "loss": 0.0036,
      "step": 9770
    },
    {
      "epoch": 2.2354285714285713,
      "grad_norm": 0.06190227344632149,
      "learning_rate": 1.3251485148514853e-05,
      "loss": 0.0046,
      "step": 9780
    },
    {
      "epoch": 2.2377142857142855,
      "grad_norm": 0.0009533350239507854,
      "learning_rate": 1.3211881188118814e-05,
      "loss": 0.0061,
      "step": 9790
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.0004410737310536206,
      "learning_rate": 1.3172277227722773e-05,
      "loss": 0.0099,
      "step": 9800
    },
    {
      "epoch": 2.2422857142857144,
      "grad_norm": 0.0007855452713556588,
      "learning_rate": 1.3132673267326734e-05,
      "loss": 0.0199,
      "step": 9810
    },
    {
      "epoch": 2.2445714285714287,
      "grad_norm": 0.001310014515183866,
      "learning_rate": 1.3093069306930695e-05,
      "loss": 0.0004,
      "step": 9820
    },
    {
      "epoch": 2.246857142857143,
      "grad_norm": 0.00153746095020324,
      "learning_rate": 1.3053465346534654e-05,
      "loss": 0.0005,
      "step": 9830
    },
    {
      "epoch": 2.249142857142857,
      "grad_norm": 0.0016040686750784516,
      "learning_rate": 1.3013861386138615e-05,
      "loss": 0.0,
      "step": 9840
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.0008954001241363585,
      "learning_rate": 1.2974257425742576e-05,
      "loss": 0.0073,
      "step": 9850
    },
    {
      "epoch": 2.2537142857142856,
      "grad_norm": 0.00028727573226206005,
      "learning_rate": 1.2934653465346535e-05,
      "loss": 0.0179,
      "step": 9860
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 7.672277570236474e-05,
      "learning_rate": 1.2895049504950496e-05,
      "loss": 0.0294,
      "step": 9870
    },
    {
      "epoch": 2.2582857142857145,
      "grad_norm": 0.0013123402604833245,
      "learning_rate": 1.2855445544554457e-05,
      "loss": 0.0005,
      "step": 9880
    },
    {
      "epoch": 2.2605714285714287,
      "grad_norm": 0.0020410516299307346,
      "learning_rate": 1.2815841584158417e-05,
      "loss": 0.0001,
      "step": 9890
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 0.0004211296036373824,
      "learning_rate": 1.2776237623762377e-05,
      "loss": 0.0016,
      "step": 9900
    },
    {
      "epoch": 2.265142857142857,
      "grad_norm": 0.10286394506692886,
      "learning_rate": 1.2736633663366337e-05,
      "loss": 0.0007,
      "step": 9910
    },
    {
      "epoch": 2.2674285714285713,
      "grad_norm": 0.0017589048948138952,
      "learning_rate": 1.2697029702970298e-05,
      "loss": 0.0163,
      "step": 9920
    },
    {
      "epoch": 2.2697142857142856,
      "grad_norm": 0.0017497855005785823,
      "learning_rate": 1.2657425742574258e-05,
      "loss": 0.0033,
      "step": 9930
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.0015667875995859504,
      "learning_rate": 1.2617821782178218e-05,
      "loss": 0.0001,
      "step": 9940
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 0.0007805645000189543,
      "learning_rate": 1.257821782178218e-05,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 2.2765714285714287,
      "grad_norm": 7.977410132298246e-05,
      "learning_rate": 1.2538613861386138e-05,
      "loss": 0.0034,
      "step": 9960
    },
    {
      "epoch": 2.278857142857143,
      "grad_norm": 0.002403613878414035,
      "learning_rate": 1.24990099009901e-05,
      "loss": 0.0007,
      "step": 9970
    },
    {
      "epoch": 2.281142857142857,
      "grad_norm": 0.0016806905623525381,
      "learning_rate": 1.245940594059406e-05,
      "loss": 0.0006,
      "step": 9980
    },
    {
      "epoch": 2.2834285714285714,
      "grad_norm": 0.0015857854159548879,
      "learning_rate": 1.2419801980198021e-05,
      "loss": 0.0004,
      "step": 9990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.0006975202704779804,
      "learning_rate": 1.238019801980198e-05,
      "loss": 0.0005,
      "step": 10000
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.0006213783053681254,
      "learning_rate": 1.2340594059405941e-05,
      "loss": 0.0012,
      "step": 10010
    },
    {
      "epoch": 2.290285714285714,
      "grad_norm": 0.0021394442301243544,
      "learning_rate": 1.2300990099009902e-05,
      "loss": 0.0,
      "step": 10020
    },
    {
      "epoch": 2.2925714285714287,
      "grad_norm": 0.0025731308851391077,
      "learning_rate": 1.2261386138613861e-05,
      "loss": 0.0005,
      "step": 10030
    },
    {
      "epoch": 2.294857142857143,
      "grad_norm": 0.0017484533600509167,
      "learning_rate": 1.2221782178217822e-05,
      "loss": 0.0005,
      "step": 10040
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 0.0013013596180826426,
      "learning_rate": 1.2182178217821783e-05,
      "loss": 0.0,
      "step": 10050
    },
    {
      "epoch": 2.2994285714285714,
      "grad_norm": 0.0007857710588723421,
      "learning_rate": 1.2142574257425742e-05,
      "loss": 0.0004,
      "step": 10060
    },
    {
      "epoch": 2.3017142857142856,
      "grad_norm": 0.001340086106210947,
      "learning_rate": 1.2102970297029703e-05,
      "loss": 0.0064,
      "step": 10070
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.001971418969333172,
      "learning_rate": 1.2063366336633664e-05,
      "loss": 0.0009,
      "step": 10080
    },
    {
      "epoch": 2.306285714285714,
      "grad_norm": 0.00022275357332546264,
      "learning_rate": 1.2023762376237623e-05,
      "loss": 0.0,
      "step": 10090
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 0.0009264419204555452,
      "learning_rate": 1.1984158415841584e-05,
      "loss": 0.0004,
      "step": 10100
    },
    {
      "epoch": 2.310857142857143,
      "grad_norm": 0.0012998536694794893,
      "learning_rate": 1.1944554455445545e-05,
      "loss": 0.0,
      "step": 10110
    },
    {
      "epoch": 2.313142857142857,
      "grad_norm": 0.0012716511264443398,
      "learning_rate": 1.1904950495049506e-05,
      "loss": 0.0,
      "step": 10120
    },
    {
      "epoch": 2.3154285714285714,
      "grad_norm": 0.0010827521327883005,
      "learning_rate": 1.1865346534653465e-05,
      "loss": 0.0033,
      "step": 10130
    },
    {
      "epoch": 2.3177142857142856,
      "grad_norm": 0.0013744350289925933,
      "learning_rate": 1.1825742574257426e-05,
      "loss": 0.0001,
      "step": 10140
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.0016020324546843767,
      "learning_rate": 1.1786138613861387e-05,
      "loss": 0.0,
      "step": 10150
    },
    {
      "epoch": 2.322285714285714,
      "grad_norm": 0.0013244260335341096,
      "learning_rate": 1.1746534653465346e-05,
      "loss": 0.0001,
      "step": 10160
    },
    {
      "epoch": 2.3245714285714287,
      "grad_norm": 4.500546128838323e-05,
      "learning_rate": 1.1706930693069308e-05,
      "loss": 0.0003,
      "step": 10170
    },
    {
      "epoch": 2.326857142857143,
      "grad_norm": 0.0016650514444336295,
      "learning_rate": 1.166732673267327e-05,
      "loss": 0.0004,
      "step": 10180
    },
    {
      "epoch": 2.329142857142857,
      "grad_norm": 0.0010193713242188096,
      "learning_rate": 1.1627722772277228e-05,
      "loss": 0.0009,
      "step": 10190
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 0.049739524722099304,
      "learning_rate": 1.158811881188119e-05,
      "loss": 0.0003,
      "step": 10200
    },
    {
      "epoch": 2.3337142857142856,
      "grad_norm": 0.0005774482269771397,
      "learning_rate": 1.154851485148515e-05,
      "loss": 0.0005,
      "step": 10210
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.0012287250719964504,
      "learning_rate": 1.150891089108911e-05,
      "loss": 0.0004,
      "step": 10220
    },
    {
      "epoch": 2.338285714285714,
      "grad_norm": 0.001446020556613803,
      "learning_rate": 1.146930693069307e-05,
      "loss": 0.0003,
      "step": 10230
    },
    {
      "epoch": 2.3405714285714287,
      "grad_norm": 0.0010733545059338212,
      "learning_rate": 1.1429702970297031e-05,
      "loss": 0.0,
      "step": 10240
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.0015894916141405702,
      "learning_rate": 1.139009900990099e-05,
      "loss": 0.0007,
      "step": 10250
    },
    {
      "epoch": 2.345142857142857,
      "grad_norm": 0.00034930967376567423,
      "learning_rate": 1.1350495049504951e-05,
      "loss": 0.0004,
      "step": 10260
    },
    {
      "epoch": 2.3474285714285714,
      "grad_norm": 0.0020565942395478487,
      "learning_rate": 1.1310891089108912e-05,
      "loss": 0.0006,
      "step": 10270
    },
    {
      "epoch": 2.3497142857142856,
      "grad_norm": 0.0013670993503183126,
      "learning_rate": 1.1271287128712873e-05,
      "loss": 0.0,
      "step": 10280
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.0003821989521384239,
      "learning_rate": 1.1231683168316832e-05,
      "loss": 0.0032,
      "step": 10290
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 0.05187609791755676,
      "learning_rate": 1.1192079207920793e-05,
      "loss": 0.0003,
      "step": 10300
    },
    {
      "epoch": 2.3565714285714288,
      "grad_norm": 0.0005845733103342354,
      "learning_rate": 1.1152475247524754e-05,
      "loss": 0.0031,
      "step": 10310
    },
    {
      "epoch": 2.358857142857143,
      "grad_norm": 0.0013461968628689647,
      "learning_rate": 1.1112871287128713e-05,
      "loss": 0.0,
      "step": 10320
    },
    {
      "epoch": 2.361142857142857,
      "grad_norm": 0.04731837287545204,
      "learning_rate": 1.1073267326732674e-05,
      "loss": 0.0003,
      "step": 10330
    },
    {
      "epoch": 2.3634285714285714,
      "grad_norm": 0.0011854843469336629,
      "learning_rate": 1.1033663366336635e-05,
      "loss": 0.0069,
      "step": 10340
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 6.089546513976529e-05,
      "learning_rate": 1.0994059405940594e-05,
      "loss": 0.0003,
      "step": 10350
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.0013128892751410604,
      "learning_rate": 1.0954455445544555e-05,
      "loss": 0.0003,
      "step": 10360
    },
    {
      "epoch": 2.370285714285714,
      "grad_norm": 0.0012980481842532754,
      "learning_rate": 1.0914851485148516e-05,
      "loss": 0.0003,
      "step": 10370
    },
    {
      "epoch": 2.3725714285714288,
      "grad_norm": 0.043003614991903305,
      "learning_rate": 1.0875247524752475e-05,
      "loss": 0.0119,
      "step": 10380
    },
    {
      "epoch": 2.374857142857143,
      "grad_norm": 0.0015005379682406783,
      "learning_rate": 1.0835643564356436e-05,
      "loss": 0.0005,
      "step": 10390
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 0.000976890092715621,
      "learning_rate": 1.0796039603960397e-05,
      "loss": 0.006,
      "step": 10400
    },
    {
      "epoch": 2.3794285714285714,
      "grad_norm": 0.0012779056560248137,
      "learning_rate": 1.0756435643564358e-05,
      "loss": 0.0072,
      "step": 10410
    },
    {
      "epoch": 2.3817142857142857,
      "grad_norm": 0.0008183825411833823,
      "learning_rate": 1.0716831683168317e-05,
      "loss": 0.0271,
      "step": 10420
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.0013542183442041278,
      "learning_rate": 1.0677227722772278e-05,
      "loss": 0.0,
      "step": 10430
    },
    {
      "epoch": 2.386285714285714,
      "grad_norm": 0.001112024299800396,
      "learning_rate": 1.0637623762376239e-05,
      "loss": 0.0004,
      "step": 10440
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 0.0012846384197473526,
      "learning_rate": 1.0598019801980198e-05,
      "loss": 0.0006,
      "step": 10450
    },
    {
      "epoch": 2.390857142857143,
      "grad_norm": 0.0008363695815205574,
      "learning_rate": 1.0558415841584159e-05,
      "loss": 0.0,
      "step": 10460
    },
    {
      "epoch": 2.3931428571428572,
      "grad_norm": 0.07951998710632324,
      "learning_rate": 1.051881188118812e-05,
      "loss": 0.0007,
      "step": 10470
    },
    {
      "epoch": 2.3954285714285715,
      "grad_norm": 2.8338292395346798e-05,
      "learning_rate": 1.0479207920792079e-05,
      "loss": 0.0004,
      "step": 10480
    },
    {
      "epoch": 2.3977142857142857,
      "grad_norm": 3.811392161878757e-05,
      "learning_rate": 1.043960396039604e-05,
      "loss": 0.0,
      "step": 10490
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0006278681685216725,
      "learning_rate": 1.04e-05,
      "loss": 0.0039,
      "step": 10500
    },
    {
      "epoch": 2.402285714285714,
      "grad_norm": 0.1457744836807251,
      "learning_rate": 1.036039603960396e-05,
      "loss": 0.0229,
      "step": 10510
    },
    {
      "epoch": 2.404571428571429,
      "grad_norm": 0.0002443412959109992,
      "learning_rate": 1.032079207920792e-05,
      "loss": 0.0003,
      "step": 10520
    },
    {
      "epoch": 2.406857142857143,
      "grad_norm": 0.0014292967971414328,
      "learning_rate": 1.0281188118811881e-05,
      "loss": 0.0004,
      "step": 10530
    },
    {
      "epoch": 2.4091428571428573,
      "grad_norm": 0.05820298194885254,
      "learning_rate": 1.0241584158415842e-05,
      "loss": 0.0018,
      "step": 10540
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 2.0858893394470215,
      "learning_rate": 1.0201980198019801e-05,
      "loss": 0.0573,
      "step": 10550
    },
    {
      "epoch": 2.4137142857142857,
      "grad_norm": 0.0004980385419912636,
      "learning_rate": 1.0162376237623762e-05,
      "loss": 0.0,
      "step": 10560
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.001732346834614873,
      "learning_rate": 1.0122772277227723e-05,
      "loss": 0.0003,
      "step": 10570
    },
    {
      "epoch": 2.418285714285714,
      "grad_norm": 0.0022875561844557524,
      "learning_rate": 1.0083168316831684e-05,
      "loss": 0.0004,
      "step": 10580
    },
    {
      "epoch": 2.420571428571429,
      "grad_norm": 0.002775278640910983,
      "learning_rate": 1.0043564356435645e-05,
      "loss": 0.0004,
      "step": 10590
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 0.0010139364749193192,
      "learning_rate": 1.0003960396039606e-05,
      "loss": 0.0038,
      "step": 10600
    },
    {
      "epoch": 2.4251428571428573,
      "grad_norm": 0.061989009380340576,
      "learning_rate": 9.964356435643565e-06,
      "loss": 0.0004,
      "step": 10610
    },
    {
      "epoch": 2.4274285714285715,
      "grad_norm": 0.0015054908581078053,
      "learning_rate": 9.924752475247526e-06,
      "loss": 0.0001,
      "step": 10620
    },
    {
      "epoch": 2.4297142857142857,
      "grad_norm": 0.0016592534957453609,
      "learning_rate": 9.885148514851487e-06,
      "loss": 0.0029,
      "step": 10630
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.002312990138307214,
      "learning_rate": 9.845544554455446e-06,
      "loss": 0.0067,
      "step": 10640
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 0.0027732248418033123,
      "learning_rate": 9.805940594059407e-06,
      "loss": 0.0,
      "step": 10650
    },
    {
      "epoch": 2.4365714285714284,
      "grad_norm": 0.0003171029966324568,
      "learning_rate": 9.766336633663368e-06,
      "loss": 0.0003,
      "step": 10660
    },
    {
      "epoch": 2.4388571428571426,
      "grad_norm": 0.0017357764299958944,
      "learning_rate": 9.726732673267327e-06,
      "loss": 0.001,
      "step": 10670
    },
    {
      "epoch": 2.4411428571428573,
      "grad_norm": 0.0014609742211177945,
      "learning_rate": 9.687128712871288e-06,
      "loss": 0.0004,
      "step": 10680
    },
    {
      "epoch": 2.4434285714285715,
      "grad_norm": 0.0010572181781753898,
      "learning_rate": 9.647524752475249e-06,
      "loss": 0.0005,
      "step": 10690
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.03713614121079445,
      "learning_rate": 9.60792079207921e-06,
      "loss": 0.0002,
      "step": 10700
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.001310426858253777,
      "learning_rate": 9.568316831683169e-06,
      "loss": 0.0062,
      "step": 10710
    },
    {
      "epoch": 2.450285714285714,
      "grad_norm": 3.4450727980583906e-05,
      "learning_rate": 9.52871287128713e-06,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 2.4525714285714284,
      "grad_norm": 0.0006876593688502908,
      "learning_rate": 9.48910891089109e-06,
      "loss": 0.0005,
      "step": 10730
    },
    {
      "epoch": 2.4548571428571426,
      "grad_norm": 0.0004333342076279223,
      "learning_rate": 9.44950495049505e-06,
      "loss": 0.0003,
      "step": 10740
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.0010910360142588615,
      "learning_rate": 9.40990099009901e-06,
      "loss": 0.0001,
      "step": 10750
    },
    {
      "epoch": 2.4594285714285715,
      "grad_norm": 0.0007146290154196322,
      "learning_rate": 9.370297029702971e-06,
      "loss": 0.0063,
      "step": 10760
    },
    {
      "epoch": 2.4617142857142857,
      "grad_norm": 0.04140017554163933,
      "learning_rate": 9.33069306930693e-06,
      "loss": 0.0036,
      "step": 10770
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.0014125744346529245,
      "learning_rate": 9.291089108910891e-06,
      "loss": 0.0003,
      "step": 10780
    },
    {
      "epoch": 2.466285714285714,
      "grad_norm": 0.0017520241672173142,
      "learning_rate": 9.251485148514852e-06,
      "loss": 0.0,
      "step": 10790
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.0029734866693615913,
      "learning_rate": 9.211881188118811e-06,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 2.4708571428571426,
      "grad_norm": 0.0007690401980653405,
      "learning_rate": 9.172277227722772e-06,
      "loss": 0.0,
      "step": 10810
    },
    {
      "epoch": 2.4731428571428573,
      "grad_norm": 0.0014814736787229776,
      "learning_rate": 9.132673267326733e-06,
      "loss": 0.0038,
      "step": 10820
    },
    {
      "epoch": 2.4754285714285715,
      "grad_norm": 0.0004352036921773106,
      "learning_rate": 9.093069306930694e-06,
      "loss": 0.0032,
      "step": 10830
    },
    {
      "epoch": 2.4777142857142858,
      "grad_norm": 0.0018115021521225572,
      "learning_rate": 9.053465346534653e-06,
      "loss": 0.0004,
      "step": 10840
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.001267907558940351,
      "learning_rate": 9.013861386138614e-06,
      "loss": 0.0002,
      "step": 10850
    },
    {
      "epoch": 2.482285714285714,
      "grad_norm": 0.0012918697902932763,
      "learning_rate": 8.974257425742575e-06,
      "loss": 0.0003,
      "step": 10860
    },
    {
      "epoch": 2.4845714285714284,
      "grad_norm": 0.001283557154238224,
      "learning_rate": 8.934653465346534e-06,
      "loss": 0.0002,
      "step": 10870
    },
    {
      "epoch": 2.4868571428571427,
      "grad_norm": 0.06021083891391754,
      "learning_rate": 8.895049504950495e-06,
      "loss": 0.0008,
      "step": 10880
    },
    {
      "epoch": 2.4891428571428573,
      "grad_norm": 0.001445234753191471,
      "learning_rate": 8.855445544554456e-06,
      "loss": 0.0005,
      "step": 10890
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 0.0014658061554655433,
      "learning_rate": 8.815841584158415e-06,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 2.4937142857142858,
      "grad_norm": 0.0015774614876136184,
      "learning_rate": 8.776237623762376e-06,
      "loss": 0.0001,
      "step": 10910
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.042854223400354385,
      "learning_rate": 8.736633663366337e-06,
      "loss": 0.0003,
      "step": 10920
    },
    {
      "epoch": 2.498285714285714,
      "grad_norm": 0.0002490545448381454,
      "learning_rate": 8.697029702970296e-06,
      "loss": 0.0004,
      "step": 10930
    },
    {
      "epoch": 2.5005714285714284,
      "grad_norm": 1.3286399841308594,
      "learning_rate": 8.657425742574257e-06,
      "loss": 0.0373,
      "step": 10940
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 0.0011482865083962679,
      "learning_rate": 8.617821782178218e-06,
      "loss": 0.0,
      "step": 10950
    },
    {
      "epoch": 2.5051428571428573,
      "grad_norm": 0.0008391182636842132,
      "learning_rate": 8.578217821782179e-06,
      "loss": 0.0,
      "step": 10960
    },
    {
      "epoch": 2.5074285714285716,
      "grad_norm": 0.0031619409564882517,
      "learning_rate": 8.53861386138614e-06,
      "loss": 0.0032,
      "step": 10970
    },
    {
      "epoch": 2.509714285714286,
      "grad_norm": 0.000740627059713006,
      "learning_rate": 8.4990099009901e-06,
      "loss": 0.0032,
      "step": 10980
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.001445133239030838,
      "learning_rate": 8.45940594059406e-06,
      "loss": 0.0213,
      "step": 10990
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.001845084480009973,
      "learning_rate": 8.41980198019802e-06,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 2.5165714285714285,
      "grad_norm": 0.0012595534790307283,
      "learning_rate": 8.380198019801981e-06,
      "loss": 0.0,
      "step": 11010
    },
    {
      "epoch": 2.5188571428571427,
      "grad_norm": 0.00031049305107444525,
      "learning_rate": 8.340594059405942e-06,
      "loss": 0.0,
      "step": 11020
    },
    {
      "epoch": 2.5211428571428574,
      "grad_norm": 0.0018902100855484605,
      "learning_rate": 8.300990099009901e-06,
      "loss": 0.0006,
      "step": 11030
    },
    {
      "epoch": 2.5234285714285716,
      "grad_norm": 0.00017307679809164256,
      "learning_rate": 8.261386138613862e-06,
      "loss": 0.0178,
      "step": 11040
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 0.00035966280847787857,
      "learning_rate": 8.221782178217823e-06,
      "loss": 0.0009,
      "step": 11050
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.0009813725482672453,
      "learning_rate": 8.182178217821782e-06,
      "loss": 0.0035,
      "step": 11060
    },
    {
      "epoch": 2.5302857142857142,
      "grad_norm": 0.0021184429060667753,
      "learning_rate": 8.142574257425743e-06,
      "loss": 0.0005,
      "step": 11070
    },
    {
      "epoch": 2.5325714285714285,
      "grad_norm": 0.0006847853655926883,
      "learning_rate": 8.102970297029704e-06,
      "loss": 0.0,
      "step": 11080
    },
    {
      "epoch": 2.5348571428571427,
      "grad_norm": 0.00034441883326508105,
      "learning_rate": 8.063366336633663e-06,
      "loss": 0.0004,
      "step": 11090
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 0.0010007856180891395,
      "learning_rate": 8.023762376237624e-06,
      "loss": 0.0036,
      "step": 11100
    },
    {
      "epoch": 2.5394285714285716,
      "grad_norm": 0.0010702827712520957,
      "learning_rate": 7.984158415841585e-06,
      "loss": 0.0,
      "step": 11110
    },
    {
      "epoch": 2.541714285714286,
      "grad_norm": 0.0017814015736803412,
      "learning_rate": 7.944554455445546e-06,
      "loss": 0.0004,
      "step": 11120
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.0006074531702324748,
      "learning_rate": 7.904950495049505e-06,
      "loss": 0.0002,
      "step": 11130
    },
    {
      "epoch": 2.5462857142857143,
      "grad_norm": 0.0004242795694153756,
      "learning_rate": 7.865346534653466e-06,
      "loss": 0.0006,
      "step": 11140
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.0010357563151046634,
      "learning_rate": 7.825742574257427e-06,
      "loss": 0.0003,
      "step": 11150
    },
    {
      "epoch": 2.5508571428571427,
      "grad_norm": 0.0007003038772381842,
      "learning_rate": 7.786138613861386e-06,
      "loss": 0.0033,
      "step": 11160
    },
    {
      "epoch": 2.5531428571428574,
      "grad_norm": 0.00058300222735852,
      "learning_rate": 7.746534653465347e-06,
      "loss": 0.0004,
      "step": 11170
    },
    {
      "epoch": 2.555428571428571,
      "grad_norm": 0.00017606648907531053,
      "learning_rate": 7.706930693069308e-06,
      "loss": 0.009,
      "step": 11180
    },
    {
      "epoch": 2.557714285714286,
      "grad_norm": 0.0012573708081617951,
      "learning_rate": 7.667326732673267e-06,
      "loss": 0.0,
      "step": 11190
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.0010514328023418784,
      "learning_rate": 7.627722772277228e-06,
      "loss": 0.0188,
      "step": 11200
    },
    {
      "epoch": 2.5622857142857143,
      "grad_norm": 0.0007106181583367288,
      "learning_rate": 7.588118811881189e-06,
      "loss": 0.0005,
      "step": 11210
    },
    {
      "epoch": 2.5645714285714285,
      "grad_norm": 0.0011885982239618897,
      "learning_rate": 7.548514851485149e-06,
      "loss": 0.0007,
      "step": 11220
    },
    {
      "epoch": 2.5668571428571427,
      "grad_norm": 0.001347075216472149,
      "learning_rate": 7.508910891089109e-06,
      "loss": 0.0004,
      "step": 11230
    },
    {
      "epoch": 2.5691428571428574,
      "grad_norm": 0.001266367151401937,
      "learning_rate": 7.46930693069307e-06,
      "loss": 0.0038,
      "step": 11240
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.0008969181217253208,
      "learning_rate": 7.42970297029703e-06,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 2.573714285714286,
      "grad_norm": 0.0006441978621296585,
      "learning_rate": 7.39009900990099e-06,
      "loss": 0.0,
      "step": 11260
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.001209476264193654,
      "learning_rate": 7.3504950495049505e-06,
      "loss": 0.0003,
      "step": 11270
    },
    {
      "epoch": 2.5782857142857143,
      "grad_norm": 0.0004354097764007747,
      "learning_rate": 7.310891089108911e-06,
      "loss": 0.0,
      "step": 11280
    },
    {
      "epoch": 2.5805714285714285,
      "grad_norm": 0.001018099719658494,
      "learning_rate": 7.2712871287128715e-06,
      "loss": 0.001,
      "step": 11290
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 0.00018681927758734673,
      "learning_rate": 7.2316831683168315e-06,
      "loss": 0.0025,
      "step": 11300
    },
    {
      "epoch": 2.5851428571428574,
      "grad_norm": 0.0012595950393006206,
      "learning_rate": 7.1920792079207915e-06,
      "loss": 0.0006,
      "step": 11310
    },
    {
      "epoch": 2.587428571428571,
      "grad_norm": 0.0005032768822275102,
      "learning_rate": 7.152475247524752e-06,
      "loss": 0.0008,
      "step": 11320
    },
    {
      "epoch": 2.589714285714286,
      "grad_norm": 0.0007958997157402337,
      "learning_rate": 7.112871287128712e-06,
      "loss": 0.0002,
      "step": 11330
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.0009369458421133459,
      "learning_rate": 7.073267326732673e-06,
      "loss": 0.0002,
      "step": 11340
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 0.0008469038875773549,
      "learning_rate": 7.033663366336633e-06,
      "loss": 0.0,
      "step": 11350
    },
    {
      "epoch": 2.5965714285714285,
      "grad_norm": 0.000996189657598734,
      "learning_rate": 6.994059405940595e-06,
      "loss": 0.0,
      "step": 11360
    },
    {
      "epoch": 2.5988571428571428,
      "grad_norm": 0.03590075299143791,
      "learning_rate": 6.954455445544555e-06,
      "loss": 0.0007,
      "step": 11370
    },
    {
      "epoch": 2.601142857142857,
      "grad_norm": 0.0005595993134193122,
      "learning_rate": 6.914851485148516e-06,
      "loss": 0.0006,
      "step": 11380
    },
    {
      "epoch": 2.603428571428571,
      "grad_norm": 0.0018890044884756207,
      "learning_rate": 6.875247524752476e-06,
      "loss": 0.0,
      "step": 11390
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.0015849589835852385,
      "learning_rate": 6.835643564356437e-06,
      "loss": 0.0073,
      "step": 11400
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.00027643449720926583,
      "learning_rate": 6.796039603960397e-06,
      "loss": 0.0002,
      "step": 11410
    },
    {
      "epoch": 2.6102857142857143,
      "grad_norm": 0.09315287321805954,
      "learning_rate": 6.756435643564357e-06,
      "loss": 0.0013,
      "step": 11420
    },
    {
      "epoch": 2.6125714285714285,
      "grad_norm": 0.000628577487077564,
      "learning_rate": 6.716831683168318e-06,
      "loss": 0.0027,
      "step": 11430
    },
    {
      "epoch": 2.6148571428571428,
      "grad_norm": 3.1840849260333925e-05,
      "learning_rate": 6.677227722772278e-06,
      "loss": 0.0003,
      "step": 11440
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 0.0005814225296489894,
      "learning_rate": 6.637623762376239e-06,
      "loss": 0.0004,
      "step": 11450
    },
    {
      "epoch": 2.619428571428571,
      "grad_norm": 0.0013938385527580976,
      "learning_rate": 6.598019801980199e-06,
      "loss": 0.0028,
      "step": 11460
    },
    {
      "epoch": 2.621714285714286,
      "grad_norm": 0.0006045822519809008,
      "learning_rate": 6.558415841584159e-06,
      "loss": 0.0003,
      "step": 11470
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.0007915060850791633,
      "learning_rate": 6.51881188118812e-06,
      "loss": 0.0025,
      "step": 11480
    },
    {
      "epoch": 2.6262857142857143,
      "grad_norm": 0.0003289392334409058,
      "learning_rate": 6.47920792079208e-06,
      "loss": 0.0057,
      "step": 11490
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 0.0005886147846467793,
      "learning_rate": 6.43960396039604e-06,
      "loss": 0.0002,
      "step": 11500
    },
    {
      "epoch": 2.630857142857143,
      "grad_norm": 0.0007147809956222773,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0008,
      "step": 11510
    },
    {
      "epoch": 2.633142857142857,
      "grad_norm": 0.0011492266785353422,
      "learning_rate": 6.360396039603961e-06,
      "loss": 0.0,
      "step": 11520
    },
    {
      "epoch": 2.6354285714285712,
      "grad_norm": 0.0009733930346556008,
      "learning_rate": 6.3207920792079215e-06,
      "loss": 0.0144,
      "step": 11530
    },
    {
      "epoch": 2.637714285714286,
      "grad_norm": 0.03329760581254959,
      "learning_rate": 6.2811881188118815e-06,
      "loss": 0.0002,
      "step": 11540
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.1062597036361694,
      "learning_rate": 6.2415841584158415e-06,
      "loss": 0.0196,
      "step": 11550
    },
    {
      "epoch": 2.6422857142857143,
      "grad_norm": 0.001180189079605043,
      "learning_rate": 6.201980198019802e-06,
      "loss": 0.0002,
      "step": 11560
    },
    {
      "epoch": 2.6445714285714286,
      "grad_norm": 0.0007708287448622286,
      "learning_rate": 6.1623762376237624e-06,
      "loss": 0.0027,
      "step": 11570
    },
    {
      "epoch": 2.646857142857143,
      "grad_norm": 0.001383845810778439,
      "learning_rate": 6.122772277227723e-06,
      "loss": 0.0,
      "step": 11580
    },
    {
      "epoch": 2.649142857142857,
      "grad_norm": 0.00034006379428319633,
      "learning_rate": 6.083168316831683e-06,
      "loss": 0.0002,
      "step": 11590
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 0.0015853740042075515,
      "learning_rate": 6.043564356435643e-06,
      "loss": 0.0026,
      "step": 11600
    },
    {
      "epoch": 2.653714285714286,
      "grad_norm": 0.000861293519847095,
      "learning_rate": 6.003960396039604e-06,
      "loss": 0.0002,
      "step": 11610
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.1451401263475418,
      "learning_rate": 5.964356435643564e-06,
      "loss": 0.0025,
      "step": 11620
    },
    {
      "epoch": 2.6582857142857144,
      "grad_norm": 0.0014287165831774473,
      "learning_rate": 5.924752475247525e-06,
      "loss": 0.0029,
      "step": 11630
    },
    {
      "epoch": 2.6605714285714286,
      "grad_norm": 0.00048275868175551295,
      "learning_rate": 5.885148514851485e-06,
      "loss": 0.007,
      "step": 11640
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 0.001406939933076501,
      "learning_rate": 5.845544554455446e-06,
      "loss": 0.0004,
      "step": 11650
    },
    {
      "epoch": 2.665142857142857,
      "grad_norm": 0.0003720906388480216,
      "learning_rate": 5.805940594059407e-06,
      "loss": 0.0,
      "step": 11660
    },
    {
      "epoch": 2.6674285714285713,
      "grad_norm": 0.0002426314022159204,
      "learning_rate": 5.766336633663367e-06,
      "loss": 0.0004,
      "step": 11670
    },
    {
      "epoch": 2.669714285714286,
      "grad_norm": 0.0001777593424776569,
      "learning_rate": 5.726732673267327e-06,
      "loss": 0.0064,
      "step": 11680
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.0013652644120156765,
      "learning_rate": 5.687128712871288e-06,
      "loss": 0.0,
      "step": 11690
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 0.00027437470271252096,
      "learning_rate": 5.647524752475248e-06,
      "loss": 0.0028,
      "step": 11700
    },
    {
      "epoch": 2.6765714285714286,
      "grad_norm": 0.00040138597250916064,
      "learning_rate": 5.607920792079208e-06,
      "loss": 0.0002,
      "step": 11710
    },
    {
      "epoch": 2.678857142857143,
      "grad_norm": 0.00043944927165284753,
      "learning_rate": 5.568316831683169e-06,
      "loss": 0.0004,
      "step": 11720
    },
    {
      "epoch": 2.681142857142857,
      "grad_norm": 0.0013129940489307046,
      "learning_rate": 5.528712871287129e-06,
      "loss": 0.0003,
      "step": 11730
    },
    {
      "epoch": 2.6834285714285713,
      "grad_norm": 0.0009379459079355001,
      "learning_rate": 5.48910891089109e-06,
      "loss": 0.0002,
      "step": 11740
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 2.0374658561195247e-05,
      "learning_rate": 5.44950495049505e-06,
      "loss": 0.0,
      "step": 11750
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.00039738984196446836,
      "learning_rate": 5.40990099009901e-06,
      "loss": 0.0,
      "step": 11760
    },
    {
      "epoch": 2.6902857142857144,
      "grad_norm": 0.0006936583667993546,
      "learning_rate": 5.370297029702971e-06,
      "loss": 0.0,
      "step": 11770
    },
    {
      "epoch": 2.6925714285714286,
      "grad_norm": 0.0013117921771481633,
      "learning_rate": 5.330693069306931e-06,
      "loss": 0.0027,
      "step": 11780
    },
    {
      "epoch": 2.694857142857143,
      "grad_norm": 1.9778897694777697e-05,
      "learning_rate": 5.2910891089108915e-06,
      "loss": 0.0,
      "step": 11790
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 0.0006029240903444588,
      "learning_rate": 5.2514851485148516e-06,
      "loss": 0.0067,
      "step": 11800
    },
    {
      "epoch": 2.6994285714285713,
      "grad_norm": 0.0004775733104906976,
      "learning_rate": 5.211881188118812e-06,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 2.701714285714286,
      "grad_norm": 0.0010783534962683916,
      "learning_rate": 5.1722772277227725e-06,
      "loss": 0.0003,
      "step": 11820
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.0008010066812857985,
      "learning_rate": 5.1326732673267325e-06,
      "loss": 0.0006,
      "step": 11830
    },
    {
      "epoch": 2.7062857142857144,
      "grad_norm": 0.0007811097893863916,
      "learning_rate": 5.093069306930693e-06,
      "loss": 0.0,
      "step": 11840
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 0.0005822263192385435,
      "learning_rate": 5.053465346534654e-06,
      "loss": 0.0002,
      "step": 11850
    },
    {
      "epoch": 2.710857142857143,
      "grad_norm": 3.0567633075406775e-05,
      "learning_rate": 5.013861386138614e-06,
      "loss": 0.0024,
      "step": 11860
    },
    {
      "epoch": 2.713142857142857,
      "grad_norm": 0.0006996351876296103,
      "learning_rate": 4.974257425742575e-06,
      "loss": 0.0007,
      "step": 11870
    },
    {
      "epoch": 2.7154285714285713,
      "grad_norm": 0.00027697099721990526,
      "learning_rate": 4.934653465346535e-06,
      "loss": 0.0005,
      "step": 11880
    },
    {
      "epoch": 2.717714285714286,
      "grad_norm": 0.0007401677430607378,
      "learning_rate": 4.895049504950495e-06,
      "loss": 0.0,
      "step": 11890
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0005113594233989716,
      "learning_rate": 4.855445544554456e-06,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 2.7222857142857144,
      "grad_norm": 0.0001558161311550066,
      "learning_rate": 4.815841584158416e-06,
      "loss": 0.0,
      "step": 11910
    },
    {
      "epoch": 2.7245714285714286,
      "grad_norm": 0.000921561848372221,
      "learning_rate": 4.776237623762376e-06,
      "loss": 0.0022,
      "step": 11920
    },
    {
      "epoch": 2.726857142857143,
      "grad_norm": 0.000348859146470204,
      "learning_rate": 4.736633663366337e-06,
      "loss": 0.0169,
      "step": 11930
    },
    {
      "epoch": 2.729142857142857,
      "grad_norm": 0.0009297119686380029,
      "learning_rate": 4.697029702970297e-06,
      "loss": 0.0,
      "step": 11940
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 0.0004250725614838302,
      "learning_rate": 4.657425742574258e-06,
      "loss": 0.0,
      "step": 11950
    },
    {
      "epoch": 2.733714285714286,
      "grad_norm": 0.059593185782432556,
      "learning_rate": 4.617821782178218e-06,
      "loss": 0.0194,
      "step": 11960
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.00016316869005095214,
      "learning_rate": 4.578217821782178e-06,
      "loss": 0.0,
      "step": 11970
    },
    {
      "epoch": 2.7382857142857144,
      "grad_norm": 0.14283610880374908,
      "learning_rate": 4.538613861386139e-06,
      "loss": 0.0029,
      "step": 11980
    },
    {
      "epoch": 2.7405714285714287,
      "grad_norm": 0.0007433047867380083,
      "learning_rate": 4.499009900990099e-06,
      "loss": 0.0,
      "step": 11990
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 0.0009627013350836933,
      "learning_rate": 4.45940594059406e-06,
      "loss": 0.0025,
      "step": 12000
    },
    {
      "epoch": 2.745142857142857,
      "grad_norm": 0.0006199623458087444,
      "learning_rate": 4.41980198019802e-06,
      "loss": 0.0003,
      "step": 12010
    },
    {
      "epoch": 2.7474285714285713,
      "grad_norm": 0.00048721281928010285,
      "learning_rate": 4.38019801980198e-06,
      "loss": 0.0003,
      "step": 12020
    },
    {
      "epoch": 2.7497142857142856,
      "grad_norm": 0.0013992892345413566,
      "learning_rate": 4.340594059405941e-06,
      "loss": 0.0,
      "step": 12030
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.001144243637099862,
      "learning_rate": 4.300990099009901e-06,
      "loss": 0.0,
      "step": 12040
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 0.0006211777217686176,
      "learning_rate": 4.261386138613862e-06,
      "loss": 0.0,
      "step": 12050
    },
    {
      "epoch": 2.7565714285714287,
      "grad_norm": 1.6946862160693854e-05,
      "learning_rate": 4.2217821782178225e-06,
      "loss": 0.0008,
      "step": 12060
    },
    {
      "epoch": 2.758857142857143,
      "grad_norm": 0.0007092056912370026,
      "learning_rate": 4.1821782178217825e-06,
      "loss": 0.0,
      "step": 12070
    },
    {
      "epoch": 2.761142857142857,
      "grad_norm": 0.05067454278469086,
      "learning_rate": 4.142574257425743e-06,
      "loss": 0.0208,
      "step": 12080
    },
    {
      "epoch": 2.7634285714285713,
      "grad_norm": 0.0006200639763846993,
      "learning_rate": 4.102970297029703e-06,
      "loss": 0.0004,
      "step": 12090
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 0.001222754130139947,
      "learning_rate": 4.0633663366336634e-06,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.0006363476277329028,
      "learning_rate": 4.023762376237624e-06,
      "loss": 0.0004,
      "step": 12110
    },
    {
      "epoch": 2.7702857142857145,
      "grad_norm": 0.0007307231426239014,
      "learning_rate": 3.984158415841584e-06,
      "loss": 0.0002,
      "step": 12120
    },
    {
      "epoch": 2.7725714285714287,
      "grad_norm": 0.00042522759758867323,
      "learning_rate": 3.944554455445544e-06,
      "loss": 0.0028,
      "step": 12130
    },
    {
      "epoch": 2.774857142857143,
      "grad_norm": 0.0003018016286659986,
      "learning_rate": 3.904950495049505e-06,
      "loss": 0.0002,
      "step": 12140
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 0.0002929406182374805,
      "learning_rate": 3.865346534653465e-06,
      "loss": 0.0005,
      "step": 12150
    },
    {
      "epoch": 2.7794285714285714,
      "grad_norm": 0.03829648345708847,
      "learning_rate": 3.825742574257426e-06,
      "loss": 0.0006,
      "step": 12160
    },
    {
      "epoch": 2.7817142857142856,
      "grad_norm": 0.0004474266606848687,
      "learning_rate": 3.786138613861386e-06,
      "loss": 0.003,
      "step": 12170
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.03417108207941055,
      "learning_rate": 3.7465346534653466e-06,
      "loss": 0.0002,
      "step": 12180
    },
    {
      "epoch": 2.7862857142857145,
      "grad_norm": 0.00036134914262220263,
      "learning_rate": 3.706930693069307e-06,
      "loss": 0.0074,
      "step": 12190
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.0007641708361916244,
      "learning_rate": 3.667326732673267e-06,
      "loss": 0.0003,
      "step": 12200
    },
    {
      "epoch": 2.790857142857143,
      "grad_norm": 0.0005277274758554995,
      "learning_rate": 3.6277227722772276e-06,
      "loss": 0.0,
      "step": 12210
    },
    {
      "epoch": 2.793142857142857,
      "grad_norm": 0.00044610153418034315,
      "learning_rate": 3.588118811881188e-06,
      "loss": 0.0023,
      "step": 12220
    },
    {
      "epoch": 2.7954285714285714,
      "grad_norm": 0.0008810914005152881,
      "learning_rate": 3.5485148514851485e-06,
      "loss": 0.0072,
      "step": 12230
    },
    {
      "epoch": 2.7977142857142856,
      "grad_norm": 0.0006566512165591121,
      "learning_rate": 3.5089108910891093e-06,
      "loss": 0.0,
      "step": 12240
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0006689360598102212,
      "learning_rate": 3.46930693069307e-06,
      "loss": 0.0,
      "step": 12250
    },
    {
      "epoch": 2.8022857142857145,
      "grad_norm": 0.0017642190214246511,
      "learning_rate": 3.4297029702970302e-06,
      "loss": 0.0003,
      "step": 12260
    },
    {
      "epoch": 2.8045714285714287,
      "grad_norm": 0.0004361135943327099,
      "learning_rate": 3.3900990099009907e-06,
      "loss": 0.0001,
      "step": 12270
    },
    {
      "epoch": 2.806857142857143,
      "grad_norm": 0.048622485250234604,
      "learning_rate": 3.3504950495049507e-06,
      "loss": 0.0079,
      "step": 12280
    },
    {
      "epoch": 2.809142857142857,
      "grad_norm": 0.0003635453467722982,
      "learning_rate": 3.310891089108911e-06,
      "loss": 0.0024,
      "step": 12290
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 0.0006031161756254733,
      "learning_rate": 3.2712871287128716e-06,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 2.8137142857142856,
      "grad_norm": 0.0005781643558293581,
      "learning_rate": 3.231683168316832e-06,
      "loss": 0.0009,
      "step": 12310
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.2454632818698883,
      "learning_rate": 3.192079207920792e-06,
      "loss": 0.0069,
      "step": 12320
    },
    {
      "epoch": 2.8182857142857145,
      "grad_norm": 0.0005279170582070947,
      "learning_rate": 3.1524752475247526e-06,
      "loss": 0.0026,
      "step": 12330
    },
    {
      "epoch": 2.8205714285714287,
      "grad_norm": 2.196963941969443e-05,
      "learning_rate": 3.112871287128713e-06,
      "loss": 0.0093,
      "step": 12340
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 0.000915112963411957,
      "learning_rate": 3.0732673267326735e-06,
      "loss": 0.0,
      "step": 12350
    },
    {
      "epoch": 2.825142857142857,
      "grad_norm": 0.00039273250149562955,
      "learning_rate": 3.033663366336634e-06,
      "loss": 0.0,
      "step": 12360
    },
    {
      "epoch": 2.8274285714285714,
      "grad_norm": 0.0009998527821153402,
      "learning_rate": 2.994059405940594e-06,
      "loss": 0.0026,
      "step": 12370
    },
    {
      "epoch": 2.8297142857142856,
      "grad_norm": 0.0007247489411383867,
      "learning_rate": 2.9544554455445544e-06,
      "loss": 0.0002,
      "step": 12380
    },
    {
      "epoch": 2.832,
      "grad_norm": 7.979522342793643e-05,
      "learning_rate": 2.9148514851485153e-06,
      "loss": 0.0003,
      "step": 12390
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 0.00046851931256242096,
      "learning_rate": 2.8752475247524753e-06,
      "loss": 0.0005,
      "step": 12400
    },
    {
      "epoch": 2.8365714285714283,
      "grad_norm": 0.06081750988960266,
      "learning_rate": 2.8356435643564358e-06,
      "loss": 0.0056,
      "step": 12410
    },
    {
      "epoch": 2.838857142857143,
      "grad_norm": 0.0003127323871012777,
      "learning_rate": 2.7960396039603962e-06,
      "loss": 0.0061,
      "step": 12420
    },
    {
      "epoch": 2.841142857142857,
      "grad_norm": 0.0007308889180421829,
      "learning_rate": 2.7564356435643567e-06,
      "loss": 0.0242,
      "step": 12430
    },
    {
      "epoch": 2.8434285714285714,
      "grad_norm": 0.00013257961836643517,
      "learning_rate": 2.716831683168317e-06,
      "loss": 0.0,
      "step": 12440
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 0.0006811970961280167,
      "learning_rate": 2.677227722772277e-06,
      "loss": 0.0002,
      "step": 12450
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.03711127117276192,
      "learning_rate": 2.6376237623762376e-06,
      "loss": 0.001,
      "step": 12460
    },
    {
      "epoch": 2.8502857142857145,
      "grad_norm": 0.00022672295744996518,
      "learning_rate": 2.598019801980198e-06,
      "loss": 0.0004,
      "step": 12470
    },
    {
      "epoch": 2.8525714285714283,
      "grad_norm": 0.0008347714319825172,
      "learning_rate": 2.5584158415841585e-06,
      "loss": 0.0,
      "step": 12480
    },
    {
      "epoch": 2.854857142857143,
      "grad_norm": 0.00041401604539714754,
      "learning_rate": 2.518811881188119e-06,
      "loss": 0.0185,
      "step": 12490
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.0008738987962715328,
      "learning_rate": 2.4792079207920794e-06,
      "loss": 0.0021,
      "step": 12500
    },
    {
      "epoch": 2.8594285714285714,
      "grad_norm": 0.04600198566913605,
      "learning_rate": 2.43960396039604e-06,
      "loss": 0.0007,
      "step": 12510
    },
    {
      "epoch": 2.8617142857142857,
      "grad_norm": 0.00039041676791384816,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0032,
      "step": 12520
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.0008281412883661687,
      "learning_rate": 2.3603960396039603e-06,
      "loss": 0.0014,
      "step": 12530
    },
    {
      "epoch": 2.8662857142857145,
      "grad_norm": 0.00019147965940646827,
      "learning_rate": 2.320792079207921e-06,
      "loss": 0.0,
      "step": 12540
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 0.0006849904893897474,
      "learning_rate": 2.2811881188118812e-06,
      "loss": 0.0,
      "step": 12550
    },
    {
      "epoch": 2.870857142857143,
      "grad_norm": 0.0006199934286996722,
      "learning_rate": 2.2415841584158417e-06,
      "loss": 0.0074,
      "step": 12560
    },
    {
      "epoch": 2.873142857142857,
      "grad_norm": 0.00016224569117184728,
      "learning_rate": 2.201980198019802e-06,
      "loss": 0.0002,
      "step": 12570
    },
    {
      "epoch": 2.8754285714285714,
      "grad_norm": 0.00041213157237507403,
      "learning_rate": 2.162376237623762e-06,
      "loss": 0.0054,
      "step": 12580
    },
    {
      "epoch": 2.8777142857142857,
      "grad_norm": 0.00037092191632837057,
      "learning_rate": 2.122772277227723e-06,
      "loss": 0.0004,
      "step": 12590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.0001977067004190758,
      "learning_rate": 2.0831683168316835e-06,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 2.8822857142857146,
      "grad_norm": 0.0007920413627289236,
      "learning_rate": 2.0435643564356435e-06,
      "loss": 0.0,
      "step": 12610
    },
    {
      "epoch": 2.8845714285714283,
      "grad_norm": 0.00040198719943873584,
      "learning_rate": 2.003960396039604e-06,
      "loss": 0.0,
      "step": 12620
    },
    {
      "epoch": 2.886857142857143,
      "grad_norm": 0.00043949062819592655,
      "learning_rate": 1.9643564356435644e-06,
      "loss": 0.0003,
      "step": 12630
    },
    {
      "epoch": 2.8891428571428572,
      "grad_norm": 0.0002922793210018426,
      "learning_rate": 1.924752475247525e-06,
      "loss": 0.0,
      "step": 12640
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 0.0007888887193985283,
      "learning_rate": 1.8851485148514851e-06,
      "loss": 0.0003,
      "step": 12650
    },
    {
      "epoch": 2.8937142857142857,
      "grad_norm": 0.00045738869812339544,
      "learning_rate": 1.8455445544554456e-06,
      "loss": 0.0006,
      "step": 12660
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.0007018790929578245,
      "learning_rate": 1.8059405940594058e-06,
      "loss": 0.0004,
      "step": 12670
    },
    {
      "epoch": 2.898285714285714,
      "grad_norm": 0.0008174218819476664,
      "learning_rate": 1.7663366336633663e-06,
      "loss": 0.0001,
      "step": 12680
    },
    {
      "epoch": 2.9005714285714284,
      "grad_norm": 0.0005163628957234323,
      "learning_rate": 1.726732673267327e-06,
      "loss": 0.0,
      "step": 12690
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.001058319816365838,
      "learning_rate": 1.6871287128712874e-06,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 2.9051428571428572,
      "grad_norm": 0.0007772008539177477,
      "learning_rate": 1.6475247524752476e-06,
      "loss": 0.0032,
      "step": 12710
    },
    {
      "epoch": 2.9074285714285715,
      "grad_norm": 0.0001579517702339217,
      "learning_rate": 1.607920792079208e-06,
      "loss": 0.0003,
      "step": 12720
    },
    {
      "epoch": 2.9097142857142857,
      "grad_norm": 3.095232750638388e-05,
      "learning_rate": 1.5683168316831683e-06,
      "loss": 0.0062,
      "step": 12730
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.0004637342062778771,
      "learning_rate": 1.5287128712871288e-06,
      "loss": 0.0002,
      "step": 12740
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.00022829730005469173,
      "learning_rate": 1.489108910891089e-06,
      "loss": 0.0004,
      "step": 12750
    },
    {
      "epoch": 2.9165714285714284,
      "grad_norm": 0.0004806689394172281,
      "learning_rate": 1.4495049504950497e-06,
      "loss": 0.0011,
      "step": 12760
    },
    {
      "epoch": 2.918857142857143,
      "grad_norm": 0.00015676931070629507,
      "learning_rate": 1.40990099009901e-06,
      "loss": 0.0,
      "step": 12770
    },
    {
      "epoch": 2.9211428571428573,
      "grad_norm": 0.0006075302953831851,
      "learning_rate": 1.3702970297029704e-06,
      "loss": 0.0002,
      "step": 12780
    },
    {
      "epoch": 2.9234285714285715,
      "grad_norm": 0.0008538870606571436,
      "learning_rate": 1.3306930693069306e-06,
      "loss": 0.0,
      "step": 12790
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.000604822940658778,
      "learning_rate": 1.291089108910891e-06,
      "loss": 0.0077,
      "step": 12800
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.0011727010132744908,
      "learning_rate": 1.2514851485148515e-06,
      "loss": 0.0024,
      "step": 12810
    },
    {
      "epoch": 2.930285714285714,
      "grad_norm": 0.0005641754250973463,
      "learning_rate": 1.211881188118812e-06,
      "loss": 0.0003,
      "step": 12820
    },
    {
      "epoch": 2.9325714285714284,
      "grad_norm": 1.631809391255956e-05,
      "learning_rate": 1.1722772277227724e-06,
      "loss": 0.0004,
      "step": 12830
    },
    {
      "epoch": 2.934857142857143,
      "grad_norm": 0.0008425383130088449,
      "learning_rate": 1.1326732673267327e-06,
      "loss": 0.0004,
      "step": 12840
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.0007689313497394323,
      "learning_rate": 1.0930693069306931e-06,
      "loss": 0.0,
      "step": 12850
    },
    {
      "epoch": 2.9394285714285715,
      "grad_norm": 0.1441037803888321,
      "learning_rate": 1.0534653465346536e-06,
      "loss": 0.0028,
      "step": 12860
    },
    {
      "epoch": 2.9417142857142857,
      "grad_norm": 0.000655065814498812,
      "learning_rate": 1.013861386138614e-06,
      "loss": 0.0026,
      "step": 12870
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.0008061712142080069,
      "learning_rate": 9.742574257425743e-07,
      "loss": 0.0007,
      "step": 12880
    },
    {
      "epoch": 2.946285714285714,
      "grad_norm": 0.0006558671011589468,
      "learning_rate": 9.346534653465346e-07,
      "loss": 0.0002,
      "step": 12890
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 0.000776893284637481,
      "learning_rate": 8.950495049504951e-07,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 2.950857142857143,
      "grad_norm": 0.23332412540912628,
      "learning_rate": 8.554455445544555e-07,
      "loss": 0.0063,
      "step": 12910
    },
    {
      "epoch": 2.9531428571428573,
      "grad_norm": 0.0010128332069143653,
      "learning_rate": 8.158415841584159e-07,
      "loss": 0.0002,
      "step": 12920
    },
    {
      "epoch": 2.9554285714285715,
      "grad_norm": 0.0007651104824617505,
      "learning_rate": 7.762376237623763e-07,
      "loss": 0.0073,
      "step": 12930
    },
    {
      "epoch": 2.9577142857142857,
      "grad_norm": 0.0008225718047469854,
      "learning_rate": 7.366336633663367e-07,
      "loss": 0.0002,
      "step": 12940
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.00023918070655781776,
      "learning_rate": 6.970297029702971e-07,
      "loss": 0.0002,
      "step": 12950
    },
    {
      "epoch": 2.962285714285714,
      "grad_norm": 0.00016132203745655715,
      "learning_rate": 6.574257425742575e-07,
      "loss": 0.0,
      "step": 12960
    },
    {
      "epoch": 2.9645714285714284,
      "grad_norm": 0.00013334283721633255,
      "learning_rate": 6.178217821782179e-07,
      "loss": 0.0002,
      "step": 12970
    },
    {
      "epoch": 2.966857142857143,
      "grad_norm": 0.0008685232605785131,
      "learning_rate": 5.782178217821783e-07,
      "loss": 0.0002,
      "step": 12980
    },
    {
      "epoch": 2.9691428571428573,
      "grad_norm": 0.0005235234857536852,
      "learning_rate": 5.386138613861386e-07,
      "loss": 0.0,
      "step": 12990
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.00038875258178450167,
      "learning_rate": 4.990099009900991e-07,
      "loss": 0.0005,
      "step": 13000
    },
    {
      "epoch": 2.9737142857142858,
      "grad_norm": 0.05274619162082672,
      "learning_rate": 4.594059405940594e-07,
      "loss": 0.0003,
      "step": 13010
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.000454700697446242,
      "learning_rate": 4.1980198019801986e-07,
      "loss": 0.0,
      "step": 13020
    },
    {
      "epoch": 2.978285714285714,
      "grad_norm": 0.0004072051087860018,
      "learning_rate": 3.801980198019802e-07,
      "loss": 0.0,
      "step": 13030
    },
    {
      "epoch": 2.9805714285714284,
      "grad_norm": 0.0005027364823035896,
      "learning_rate": 3.405940594059406e-07,
      "loss": 0.0594,
      "step": 13040
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 0.024729814380407333,
      "learning_rate": 3.00990099009901e-07,
      "loss": 0.0007,
      "step": 13050
    },
    {
      "epoch": 2.985142857142857,
      "grad_norm": 0.0337502621114254,
      "learning_rate": 2.613861386138614e-07,
      "loss": 0.0002,
      "step": 13060
    },
    {
      "epoch": 2.9874285714285715,
      "grad_norm": 0.0008385468390770257,
      "learning_rate": 2.2178217821782178e-07,
      "loss": 0.0003,
      "step": 13070
    },
    {
      "epoch": 2.9897142857142858,
      "grad_norm": 0.00043458284926600754,
      "learning_rate": 1.821782178217822e-07,
      "loss": 0.0002,
      "step": 13080
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.0004520788206718862,
      "learning_rate": 1.4257425742574258e-07,
      "loss": 0.0035,
      "step": 13090
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 0.03638575226068497,
      "learning_rate": 1.0297029702970298e-07,
      "loss": 0.0008,
      "step": 13100
    },
    {
      "epoch": 2.9965714285714284,
      "grad_norm": 0.0005317389732226729,
      "learning_rate": 6.336633663366338e-08,
      "loss": 0.0,
      "step": 13110
    },
    {
      "epoch": 2.998857142857143,
      "grad_norm": 0.0002140207216143608,
      "learning_rate": 2.3762376237623763e-08,
      "loss": 0.0009,
      "step": 13120
    }
  ],
  "logging_steps": 10,
  "max_steps": 13125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6954538429440000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
